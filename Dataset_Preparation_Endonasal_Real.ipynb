{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/Dataset_Preparation_Endonasal_Real.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIo5spaeEaik"
      },
      "source": [
        "# Endonasal data preparation from PitVIS videos:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da_7YBxsEaim"
      },
      "source": [
        "Video links:<br>\n",
        "https://drive.google.com/file/d/1-aFmRseZ19OJvIEnFWNYfJdtKEw3gJmz/view?usp=sharing <br>\n",
        "https://drive.google.com/file/d/1Qe_ml7kS62DWbrxRD-IUkmP-BpZNg1h-/view?usp=sharing <br>\n",
        "https://drive.google.com/file/d/1n6uHQ2mPu0DTnBD_Bsn4V0eRIp2Z6Njk/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkNzViVtEaim",
        "outputId": "642ada75-6a26-4d12-ac4a-91c623965917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/sh: 1: gdown: not found\r\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1-aFmRseZ19OJvIEnFWNYfJdtKEw3gJmz\n",
        "!gdown --id 1Qe_ml7kS62DWbrxRD-IUkmP-BpZNg1h-\n",
        "!gdown --id 1n6uHQ2mPu0DTnBD_Bsn4V0eRIp2Z6Njk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsUA-xOrEaio",
        "outputId": "3d052d9f-3797-425c-a50d-42ec718173bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Annotations  Annotations.zip  imgs  masks  video_02.mp4  videos\r\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKfM92EOEaio"
      },
      "source": [
        "Video to frame conversion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nimHBrdXEaip",
        "outputId": "936fe797-f9af-4153-f853-9085cf9585c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['video_01.mp4', 'video_02.mp4', 'video_03.mp4']\n",
            "videos/video_01.mp4\n",
            "int_frames_per_second 24.0\n",
            "videos/video_01.mp4 successfully converted to 172812 images.\n",
            "videos/video_02.mp4\n",
            "int_frames_per_second 24.0\n",
            "videos/video_02.mp4 successfully converted to 145631 images.\n",
            "videos/video_03.mp4\n",
            "int_frames_per_second 24.0\n",
            "videos/video_03.mp4 successfully converted to 82049 images.\n"
          ]
        }
      ],
      "source": [
        "# global imports\n",
        "import argparse\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# strong typing\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "\n",
        "def main(pt_videos: Path, pt_images: Path):\n",
        "    convert_videos_to_images(pt_videos=pt_videos, pt_images=pt_images)\n",
        "\n",
        "\n",
        "def convert_videos_to_images(pt_videos: Path, pt_images: Path):\n",
        "    \"\"\"convert all videos from {pt_videos} to images saved to {pt_images}\"\"\"\n",
        "    create_directory(pt=pt_images)\n",
        "\n",
        "    ls_videos: List[str] = os.listdir(pt_videos)\n",
        "    ls_videos.sort()\n",
        "    print(ls_videos)\n",
        "    for str_video in ls_videos:\n",
        "        pt_video: Path = pt_videos.joinpath(str_video)\n",
        "        pt_image: Path = pt_images.joinpath(str_video.split(\".\")[0])\n",
        "        print(pt_video)\n",
        "        create_directory(pt=pt_image)\n",
        "        convert_video_to_image(pt_video=pt_video, pt_image=pt_image)\n",
        "\n",
        "\n",
        "def convert_video_to_image(pt_video: Path, pt_image: Path):\n",
        "    \"\"\"convert a single video from {pt_video} to images saved to {pt_image}\"\"\"\n",
        "    video_capture = cv2.VideoCapture(str(pt_video))\n",
        "    int_frames_per_second: int = np.ceil(video_capture.get(cv2.CAP_PROP_FPS))  # ceiling function to ensure integer\n",
        "    print('int_frames_per_second', int_frames_per_second)\n",
        "    int_frame: int = 0\n",
        "    count: int = 0\n",
        "    while video_capture.isOpened():\n",
        "        bool_success, np_frame_matrix = video_capture.read()\n",
        "        if bool_success:\n",
        "            if int_frame % int_frames_per_second == 0:\n",
        "                pt_image_frame: Path = pt_image.joinpath(f\"{int(count):07}.png\")\n",
        "                cv2.imwrite(str(pt_image_frame), np_frame_matrix)\n",
        "                count += 1\n",
        "        else:\n",
        "            break\n",
        "        int_frame += 1\n",
        "\n",
        "    video_capture.release()\n",
        "    print(f\"{pt_video} successfully converted to {int_frame} images.\")\n",
        "\n",
        "\n",
        "def create_directory(pt: Path):\n",
        "    \"\"\"create a directory for a given {path} if it does not already exist\"\"\"\n",
        "    if not os.path.exists(pt):\n",
        "        os.mkdir(pt)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    arg_parser = argparse.ArgumentParser()\n",
        "    arg_parser.add_argument(\"--pt_videos\", type=str, help=\"videos path (parent directory)\", default='')\n",
        "    arg_parser.add_argument(\"--pt_images\", type=str, help=\"images path (parent directory)\", default='')\n",
        "    args = arg_parser.parse_args([])\n",
        "    args.pt_videos = 'videos'\n",
        "    args.pt_images = 'imgs'\n",
        "    SystemExit(main(pt_videos=Path(args.pt_videos), pt_images=Path(args.pt_images)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUBGvq3OEaip"
      },
      "source": [
        "sub-grouping frames based on blurred interruption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "jP0C1PLREaiq",
        "outputId": "bdb7cb52-f8c4-4c5e-ed7a-3932049a4f58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of clear frames: 6816 / 7202\n",
            "group_path: imgs/video_01/video_01_01 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_02 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_03 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_04 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_05 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_06 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_07 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_08 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_09 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_10 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_11 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_12 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_13 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_14 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_15 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_16 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_17 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_18 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_19 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_20 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_21 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_22 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_23 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_24 Annotations/annotations_01.csv\n",
            "group_path: imgs/video_01/video_01_25 Annotations/annotations_01.csv\n",
            "number of clear frames: 5376 / 6069\n",
            "group_path: imgs/video_02/video_02_01 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_02 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_03 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_04 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_05 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_06 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_07 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_08 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_09 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_10 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_11 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_12 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_13 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_14 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_15 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_16 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_17 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_18 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_19 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_20 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_21 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_22 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_23 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_24 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_25 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_26 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_27 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_28 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_29 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_30 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_31 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_32 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_33 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_34 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_35 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_36 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_37 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_38 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_39 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_40 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_41 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_42 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_43 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_44 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_45 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_46 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_47 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_48 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_49 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_50 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_51 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_52 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_53 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_54 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_55 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_56 Annotations/annotations_02.csv\n",
            "group_path: imgs/video_02/video_02_57 Annotations/annotations_02.csv\n",
            "number of clear frames: 3240 / 3420\n",
            "group_path: imgs/video_03/video_03_01 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_02 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_03 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_04 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_05 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_06 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_07 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_08 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_09 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_10 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_11 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_12 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_13 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_14 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_15 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_16 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_17 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_18 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_19 Annotations/annotations_03.csv\n",
            "group_path: imgs/video_03/video_03_20 Annotations/annotations_03.csv\n"
          ]
        }
      ],
      "source": [
        "from operator import itemgetter\n",
        "from itertools import groupby\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "imgs_videos = glob('imgs/video_*')\n",
        "anno_root = 'Annotations'\n",
        "imgs_videos.sort()\n",
        "for imgs_video_path in imgs_videos:\n",
        "    anno_path = os.path.join(anno_root, 'annotations_{}.csv'.format(imgs_video_path[-2:]))\n",
        "    #print(anno_path)\n",
        "    df = pd.read_csv(anno_path)\n",
        "    nonblur_frames = list(df['int_time'][df['int_step'] != -1])\n",
        "    print('number of clear frames:', len(nonblur_frames),'/', len(df))\n",
        "    group_count = 0\n",
        "    for key, group in groupby(enumerate(nonblur_frames), lambda i: i[0] - i[1]):\n",
        "        group = list(map(itemgetter(1), group))\n",
        "\n",
        "        group_count += 1\n",
        "        group_folder = \"{}_{:02d}\".format(os.path.basename(imgs_video_path), group_count)\n",
        "        group_path = os.path.join(imgs_video_path, group_folder)\n",
        "        print('group_path:',group_path, anno_path)\n",
        "        os.makedirs(group_path, mode = 0o777, exist_ok = True)\n",
        "        for img_num in group:\n",
        "            src_file = os.path.join(imgs_video_path, \"{:07d}.png\".format(img_num))\n",
        "            try:\n",
        "                shutil.move(src_file, group_path)\n",
        "            except:\n",
        "                continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxbAEliIEaiq"
      },
      "source": [
        "Removing blurred frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPZT_fS8Eair",
        "outputId": "76cc6a86-4844-4d03-ef5e-b8e7ab2e0fec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "blurred_imgs_videos = glob('imgs/video_*/*.png')\n",
        "print(len(blurred_imgs_videos))\n",
        "blurred_imgs_videos.sort()\n",
        "for blurred_img_path in blurred_imgs_videos:\n",
        "    os.remove(blurred_img_path)\n",
        "    #print(blurred_img_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX53LFmKEair"
      },
      "source": [
        "Images to masks to detect black padding of the limited view endoscope:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GyMk9cDEair",
        "outputId": "d38afe31-497b-4908-f376-b09bfa72796d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15432\n"
          ]
        }
      ],
      "source": [
        "from glob import glob\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from skimage import morphology\n",
        "\n",
        "imgs_videos = glob('imgs/video_*/video*/*.png')\n",
        "imgs_videos.sort()\n",
        "print(len(imgs_videos))\n",
        "for img_path in imgs_videos:\n",
        "    mask_path = os.path.join('masks',img_path[5:])\n",
        "    os.makedirs(os.path.dirname(mask_path), mode = 0o777, exist_ok = True)\n",
        "    img = Image.open(img_path).convert('L')\n",
        "    img = np.array(img)\n",
        "    mask = np.zeros(img.shape)\n",
        "    mask1 = np.zeros(img.shape)\n",
        "    mask[img!=0] = 255\n",
        "    mask = np.array(mask, np.uint8)\n",
        "    circles = cv2.HoughCircles(mask, cv2.HOUGH_GRADIENT, 4.0, 100)\n",
        "    if circles is not None:\n",
        "        circles = np.round(circles[0, :]).astype(\"int\")\n",
        "        (x, y, r) = circles[0:1][0]\n",
        "        cv2.circle(mask1, (x, y), r-10, 255, -1)\n",
        "        cv2.imwrite(mask_path, mask1)\n",
        "    else:\n",
        "        print('no mask:', img_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO0-43-lEais"
      },
      "source": [
        "Removing black padding and unwanted text in the padding from the images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoIXw_DqEais"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from skimage import morphology\n",
        "\n",
        "imgs_videos = glob('imgs/video_*/video*/*.png')\n",
        "imgs_videos.sort()\n",
        "print(len(imgs_videos))\n",
        "for img_path in imgs_videos:\n",
        "    img_rgb = Image.open(img_path).convert('RGB')\n",
        "    img = img_rgb.convert('L')\n",
        "    img_rgb = np.array(img_rgb)\n",
        "    img = np.array(img)\n",
        "    mask = np.zeros(img.shape)\n",
        "    mask1 = np.zeros(img.shape)\n",
        "    mask[img!=0] = 255\n",
        "    mask = np.array(mask, np.uint8)\n",
        "    circles = cv2.HoughCircles(mask, cv2.HOUGH_GRADIENT, 4.0, 100)\n",
        "    if circles is not None:\n",
        "        circles = np.round(circles[0, :]).astype(\"int\")\n",
        "        (x, y, r) = circles[0:1][0]\n",
        "        cv2.circle(mask1, (x, y), r, 255, -1)\n",
        "        img_rgb[mask1==0] = 0\n",
        "        img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
        "        cv2.imwrite(img_path, img_bgr)\n",
        "    else:\n",
        "        print('no mask:', img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sver6mFlEais"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}