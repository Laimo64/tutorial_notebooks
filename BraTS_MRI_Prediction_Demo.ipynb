{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/BraTS_MRI_Prediction_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ5MCVytMBzZ"
      },
      "source": [
        "# Spatially Varying Label Smoothing: Capturing Uncertainty from Expert Annotations\n",
        "[Preprint](https://arxiv.org/pdf/2104.05788.pdf)\n",
        "[Code](https://github.com/mobarakol/SVLS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiSbpb1EwjnY"
      },
      "source": [
        "Downloading SVLS and Surface Dice codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFNfvBfdKsT7",
        "outputId": "3e71e4fb-2e2c-42ea-babb-94dc611d65c8"
      },
      "source": [
        "!rm -rf SVLS\n",
        "!git clone https://github.com/mobarakol/SVLS.git\n",
        "%cd SVLS\n",
        "!git clone https://github.com/deepmind/surface-distance.git\n",
        "!mv surface-distance surface_distance"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SVLS'...\n",
            "remote: Enumerating objects: 400, done.\u001b[K\n",
            "remote: Counting objects: 100% (400/400), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 400 (delta 351), reused 372 (delta 336), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (400/400), 120.63 KiB | 5.48 MiB/s, done.\n",
            "Resolving deltas: 100% (351/351), done.\n",
            "/content/SVLS\n",
            "Cloning into 'surface-distance'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 50 (delta 11), reused 8 (delta 7), pack-reused 33\u001b[K\n",
            "Receiving objects: 100% (50/50), 36.67 KiB | 3.05 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZNhk4-Od3FR"
      },
      "source": [
        "Install require packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdbUhZNUd6kl",
        "outputId": "fb06ea54-c8a6-486a-9b18-cd60bf083754"
      },
      "source": [
        "!pip install -U -q SimpleITK"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBq96oSpM7Da"
      },
      "source": [
        "### Download Dataset and Trained Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keDB9x0yNH4J"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgGSo3tNNwaF"
      },
      "source": [
        "Trained Models: https://drive.google.com/file/d/1evE2VqBGdY-0VPB8OeArHMPdRXhWuxFm/view?usp=sharing <br>\n",
        "Validation Data: https://drive.google.com/file/d/1oZ9z-l9lBjKGNZCCTK819Z1ufwe90mg3/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhX7jTGxNxEr"
      },
      "source": [
        "ids = ['1evE2VqBGdY-0VPB8OeArHMPdRXhWuxFm', '1oZ9z-l9lBjKGNZCCTK819Z1ufwe90mg3']\n",
        "zip_files = ['ckpt_brats19.zip','train_valid.zip']\n",
        "for id, zip_file in zip(ids, zip_files):\n",
        "    downloaded = drive.CreateFile({'id':id})\n",
        "    downloaded.GetContentFile(zip_file)\n",
        "    !unzip -q $zip_file"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download BraTS validation set"
      ],
      "metadata": {
        "id": "dlKEigxZ-VPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir brats_valid\n",
        "ids = ['1dZDw0wFDTIZlAbFEqSAfMaKOAlEG_Fat', '1evE2VqBGdY-0VPB8OeArHMPdRXhWuxFm']\n",
        "zip_files = ['ASNR-MICCAI-BraTS2023-GLI-Challenge-ValidationData.zip', 'ckpt_brats19.zip']\n",
        "for id, zip_file in zip(ids, zip_files):\n",
        "    downloaded = drive.CreateFile({'id':id})\n",
        "    downloaded.GetContentFile(zip_file)\n",
        "    !unzip -q $zip_file -d brats_valid"
      ],
      "metadata": {
        "id": "Y4fEa0H9-Uek"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction to MRI:"
      ],
      "metadata": {
        "id": "hoHNDthSDwgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from model import UNet3D\n",
        "from datasets import get_datasets_brats\n",
        "from utils import seed_everything, EDiceLoss\n",
        "import nibabel as nib\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import SimpleITK as sitk\n",
        "import random\n",
        "from glob import glob\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data._utils.collate import default_collate\n",
        "from datasets import custom_collate, determinist_collate, pad_batch_to_max_shape, \\\n",
        "pad_batch1_to_compatible_size, irm_min_max_preprocess, pad_or_crop_image\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description='SVLS Brats Training')\n",
        "parser.add_argument('--batch_size', default=2, type=int,help='mini-batch size')\n",
        "parser.add_argument('--num_classes', default=4, type=int, help=\"num of classes\")\n",
        "parser.add_argument('--in_channels', default=4, type=int, help=\"num of input channels\")\n",
        "parser.add_argument('--train_option', default='SVLS', help=\"options:[SVLS, LS, OH]\")\n",
        "parser.add_argument('--epochs', default=200, type=int, help='number of total epochs to run')\n",
        "parser.add_argument('--data_root', default='train_valid', help='data directory')\n",
        "parser.add_argument('--ckpt_dir', default='ckpt_brats19', help='ckpt directory')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "def get_datasets_brats(data_root=None, normalisation=\"zscore\", no_seg=False):\n",
        "    data_rootn = data_root\n",
        "    data_root = pathlib.Path(data_root)\n",
        "    base_folder_valid = pathlib.Path(data_root).resolve()\n",
        "    subdirectories = [x for x in base_folder_valid.iterdir() if x.is_dir()]\n",
        "    patients_dir_valid = sorted([data_root/x.name for x in base_folder_valid.iterdir() if (data_root/x.name).is_dir()])\n",
        "    val_dataset = brats19(patients_dir_valid, training=False, normalisation=normalisation, no_seg=no_seg)\n",
        "    return val_dataset\n",
        "\n",
        "\n",
        "class brats19(Dataset):\n",
        "    def __init__(self, patients_dir, training=True, no_seg=False, normalisation=\"minmax\"):\n",
        "        super(brats19, self).__init__()\n",
        "        self.normalisation = normalisation\n",
        "        self.training = training\n",
        "        self.datas = []\n",
        "        self.validation = no_seg\n",
        "        self.patterns = [ \"-t2f\", \"-t1n\", \"-t1c\", \"-t2w\"]\n",
        "        self.mean = dict(flair=0.0860377, t1=0.1216296, t1ce=0.07420689, t2=0.09033176)\n",
        "        if not no_seg:\n",
        "            self.patterns += [\"_seg\"]\n",
        "        for patient_dir in patients_dir:\n",
        "            patient_id = patient_dir.name\n",
        "            paths = [patient_dir / f\"{patient_id}{value}.nii.gz\" for value in self.patterns]\n",
        "            patient = dict(\n",
        "                id=patient_id, flair=paths[0], t1=paths[1], t1ce=paths[2],\n",
        "                t2=paths[3], seg=paths[4] if not no_seg else None\n",
        "            )\n",
        "            self.datas.append(patient)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        _patient = self.datas[idx]\n",
        "        patient_image = {key: self.load_nii(_patient[key]) for key in _patient if key not in [\"id\", \"seg\"]}\n",
        "\n",
        "        patient_image = {key: (irm_min_max_preprocess(patient_image[key]) - self.mean[key]) for key in patient_image}\n",
        "        patient_image = np.stack([patient_image[key] for key in patient_image])\n",
        "        patient_label = torch.zeros(patient_image[0].shape)\n",
        "\n",
        "        # Remove maximum extent of the zero-background to make future crop more useful\n",
        "        z_indexes, y_indexes, x_indexes = np.nonzero(np.sum(patient_image, axis=0) != 0)\n",
        "\n",
        "        # Add 1 pixel in each side\n",
        "        zmin, ymin, xmin = [max(0, int(np.min(arr) - 1)) for arr in (z_indexes, y_indexes, x_indexes)]\n",
        "        zmax, ymax, xmax = [int(np.max(arr) + 1) for arr in (z_indexes, y_indexes, x_indexes)]\n",
        "        patient_image = patient_image[:, 13:141, 24:216, 24:216]\n",
        "        if _patient[\"seg\"] is not None:\n",
        "            patient_label = self.load_nii(_patient[\"seg\"])\n",
        "            patient_label = patient_label[None,:,:,:]\n",
        "            patient_label = patient_label[:, 13:141, 24:216, 24:216]\n",
        "            patient_label = patient_label.astype(\"long\")\n",
        "            patient_label = torch.from_numpy(patient_label)\n",
        "\n",
        "        patient_image = patient_image.astype(\"float16\")\n",
        "        patient_image = torch.from_numpy(np.array(patient_image))\n",
        "        # print(patient_image.shape)\n",
        "        return dict(patient_id=_patient[\"id\"],\n",
        "                    image=patient_image, label=patient_label,\n",
        "                    seg_path=str(_patient[\"seg\"]),\n",
        "                    crop_indexes=((zmin, zmax), (ymin, ymax), (xmin, xmax)),\n",
        "                    )\n",
        "\n",
        "    @staticmethod\n",
        "    def load_nii(path_folder):\n",
        "        return sitk.GetArrayFromImage(sitk.ReadImage(str(path_folder)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datas)\n",
        "\n",
        "\n",
        "def save_prediction_to_mri(args, predictions, patient_ids):\n",
        "    os.makedirs('predicted_segs', exist_ok=True)\n",
        "    for idx, patient_id in enumerate(patient_ids):\n",
        "        path = os.path.join(args.data_root, patient_id, patient_id+'-t1n.nii.gz')\n",
        "        img_original = nib.load(path)\n",
        "        img_nifti = nib.Nifti1Image(predictions[idx], img_original.affine, header=img_original.header)\n",
        "        nib.save(img_nifti,'predicted_segs/'+patient_id+'.nii.gz') #not as expected\n",
        "\n",
        "args.data_root = '/content/SVLS/brats_valid/ASNR-MICCAI-BraTS2023-GLI-Challenge-ValidationData/'\n",
        "val_dataset = get_datasets_brats(data_root=args.data_root, no_seg=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\n",
        "    pin_memory=False, num_workers=2)\n",
        "\n",
        "print('valid sample:',len(val_dataset), 'valid minibatch:',len(val_loader))\n",
        "model = UNet3D(inplanes=args.in_channels, num_classes=args.num_classes).cuda()\n",
        "model = torch.nn.DataParallel(model)\n",
        "criterion_dice = EDiceLoss().cuda()\n",
        "model.load_state_dict(torch.load(os.path.join(args.ckpt_dir, 'best_oh.pth.tar')))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    metrics = []\n",
        "    for i, batch in enumerate(val_loader):\n",
        "        targets = batch[\"label\"].squeeze(1).cuda(non_blocking=True)\n",
        "        inputs = batch[\"image\"].float().cuda()\n",
        "        preds = model(inputs)\n",
        "        pred_full = torch.zeros(targets.shape)\n",
        "        preds = preds.data.max(1)[1].squeeze_(1)\n",
        "        pred_full[:,13:141, 24:216, 24:216] = preds.cpu()\n",
        "        pred_full = pred_full.permute(0,3,2,1).detach().cpu().numpy()\n",
        "        save_prediction_to_mri(args, pred_full, batch['patient_id'])\n",
        "\n",
        "\n",
        "!zip -r predicted_segs.zip predicted_segs\n",
        "files.download('predicted_segs.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSEINqKD_KHB",
        "outputId": "a96efad3-856c-4a03-b05e-a6a71d58832c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid sample: 219 valid minibatch: 110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0PdKAYPWBx8"
      },
      "source": [
        "Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method-1: Saving the prediction: same size as training"
      ],
      "metadata": {
        "id": "PX_ri7M1KBrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from model import UNet3D\n",
        "from datasets import get_datasets_brats\n",
        "from utils import seed_everything, EDiceLoss\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import SimpleITK as sitk\n",
        "import random\n",
        "from glob import glob\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data._utils.collate import default_collate\n",
        "from datasets import custom_collate, determinist_collate, pad_batch_to_max_shape, \\\n",
        "pad_batch1_to_compatible_size, irm_min_max_preprocess, pad_or_crop_image\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description='SVLS Brats Training')\n",
        "parser.add_argument('--batch_size', default=2, type=int,help='mini-batch size')\n",
        "parser.add_argument('--num_classes', default=4, type=int, help=\"num of classes\")\n",
        "parser.add_argument('--in_channels', default=4, type=int, help=\"num of input channels\")\n",
        "parser.add_argument('--train_option', default='SVLS', help=\"options:[SVLS, LS, OH]\")\n",
        "parser.add_argument('--epochs', default=200, type=int, help='number of total epochs to run')\n",
        "parser.add_argument('--data_root', default='train_valid', help='data directory')\n",
        "parser.add_argument('--ckpt_dir', default='ckpt_brats19', help='ckpt directory')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "def get_datasets_brats(data_root=None, normalisation=\"zscore\"):\n",
        "\n",
        "    data_root = pathlib.Path(data_root)\n",
        "    base_folder_train = pathlib.Path('data/BraTS19/train_train/').resolve()\n",
        "    base_folder_valid = pathlib.Path('data/BraTS19/train_valid/').resolve()\n",
        "    patients_dir_train = sorted([data_root/x.name for x in base_folder_train.iterdir() if (data_root/x.name).is_dir()])\n",
        "    patients_dir_valid = sorted([data_root/x.name for x in base_folder_valid.iterdir() if (data_root/x.name).is_dir()])\n",
        "    train_dataset = brats19(patients_dir_train, training=True, normalisation=normalisation)\n",
        "    val_dataset = brats19(patients_dir_valid, training=False, normalisation=normalisation)\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "\n",
        "class brats19(Dataset):\n",
        "    def __init__(self, patients_dir, training=True, no_seg=False, normalisation=\"minmax\"):\n",
        "        super(brats19, self).__init__()\n",
        "        self.normalisation = normalisation\n",
        "        self.training = training\n",
        "        self.datas = []\n",
        "        self.validation = no_seg\n",
        "        self.patterns = [ \"_flair\", \"_t1\", \"_t1ce\", \"_t2\"]\n",
        "        self.mean = dict(flair=0.0860377, t1=0.1216296, t1ce=0.07420689, t2=0.09033176)\n",
        "        if not no_seg:\n",
        "            self.patterns += [\"_seg\"]\n",
        "        for patient_dir in patients_dir:\n",
        "            patient_id = patient_dir.name\n",
        "            paths = [patient_dir / f\"{patient_id}{value}.nii.gz\" for value in self.patterns]\n",
        "            patient = dict(\n",
        "                id=patient_id, flair=paths[0], t1=paths[1], t1ce=paths[2],\n",
        "                t2=paths[3], seg=paths[4] if not no_seg else None\n",
        "            )\n",
        "            self.datas.append(patient)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        _patient = self.datas[idx]\n",
        "        patient_image = {key: self.load_nii(_patient[key]) for key in _patient if key not in [\"id\", \"seg\"]}\n",
        "        if _patient[\"seg\"] is not None:\n",
        "            patient_label = self.load_nii(_patient[\"seg\"])\n",
        "\n",
        "        patient_image = {key: (irm_min_max_preprocess(patient_image[key]) - self.mean[key]) for key in patient_image}\n",
        "        patient_image = np.stack([patient_image[key] for key in patient_image])\n",
        "        patient_label[patient_label==4] = 3\n",
        "        patient_label = patient_label[None,:,:,:]\n",
        "\n",
        "        # Remove maximum extent of the zero-background to make future crop more useful\n",
        "        z_indexes, y_indexes, x_indexes = np.nonzero(np.sum(patient_image, axis=0) != 0)\n",
        "\n",
        "        # Add 1 pixel in each side\n",
        "        zmin, ymin, xmin = [max(0, int(np.min(arr) - 1)) for arr in (z_indexes, y_indexes, x_indexes)]\n",
        "        zmax, ymax, xmax = [int(np.max(arr) + 1) for arr in (z_indexes, y_indexes, x_indexes)]\n",
        "        patient_image = patient_image[:, 13:141, 24:216, 24:216]\n",
        "        patient_image, patient_label = patient_image.astype(\"float16\"), patient_label.astype(\"long\")\n",
        "        patient_image, patient_label = [torch.from_numpy(x) for x in [patient_image, patient_label]]\n",
        "        return dict(patient_id=_patient[\"id\"],\n",
        "                    image=patient_image, label=patient_label,\n",
        "                    seg_path=str(_patient[\"seg\"]),\n",
        "                    crop_indexes=((zmin, zmax), (ymin, ymax), (xmin, xmax)),\n",
        "                    )\n",
        "\n",
        "    @staticmethod\n",
        "    def load_nii(path_folder):\n",
        "        return sitk.GetArrayFromImage(sitk.ReadImage(str(path_folder)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datas)\n",
        "\n",
        "\n",
        "def save_prediction_to_mri(args, predictions, patient_ids):\n",
        "    os.makedirs('predicted_segs', exist_ok=True)\n",
        "    for idx, patient_id in enumerate(patient_ids):\n",
        "        path = os.path.join(args.data_root, patient_id, patient_id+'_t1.nii.gz')\n",
        "        img_original = nib.load(path)\n",
        "        img_nifti = nib.Nifti1Image(predictions[idx], img_original.affine, header=img_original.header)\n",
        "        nib.save(img_nifti,'predicted_segs/'+patient_id+'_pred.nii.gz') #not as expected\n",
        "\n",
        "_, val_dataset = get_datasets_brats(data_root=args.data_root)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\n",
        "    pin_memory=False, num_workers=2)\n",
        "\n",
        "print('valid sample:',len(val_dataset), 'valid minibatch:',len(val_loader))\n",
        "model = UNet3D(inplanes=args.in_channels, num_classes=args.num_classes).cuda()\n",
        "model = torch.nn.DataParallel(model)\n",
        "criterion_dice = EDiceLoss().cuda()\n",
        "model.load_state_dict(torch.load(os.path.join(args.ckpt_dir, 'best_oh.pth.tar')))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    metrics = []\n",
        "    for i, batch in enumerate(val_loader):\n",
        "        targets = batch[\"label\"].squeeze(1).cuda(non_blocking=True)\n",
        "        inputs = batch[\"image\"].float().cuda()\n",
        "        preds = model(inputs)\n",
        "        pred_full = torch.zeros(targets.shape)\n",
        "        print(targets.shape)\n",
        "        preds = preds.data.max(1)[1].squeeze_(1)\n",
        "        pred_full[:,13:141, 24:216, 24:216] = preds.cpu()\n",
        "        if len(targets.shape) < 4:#if batch size=1\n",
        "            targets = targets.unsqueeze(0)\n",
        "        metric_ = criterion_dice.metric_brats(pred_full, targets.cpu())\n",
        "        metrics.extend(metric_)\n",
        "        pred_full = pred_full.permute(0,3,2,1).detach().cpu().numpy()\n",
        "        save_prediction_to_mri(args, pred_full, batch['patient_id'])\n",
        "        break\n",
        "    metrics = list(zip(*metrics))\n",
        "    metrics = [torch.tensor(dice, device=\"cpu\").numpy() for dice in metrics]\n",
        "    avg_dices = np.mean(metrics,1)\n",
        "\n",
        "print('dice[ET:%.3f, TC:%.3f, WT:%.3f]'%(avg_dices[0], avg_dices[1], avg_dices[2]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHjwGbL3KIJ9",
        "outputId": "54bc9a30-011d-4123-ea7e-56c14d14a159"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid sample: 66 valid minibatch: 33\n",
            "torch.Size([2, 155, 240, 240])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7d834a00f250>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1442, in _shutdown_workers\n",
            "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
            "    if not wait([self.sentinel], timeout):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.10/selectors.py\", line 416, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dice[ET:0.402, TC:0.687, WT:0.730]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method-2: Saving the prediction: including padding(default volume 155 244 244)"
      ],
      "metadata": {
        "id": "W0Tt6RRorSlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from model import UNet3D\n",
        "from datasets import get_datasets_brats\n",
        "from utils import seed_everything, EDiceLoss\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import SimpleITK as sitk\n",
        "import random\n",
        "from glob import glob\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data._utils.collate import default_collate\n",
        "from datasets import custom_collate, determinist_collate, pad_batch_to_max_shape, \\\n",
        "pad_batch1_to_compatible_size, irm_min_max_preprocess, pad_or_crop_image\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description='SVLS Brats Training')\n",
        "parser.add_argument('--batch_size', default=2, type=int,help='mini-batch size')\n",
        "parser.add_argument('--num_classes', default=4, type=int, help=\"num of classes\")\n",
        "parser.add_argument('--in_channels', default=4, type=int, help=\"num of input channels\")\n",
        "parser.add_argument('--train_option', default='SVLS', help=\"options:[SVLS, LS, OH]\")\n",
        "parser.add_argument('--epochs', default=200, type=int, help='number of total epochs to run')\n",
        "parser.add_argument('--data_root', default='train_valid', help='data directory')\n",
        "parser.add_argument('--ckpt_dir', default='ckpt_brats19', help='ckpt directory')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "def get_datasets_brats(data_root=None, normalisation=\"zscore\"):\n",
        "\n",
        "    data_root = pathlib.Path(data_root)\n",
        "    base_folder_train = pathlib.Path('data/BraTS19/train_train/').resolve()\n",
        "    base_folder_valid = pathlib.Path('data/BraTS19/train_valid/').resolve()\n",
        "    patients_dir_train = sorted([data_root/x.name for x in base_folder_train.iterdir() if (data_root/x.name).is_dir()])\n",
        "    patients_dir_valid = sorted([data_root/x.name for x in base_folder_valid.iterdir() if (data_root/x.name).is_dir()])\n",
        "    train_dataset = brats19(patients_dir_train, training=True, normalisation=normalisation)\n",
        "    val_dataset = brats19(patients_dir_valid, training=False, normalisation=normalisation)\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "\n",
        "class brats19(Dataset):\n",
        "    def __init__(self, patients_dir, training=True, no_seg=False, normalisation=\"minmax\"):\n",
        "        super(brats19, self).__init__()\n",
        "        self.normalisation = normalisation\n",
        "        self.training = training\n",
        "        self.datas = []\n",
        "        self.validation = no_seg\n",
        "        self.patterns = [ \"_flair\", \"_t1\", \"_t1ce\", \"_t2\"]\n",
        "        self.mean = dict(flair=0.0860377, t1=0.1216296, t1ce=0.07420689, t2=0.09033176)\n",
        "        if not no_seg:\n",
        "            self.patterns += [\"_seg\"]\n",
        "        for patient_dir in patients_dir:\n",
        "            patient_id = patient_dir.name\n",
        "            paths = [patient_dir / f\"{patient_id}{value}.nii.gz\" for value in self.patterns]\n",
        "            patient = dict(\n",
        "                id=patient_id, flair=paths[0], t1=paths[1], t1ce=paths[2],\n",
        "                t2=paths[3], seg=paths[4] if not no_seg else None\n",
        "            )\n",
        "            self.datas.append(patient)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        _patient = self.datas[idx]\n",
        "        patient_image = {key: self.load_nii(_patient[key]) for key in _patient if key not in [\"id\", \"seg\"]}\n",
        "        if _patient[\"seg\"] is not None:\n",
        "            patient_label = self.load_nii(_patient[\"seg\"])\n",
        "\n",
        "        patient_image = {key: (irm_min_max_preprocess(patient_image[key]) - self.mean[key]) for key in patient_image}\n",
        "        patient_image = np.stack([patient_image[key] for key in patient_image])\n",
        "        patient_label[patient_label==4] = 3\n",
        "        patient_label = patient_label[None,:,:,:]\n",
        "\n",
        "        # Remove maximum extent of the zero-background to make future crop more useful\n",
        "        z_indexes, y_indexes, x_indexes = np.nonzero(np.sum(patient_image, axis=0) != 0)\n",
        "\n",
        "        # Add 1 pixel in each side\n",
        "        zmin, ymin, xmin = [max(0, int(np.min(arr) - 1)) for arr in (z_indexes, y_indexes, x_indexes)]\n",
        "        zmax, ymax, xmax = [int(np.max(arr) + 1) for arr in (z_indexes, y_indexes, x_indexes)]\n",
        "        patient_image, patient_label = patient_image.astype(\"float16\"), patient_label.astype(\"long\")\n",
        "        patient_image, patient_label = [torch.from_numpy(x) for x in [patient_image, patient_label]]\n",
        "        return dict(patient_id=_patient[\"id\"],\n",
        "                    image=patient_image, label=patient_label,\n",
        "                    seg_path=str(_patient[\"seg\"]),\n",
        "                    crop_indexes=((zmin, zmax), (ymin, ymax), (xmin, xmax)),\n",
        "                    )\n",
        "\n",
        "    @staticmethod\n",
        "    def load_nii(path_folder):\n",
        "        return sitk.GetArrayFromImage(sitk.ReadImage(str(path_folder)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datas)\n",
        "\n",
        "\n",
        "def save_prediction_to_mri(args, predictions, patient_ids):\n",
        "    os.makedirs('predicted_segs', exist_ok=True)\n",
        "    for idx, patient_id in enumerate(patient_ids):\n",
        "        path = os.path.join(args.data_root, patient_id, patient_id+'_t1.nii.gz')\n",
        "        img_original = nib.load(path)\n",
        "        img_nifti = nib.Nifti1Image(predictions[idx], img_original.affine, header=img_original.header)\n",
        "        nib.save(img_nifti,'predicted_segs/'+patient_id+'_pred.nii.gz') #not as expected\n",
        "\n",
        "_, val_dataset = get_datasets_brats(data_root=args.data_root)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\n",
        "    pin_memory=False, num_workers=2)\n",
        "\n",
        "print('valid sample:',len(val_dataset), 'valid minibatch:',len(val_loader))\n",
        "model = UNet3D(inplanes=args.in_channels, num_classes=args.num_classes).cuda()\n",
        "model = torch.nn.DataParallel(model)\n",
        "criterion_dice = EDiceLoss().cuda()\n",
        "model.load_state_dict(torch.load(os.path.join(args.ckpt_dir, 'best_oh.pth.tar')))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    metrics = []\n",
        "    for i, batch in enumerate(val_loader):\n",
        "        targets = batch[\"label\"].squeeze(1).cuda(non_blocking=True)\n",
        "        inputs = batch[\"image\"].float().cuda()\n",
        "        preds = model(inputs)\n",
        "        preds = preds.data.max(1)[1].squeeze_(1)\n",
        "        if len(targets.shape) < 4:#if batch size=1\n",
        "            targets = targets.unsqueeze(0)\n",
        "        metric_ = criterion_dice.metric_brats(preds, targets)\n",
        "        metrics.extend(metric_)\n",
        "        preds = preds.permute(0,3,2,1).detach().cpu().numpy()\n",
        "        save_prediction_to_mri(args, preds, batch['patient_id'])\n",
        "\n",
        "    metrics = list(zip(*metrics))\n",
        "    metrics = [torch.tensor(dice, device=\"cpu\").numpy() for dice in metrics]\n",
        "    avg_dices = np.mean(metrics,1)\n",
        "\n",
        "print('dice[ET:%.3f, TC:%.3f, WT:%.3f]'%(avg_dices[0], avg_dices[1], avg_dices[2]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3M_BFs5f_Da",
        "outputId": "fa64ab0f-3733-4257-f16f-aa357e8286b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid sample: 66 valid minibatch: 33\n",
            "dice[ET:0.776, TC:0.826, WT:0.872]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method-3: Saving the prediction: excluding padding"
      ],
      "metadata": {
        "id": "TzDxoh9zd-ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from model import UNet3D\n",
        "from datasets import get_datasets_brats\n",
        "from utils import seed_everything, EDiceLoss\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import SimpleITK as sitk\n",
        "import random\n",
        "from glob import glob\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data._utils.collate import default_collate\n",
        "from datasets import custom_collate, determinist_collate, pad_batch_to_max_shape, \\\n",
        "pad_batch1_to_compatible_size, irm_min_max_preprocess, pad_or_crop_image\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description='SVLS Brats Training')\n",
        "parser.add_argument('--batch_size', default=1, type=int,help='mini-batch size')\n",
        "parser.add_argument('--num_classes', default=4, type=int, help=\"num of classes\")\n",
        "parser.add_argument('--in_channels', default=4, type=int, help=\"num of input channels\")\n",
        "parser.add_argument('--train_option', default='SVLS', help=\"options:[SVLS, LS, OH]\")\n",
        "parser.add_argument('--epochs', default=200, type=int, help='number of total epochs to run')\n",
        "parser.add_argument('--data_root', default='train_valid', help='data directory')\n",
        "parser.add_argument('--ckpt_dir', default='ckpt_brats19', help='ckpt directory')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "def get_datasets_brats(data_root=None, normalisation=\"zscore\"):\n",
        "\n",
        "    data_root = pathlib.Path(data_root)\n",
        "    base_folder_train = pathlib.Path('data/BraTS19/train_train/').resolve()\n",
        "    base_folder_valid = pathlib.Path('data/BraTS19/train_valid/').resolve()\n",
        "    patients_dir_train = sorted([data_root/x.name for x in base_folder_train.iterdir() if (data_root/x.name).is_dir()])\n",
        "    patients_dir_valid = sorted([data_root/x.name for x in base_folder_valid.iterdir() if (data_root/x.name).is_dir()])\n",
        "    train_dataset = brats19(patients_dir_train, training=True, normalisation=normalisation)\n",
        "    val_dataset = brats19(patients_dir_valid, training=False, normalisation=normalisation)\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "\n",
        "class brats19(Dataset):\n",
        "    def __init__(self, patients_dir, training=True, no_seg=False, normalisation=\"minmax\"):\n",
        "        super(brats19, self).__init__()\n",
        "        self.normalisation = normalisation\n",
        "        self.training = training\n",
        "        self.datas = []\n",
        "        self.validation = no_seg\n",
        "        self.patterns = [ \"_flair\", \"_t1\", \"_t1ce\", \"_t2\"]\n",
        "        # self.mean = dict(flair=0.0860377, t1=0.1216296, t1ce=0.07420689, t2=0.09033176)\n",
        "        self.mean = [0.0860377, 0.1216296, 0.07420689, 0.09033176]\n",
        "        if not no_seg:\n",
        "            self.patterns += [\"_seg\"]\n",
        "        for patient_dir in patients_dir:\n",
        "            patient_id = patient_dir.name\n",
        "            paths = [patient_dir / f\"{patient_id}{value}.nii.gz\" for value in self.patterns]\n",
        "            patient = dict(\n",
        "                id=patient_id, flair=paths[0], t1=paths[1], t1ce=paths[2],\n",
        "                t2=paths[3], seg=paths[4] if not no_seg else None\n",
        "            )\n",
        "            self.datas.append(patient)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        _patient = self.datas[idx]\n",
        "        patient_image = {key: self.load_nii(_patient[key]) for key in _patient if key not in [\"id\", \"seg\"]}\n",
        "        if _patient[\"seg\"] is not None:\n",
        "            patient_label = self.load_nii(_patient[\"seg\"])\n",
        "\n",
        "        # Remove maximum extent of the zero-background to make future crop more useful\n",
        "        patient_image = np.stack([patient_image[key] for key in patient_image])\n",
        "        z_indexes, y_indexes, x_indexes = np.nonzero(np.sum(patient_image, axis=0) != 0)\n",
        "\n",
        "        # Add 1 pixel in each side\n",
        "        zmin, ymin, xmin = [max(0, int(np.min(arr) - 1)) for arr in (z_indexes, y_indexes, x_indexes)]\n",
        "        zmax, ymax, xmax = [int(np.max(arr) + 1) for arr in (z_indexes, y_indexes, x_indexes)]\n",
        "        patient_image = [(irm_min_max_preprocess(patient_image[mod_idx]) - self.mean[mod_idx]) for mod_idx, key in enumerate(patient_image)]\n",
        "        patient_image = np.stack(patient_image)\n",
        "        patient_label[patient_label==4] = 3\n",
        "        patient_label = patient_label[None,:,:,:]\n",
        "        patient_image = patient_image[:, zmin:zmax, ymin:ymax, xmin:xmax]\n",
        "        patient_image, patient_label = patient_image.astype(\"float16\"), patient_label.astype(\"long\")\n",
        "        patient_image, patient_label = [torch.from_numpy(x) for x in [patient_image, patient_label]]\n",
        "        return dict(patient_id=_patient[\"id\"],\n",
        "                    image=patient_image, label=patient_label,\n",
        "                    seg_path=str(_patient[\"seg\"]),\n",
        "                    crop_indexes=((zmin, zmax), (ymin, ymax), (xmin, xmax)),\n",
        "                    )\n",
        "\n",
        "    @staticmethod\n",
        "    def load_nii(path_folder):\n",
        "        return sitk.GetArrayFromImage(sitk.ReadImage(str(path_folder)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datas)\n",
        "\n",
        "\n",
        "def save_prediction_to_mri(args, predictions, patient_ids):\n",
        "    os.makedirs('predicted_segs', exist_ok=True)\n",
        "    for idx, patient_id in enumerate(patient_ids):\n",
        "        path = os.path.join(args.data_root, patient_id, patient_id+'_t1.nii.gz')\n",
        "        img_original = nib.load(path)\n",
        "        img_nifti = nib.Nifti1Image(predictions[idx], img_original.affine, header=img_original.header)\n",
        "        nib.save(img_nifti,'predicted_segs/'+patient_id+'_pred.nii.gz') #not as expected\n",
        "\n",
        "_, val_dataset = get_datasets_brats(data_root=args.data_root)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\n",
        "    pin_memory=False, num_workers=2)\n",
        "\n",
        "print('valid sample:',len(val_dataset), 'valid minibatch:',len(val_loader))\n",
        "model = UNet3D(inplanes=args.in_channels, num_classes=args.num_classes).cuda()\n",
        "model = torch.nn.DataParallel(model)\n",
        "criterion_dice = EDiceLoss().cuda()\n",
        "model.load_state_dict(torch.load(os.path.join(args.ckpt_dir, 'best_oh.pth.tar')))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    metrics = []\n",
        "    for i, batch in enumerate(val_loader):\n",
        "        targets = batch[\"label\"].squeeze(1).cuda(non_blocking=True)\n",
        "        inputs = batch[\"image\"].float().cuda()\n",
        "        ((zmin, zmax), (ymin, ymax), (xmin, xmax)) = batch[\"crop_indexes\"]\n",
        "        ((zmin, zmax), (ymin, ymax), (xmin, xmax)) = ((zmin.item(), zmax.item()), (ymin.item(), ymax.item()), (xmin.item(), xmax.item()))\n",
        "        pred_full = torch.zeros(targets.shape)\n",
        "        preds = model(inputs)\n",
        "        preds = preds.data.max(1)[1].squeeze_(1)\n",
        "        if len(targets.shape) < 4:#if batch size=1\n",
        "            targets = targets.unsqueeze(0)\n",
        "\n",
        "        pred_full[:,zmin:zmax, ymin:ymax, xmin:xmax] = preds.cpu()\n",
        "        metric_ = criterion_dice.metric_brats(pred_full, targets.cpu())\n",
        "        metrics.extend(metric_)\n",
        "        pred_full = pred_full.permute(0,3,2,1).detach().cpu().numpy()\n",
        "        save_prediction_to_mri(args, pred_full, batch['patient_id'])\n",
        "\n",
        "    metrics = list(zip(*metrics))\n",
        "    metrics = [torch.tensor(dice, device=\"cpu\").numpy() for dice in metrics]\n",
        "    avg_dices = np.mean(metrics,1)\n",
        "\n",
        "print('dice[ET:%.3f, TC:%.3f, WT:%.3f]'%(avg_dices[0], avg_dices[1], avg_dices[2]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPAZ2Bk-cR01",
        "outputId": "9191abdd-855f-4aff-c3dd-efe9edbad764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid sample: 66 valid minibatch: 66\n",
            "dice[ET:0.788, TC:0.817, WT:0.860]\n"
          ]
        }
      ]
    }
  ]
}