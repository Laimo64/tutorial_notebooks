{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfWEZm0EqBoHmVKZsqtvbH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/VIsualBERT_VQA_COCO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VIsualBERT VQA COCO\n",
        "paper: https://arxiv.org/pdf/1908.03557.pdf <br>\n",
        "We use the VQA\n",
        "2.0 (Goyal et al., 2017), consisting of over 1 million questions about images from COCO. We train\n",
        "the model to predict the 3,129 most frequent answers and use image features from a ResNeXt-based\n",
        "Faster RCNN pre-trained on Visual Genome (Jiang et al., 2018)."
      ],
      "metadata": {
        "id": "hMWxfh0OQCRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For COCO pre-training, first download COCO caption annotations to a folder X_COCO."
      ],
      "metadata": {
        "id": "qJhc_CcSQXop"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EgS3HBJPs_K",
        "outputId": "59dd30cf-45be-43b3-855d-e439786ab514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/X_COCO\n",
            "--2023-02-05 01:47:50--  http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.220.193, 54.231.199.41, 52.217.229.137, ...\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.220.193|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252872794 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2014.zip’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.16M   101MB/s    in 2.4s    \n",
            "\n",
            "2023-02-05 01:47:53 (101 MB/s) - ‘annotations_trainval2014.zip’ saved [252872794/252872794]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir X_COCO\n",
        "%cd X_COCO\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
        "!unzip -q annotations_trainval2014.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then download COCO image features to X_COCO.<br> \n",
        "Train: https://drive.google.com/file/d/1F-LSQhpKleV4nmiKMjQvpHMS2gkbK3bY/view?usp=sharing <br> \n",
        "Val: https://drive.google.com/file/d/1cZjPob3YqfM46LaWY3-Ky12claxeXbWi/view?usp=sharing"
      ],
      "metadata": {
        "id": "8MXmqoplQoMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train: https://drive.google.com/file/d/1F-LSQhpKleV4nmiKMjQvpHMS2gkbK3bY/view?usp=sharing\n",
        "# Val: https://drive.google.com/file/d/1cZjPob3YqfM46LaWY3-Ky12claxeXbWi/view?usp=sharing\n",
        "\n",
        "#Option1:\n",
        "# import gdown\n",
        "# url = 'https://drive.google.com/uc?id=1F-LSQhpKleV4nmiKMjQvpHMS2gkbK3bY'\n",
        "# gdown.download(url,'coco_features_train_150.th ',quiet=True) \n",
        "\n",
        "#Option2:\n",
        "# !pip install -U -q PyDrive\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# # Authenticate and create the PyDrive client.\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)\n",
        "\n",
        "# id = ['1F-LSQhpKleV4nmiKMjQvpHMS2gkbK3bY']\n",
        "# downloaded = drive.CreateFile({'id':id[0]}) \n",
        "# downloaded.GetContentFile('coco_features_train_150.th')\n",
        "\n",
        "#Option3:\n",
        "!curl -L -s -o coco_features_train_150.th 'https://drive.google.com/uc?id=1F-LSQhpKleV4nmiKMjQvpHMS2gkbK3bY'\n",
        "!curl -L -s -o coco_features_val_150.th 'https://drive.google.com/uc?id=1cZjPob3YqfM46LaWY3-Ky12claxeXbWi'"
      ],
      "metadata": {
        "id": "Rs4aYi_OQgWd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare VQA Data\n",
        "The image features and VQA data are from Pythia. Assuming the data is stored in X_COCO.\n",
        "\n"
      ],
      "metadata": {
        "id": "osimKWMZR5yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "%cd data\n",
        "!wget https://dl.fbaipublicfiles.com/pythia/data/vocabulary_vqa.txt\n",
        "!wget https://dl.fbaipublicfiles.com/pythia/data/answers_vqa.txt\n",
        "!wget https://dl.fbaipublicfiles.com/pythia/data/imdb.tar.gz\n",
        "!gunzip -q imdb.tar.gz \n",
        "!tar -xf imdb.tar\n",
        "\n",
        "!wget https://dl.fbaipublicfiles.com/pythia/features/detectron_fix_100.tar.gz\n",
        "!gunzip -q detectron_fix_100.tar.gz\n",
        "!tar -xf detectron_fix_100.tar\n",
        "!rm -f detectron_fix_100.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBuxpFNtRYY6",
        "outputId": "23807ce5-10ee-42b0-8d96-333e2bd08e9d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/X_COCO/data\n",
            "--2023-02-05 02:02:23--  https://dl.fbaipublicfiles.com/pythia/data/vocabulary_vqa.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 142136 (139K) [text/plain]\n",
            "Saving to: ‘vocabulary_vqa.txt’\n",
            "\n",
            "vocabulary_vqa.txt  100%[===================>] 138.80K   580KB/s    in 0.2s    \n",
            "\n",
            "2023-02-05 02:02:24 (580 KB/s) - ‘vocabulary_vqa.txt’ saved [142136/142136]\n",
            "\n",
            "--2023-02-05 02:02:24--  https://dl.fbaipublicfiles.com/pythia/data/answers_vqa.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24768 (24K) [text/plain]\n",
            "Saving to: ‘answers_vqa.txt’\n",
            "\n",
            "answers_vqa.txt     100%[===================>]  24.19K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-02-05 02:02:24 (329 KB/s) - ‘answers_vqa.txt’ saved [24768/24768]\n",
            "\n",
            "--2023-02-05 02:02:25--  https://dl.fbaipublicfiles.com/pythia/data/imdb.tar.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 541765540 (517M) [application/gzip]\n",
            "Saving to: ‘imdb.tar.gz’\n",
            "\n",
            "imdb.tar.gz         100%[===================>] 516.67M  48.1MB/s    in 11s     \n",
            "\n",
            "2023-02-05 02:02:37 (45.3 MB/s) - ‘imdb.tar.gz’ saved [541765540/541765540]\n",
            "\n",
            "--2023-02-05 02:02:59--  https://dl.fbaipublicfiles.com/pythia/features/detectron_fix_100.tar.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 174625747710 (163G) [application/gzip]\n",
            "Saving to: ‘detectron_fix_100.tar.gz’\n",
            "\n",
            "detectron_fix_100.t  13%[=>                  ]  22.62G  45.1MB/s    eta 59m 15s^C\n",
            "^C\n",
            "tar: detectron_fix_100.tar: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download raw COCO images:"
      ],
      "metadata": {
        "id": "4Aw2wFSLUKsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://images.cocodataset.org/zips/train2014.zip\n",
        "!wget http://images.cocodataset.org/zips/val2014.zip\n",
        "!unzip -q train2014.zip\n",
        "!unzip -q val2014.zip"
      ],
      "metadata": {
        "id": "J025Ca7nSt9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "COCO VQA Datalaoder: https://github.com/uclanlp/visualbert/blob/master/visualbert/dataloaders/vqa_dataset.py <br>\n",
        "another1: https://github.com/Axe--/Visual-Question-Answering/blob/master/dataloader.py"
      ],
      "metadata": {
        "id": "hXGOp67hVgJd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xo7hLOjpVjWf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}