{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMRZJPyBnRbwTrVczediuMt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/MambaVision_HF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q timm mamba_ssm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngFfKrtdevfV",
        "outputId": "63ef0eb0-961f-43ea-dbe9-e8e6c53cfb4f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for mamba_ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification"
      ],
      "metadata": {
        "id": "YXLsOyV8rNYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "from PIL import Image\n",
        "from timm.data.transforms_factory import create_transform\n",
        "import requests\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\"nvidia/MambaVision-T-1K\", trust_remote_code=True)\n",
        "\n",
        "# eval mode for inference\n",
        "model.cuda().eval()\n",
        "\n",
        "# prepare image for the model\n",
        "url = 'http://images.cocodataset.org/val2017/000000020247.jpg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "input_resolution = (3, 224, 224)  # MambaVision supports any input resolutions\n",
        "\n",
        "transform = create_transform(input_size=input_resolution,\n",
        "                             is_training=False,\n",
        "                             mean=model.config.mean,\n",
        "                             std=model.config.std,\n",
        "                             crop_mode=model.config.crop_mode,\n",
        "                             crop_pct=model.config.crop_pct)\n",
        "\n",
        "inputs = transform(image).unsqueeze(0).cuda()\n",
        "# model inference\n",
        "outputs = model(inputs)\n",
        "logits = outputs['logits']\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6DKPogBPEpI",
        "outputId": "52e25658-ebdc-4aea-e1c7-12ed0db46963"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: brown bear, bruin, Ursus arctos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction:"
      ],
      "metadata": {
        "id": "72ZxRavzrPWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "from PIL import Image\n",
        "from timm.data.transforms_factory import create_transform\n",
        "import requests\n",
        "\n",
        "model = AutoModel.from_pretrained(\"nvidia/MambaVision-T-1K\", trust_remote_code=True)\n",
        "\n",
        "# eval mode for inference\n",
        "model.cuda().eval()\n",
        "\n",
        "# prepare image for the model\n",
        "url = 'http://images.cocodataset.org/val2017/000000020247.jpg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "input_resolution = (3, 224, 224)  # MambaVision supports any input resolutions\n",
        "\n",
        "transform = create_transform(input_size=input_resolution,\n",
        "                             is_training=False,\n",
        "                             mean=model.config.mean,\n",
        "                             std=model.config.std,\n",
        "                             crop_mode=model.config.crop_mode,\n",
        "                             crop_pct=model.config.crop_pct)\n",
        "inputs = transform(image).unsqueeze(0).cuda()\n",
        "# model inference\n",
        "out_avg_pool, features = model(inputs)\n",
        "print(\"Size of the averaged pool features:\", out_avg_pool.size())  # torch.Size([1, 640])\n",
        "print(\"Number of stages in extracted features:\", len(features)) # 4 stages\n",
        "print(\"Size of extracted features in stage 1:\", features[0].size()) # torch.Size([1, 80, 56, 56])\n",
        "print(\"Size of extracted features in stage 4:\", features[3].size()) # torch.Size([1, 640, 7, 7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtxCHTQ9rI2e",
        "outputId": "78dfaba8-8834-45b8-b68f-233550cef798"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the averaged pool features: torch.Size([1, 640])\n",
            "Number of stages in extracted features: 4\n",
            "Size of extracted features in stage 1: torch.Size([1, 80, 56, 56])\n",
            "Size of extracted features in stage 4: torch.Size([1, 640, 7, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HF Repo to edit code"
      ],
      "metadata": {
        "id": "97h28pCvrWsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/nvidia/MambaVision-T2-1K"
      ],
      "metadata": {
        "id": "gbRXSAqzPwrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b360765f-a63e-4858-df67-7f6d24f8a2fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MambaVision-T2-1K'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 47 (delta 18), reused 0 (delta 0), pack-reused 5 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (47/47), 40.05 KiB | 1000.00 KiB/s, done.\n"
          ]
        }
      ]
    }
  ]
}