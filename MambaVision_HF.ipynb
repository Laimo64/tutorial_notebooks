{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMjkql4nYPF7KSLjd3ZRcOT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/MambaVision_HF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q timm mamba_ssm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngFfKrtdevfV",
        "outputId": "7589fdec-5f5b-42b1-bc2e-670c2f8268f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for mamba_ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification"
      ],
      "metadata": {
        "id": "YXLsOyV8rNYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "from PIL import Image\n",
        "from timm.data.transforms_factory import create_transform\n",
        "import requests\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\"nvidia/MambaVision-T-1K\", trust_remote_code=True)\n",
        "\n",
        "# eval mode for inference\n",
        "model.cuda().eval()\n",
        "\n",
        "# prepare image for the model\n",
        "url = 'http://images.cocodataset.org/val2017/000000020247.jpg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "input_resolution = (3, 224, 224)  # MambaVision supports any input resolutions\n",
        "\n",
        "transform = create_transform(input_size=input_resolution,\n",
        "                             is_training=False,\n",
        "                             mean=model.config.mean,\n",
        "                             std=model.config.std,\n",
        "                             crop_mode=model.config.crop_mode,\n",
        "                             crop_pct=model.config.crop_pct)\n",
        "\n",
        "inputs = transform(image).unsqueeze(0).cuda()\n",
        "# model inference\n",
        "outputs = model(inputs)\n",
        "logits = outputs['logits']\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6DKPogBPEpI",
        "outputId": "6c84e038-bc47-4f14-a0a8-1de859ca3607"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: brown bear, bruin, Ursus arctos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "https://huggingface.co/"
      ],
      "metadata": {
        "id": "OrtL0HEc0O8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.load()"
      ],
      "metadata": {
        "id": "nPQWpNMrzrxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction:"
      ],
      "metadata": {
        "id": "72ZxRavzrPWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel\n",
        "from PIL import Image\n",
        "from timm.data.transforms_factory import create_transform\n",
        "import requests\n",
        "\n",
        "model = AutoModel.from_pretrained(\"nvidia/MambaVision-T-1K\", trust_remote_code=True)\n",
        "\n",
        "# eval mode for inference\n",
        "model.cuda().eval()\n",
        "\n",
        "# prepare image for the model\n",
        "url = 'http://images.cocodataset.org/val2017/000000020247.jpg'\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "input_resolution = (3, 224, 224)  # MambaVision supports any input resolutions\n",
        "\n",
        "transform = create_transform(input_size=input_resolution,\n",
        "                             is_training=False,\n",
        "                             mean=model.config.mean,\n",
        "                             std=model.config.std,\n",
        "                             crop_mode=model.config.crop_mode,\n",
        "                             crop_pct=model.config.crop_pct)\n",
        "inputs = transform(image).unsqueeze(0).cuda()\n",
        "# model inference\n",
        "out_avg_pool, features = model(inputs)\n",
        "print(\"Size of the averaged pool features:\", out_avg_pool.size())  # torch.Size([1, 640])\n",
        "print(\"Number of stages in extracted features:\", len(features)) # 4 stages\n",
        "print(\"Size of extracted features in stage 1:\", features[0].size()) # torch.Size([1, 80, 56, 56])\n",
        "print(\"Size of extracted features in stage 4:\", features[3].size()) # torch.Size([1, 640, 7, 7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtxCHTQ9rI2e",
        "outputId": "78dfaba8-8834-45b8-b68f-233550cef798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the averaged pool features: torch.Size([1, 640])\n",
            "Number of stages in extracted features: 4\n",
            "Size of extracted features in stage 1: torch.Size([1, 80, 56, 56])\n",
            "Size of extracted features in stage 4: torch.Size([1, 640, 7, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HF Repo to edit code"
      ],
      "metadata": {
        "id": "97h28pCvrWsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/nvidia/MambaVision-T2-1K"
      ],
      "metadata": {
        "id": "gbRXSAqzPwrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b360765f-a63e-4858-df67-7f6d24f8a2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MambaVision-T2-1K'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 47 (delta 18), reused 0 (delta 0), pack-reused 5 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (47/47), 40.05 KiB | 1000.00 KiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/OpenGVLab/VideoMamba"
      ],
      "metadata": {
        "id": "Xs-CdjFR0iE-",
        "outputId": "076f297e-5f44-4843-ff33-e73d9dac9729",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VideoMamba'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 80 (delta 5), reused 80 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (80/80), 13.95 KiB | 751.00 KiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/spaces/OpenGVLab/VideoMamba"
      ],
      "metadata": {
        "id": "iTJkq3ZG0o4E",
        "outputId": "9fdc8fc5-f8fb-4745-a03a-7fc78a7edd7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VideoMamba'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Counting objects: 100% (162/162), done.\u001b[K\n",
            "remote: Compressing objects: 100% (154/154), done.\u001b[K\n",
            "remote: Total 166 (delta 54), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Receiving objects: 100% (166/166), 2.82 MiB | 23.45 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q decord einops lm_eval packaging pytest setuptools timm wheel"
      ],
      "metadata": {
        "id": "w_C6gry-09-e",
        "outputId": "b37e8505-f31e-493f-90f7-386a2862ba5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd VideoMamba"
      ],
      "metadata": {
        "id": "tyCsq0hD1BHV",
        "outputId": "c6d076b9-d920-42c4-ce06-a2825485104d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VideoMamba\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from videomamba_video import VisionMamba, videomamba_tiny\n",
        "\n",
        "model = VisionMamba(\n",
        "        patch_size=16,\n",
        "        embed_dim=192,\n",
        "        depth=24,\n",
        "        rms_norm=True,\n",
        "        residual_in_fp32=True,\n",
        "        fused_add_norm=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "_rZDnnaM1Pgs",
        "outputId": "07470792-0bc0-4089-d8af-0ab9b2acec31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/selective_scan_interface.py:164: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/selective_scan_interface.py:240: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dout):\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/layer_norm.py:986: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1045: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dout, *args):\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/distributed/tensor_parallel.py:26: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, x, weight, bias, process_group=None, sequence_parallel=True):\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/distributed/tensor_parallel.py:62: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_output):\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:758: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float(\"inf\")), return_final_states=False, activation=\"silu\",\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:836: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dout, *args):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use checkpoint: False\n",
            "Checkpoint number: 0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "the first argument must be callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-bbaaf41aa082>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvideomamba_video\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisionMamba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideomamba_tiny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model = VisionMamba(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0membed_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m192\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/VideoMamba/videomamba_video.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_size, patch_size, depth, embed_dim, channels, num_classes, drop_rate, drop_path_rate, ssm_cfg, norm_epsilon, initializer_cfg, fused_add_norm, rms_norm, residual_in_fp32, bimamba, kernel_size, num_frames, fc_drop_rate, device, dtype, use_checkpoint, checkpoint_num)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# mamba blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         self.layers = nn.ModuleList(\n\u001b[0;32m--> 250\u001b[0;31m             [\n\u001b[0m\u001b[1;32m    251\u001b[0m                 create_block(\n\u001b[1;32m    252\u001b[0m                     \u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/VideoMamba/videomamba_video.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    249\u001b[0m         self.layers = nn.ModuleList(\n\u001b[1;32m    250\u001b[0m             [\n\u001b[0;32m--> 251\u001b[0;31m                 create_block(\n\u001b[0m\u001b[1;32m    252\u001b[0m                     \u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                     \u001b[0mssm_cfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mssm_cfg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/VideoMamba/videomamba_video.py\u001b[0m in \u001b[0;36mcreate_block\u001b[0;34m(d_model, ssm_cfg, norm_epsilon, drop_path, rms_norm, residual_in_fp32, fused_add_norm, layer_idx, bimamba, device, dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mssm_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mmixer_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMamba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbimamba\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbimamba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mssm_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mnorm_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrms_norm\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mRMSNorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm_epsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     block = Block(\n\u001b[1;32m    111\u001b[0m         \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: the first argument must be callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://huggingface.co/OpenGVLab/VideoMamba/resolve/main/videomamba_t16_ssv2_f8_res224.pth'\n",
        "checkpoint = torch.hub.load_state_dict_from_url(url, map_location='cpu', check_hash=True)"
      ],
      "metadata": {
        "id": "Ce1Y3AU41w4I",
        "outputId": "3b162bd4-9d19-4f87-d496-8502c87a9577",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://huggingface.co/OpenGVLab/VideoMamba/resolve/main/videomamba_t16_ssv2_f8_res224.pth\" to /root/.cache/torch/hub/checkpoints/videomamba_t16_ssv2_f8_res224.pth\n",
            "100%|██████████| 26.8M/26.8M [00:01<00:00, 24.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DuH8bESk6VzT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}