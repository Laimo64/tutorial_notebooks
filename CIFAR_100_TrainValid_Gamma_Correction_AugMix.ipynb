{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-100_TrainValid_Gamma_Correction_AugMix.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/CIFAR_100_TrainValid_Gamma_Correction_AugMix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gamma Correction as Augmentaion"
      ],
      "metadata": {
        "id": "SNxLCUzw3GNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############## Start Gamma Correction ############\n",
        "import torch\n",
        "import torchvision.transforms.functional as TF\n",
        "import numbers\n",
        "\n",
        "class GammaCorrectionTransform:\n",
        "    \"\"\"Apply Gamma Correction to the image\"\"\"\n",
        "    def __init__(self, gamma=0.5):\n",
        "        self.gamma = self._check_input(gamma, 'gammacorrection')   \n",
        "        \n",
        "    def _check_input(self, value, name, center=1, bound=(0, float('inf')), clip_first_on_zero=True):\n",
        "        if isinstance(value, numbers.Number):\n",
        "            if value < 0:\n",
        "                raise ValueError(\"If {} is a single number, it must be non negative.\".format(name))\n",
        "            value = [center - float(value), center + float(value)]\n",
        "            if clip_first_on_zero:\n",
        "                value[0] = max(value[0], 0.0)\n",
        "        elif isinstance(value, (tuple, list)) and len(value) == 2:\n",
        "            if not bound[0] <= value[0] <= value[1] <= bound[1]:\n",
        "                raise ValueError(\"{} values should be between {}\".format(name, bound))\n",
        "        else:\n",
        "            raise TypeError(\"{} should be a single number or a list/tuple with length 2.\".format(name))\n",
        "\n",
        "        # if value is 0 or (1., 1.) for gamma correction do nothing\n",
        "        if value[0] == value[1] == center:\n",
        "            value = None\n",
        "        return value\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (PIL Image or Tensor): Input image.\n",
        "\n",
        "        Returns:\n",
        "            PIL Image or Tensor: gamma corrected image.\n",
        "        \"\"\"\n",
        "        gamma_factor = None if self.gamma is None else float(torch.empty(1).uniform_(self.gamma[0], self.gamma[1]))\n",
        "        if gamma_factor is not None:\n",
        "            img = TF.adjust_gamma(img, gamma_factor, gain=1)\n",
        "        return img\n",
        "############## End Gamma Correction ############"
      ],
      "metadata": {
        "id": "QKSQpnzt3Kax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Start AugMix ###\n",
        "# Copyright 2019 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Base augmentations operators.\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageEnhance\n",
        "\n",
        "# ImageNet code should change this value\n",
        "IMAGE_SIZE = 32\n",
        "\n",
        "\n",
        "def int_parameter(level, maxval):\n",
        "  \"\"\"Helper function to scale `val` between 0 and maxval .\n",
        "\n",
        "  Args:\n",
        "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
        "    maxval: Maximum value that the operation can have. This will be scaled to\n",
        "      level/PARAMETER_MAX.\n",
        "\n",
        "  Returns:\n",
        "    An int that results from scaling `maxval` according to `level`.\n",
        "  \"\"\"\n",
        "  return int(level * maxval / 10)\n",
        "\n",
        "\n",
        "def float_parameter(level, maxval):\n",
        "  \"\"\"Helper function to scale `val` between 0 and maxval.\n",
        "\n",
        "  Args:\n",
        "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
        "    maxval: Maximum value that the operation can have. This will be scaled to\n",
        "      level/PARAMETER_MAX.\n",
        "\n",
        "  Returns:\n",
        "    A float that results from scaling `maxval` according to `level`.\n",
        "  \"\"\"\n",
        "  return float(level) * maxval / 10.\n",
        "\n",
        "\n",
        "def sample_level(n):\n",
        "  return np.random.uniform(low=0.1, high=n)\n",
        "\n",
        "\n",
        "def autocontrast(pil_img, _):\n",
        "  return ImageOps.autocontrast(pil_img)\n",
        "\n",
        "\n",
        "def equalize(pil_img, _):\n",
        "  return ImageOps.equalize(pil_img)\n",
        "\n",
        "\n",
        "def posterize(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), 4)\n",
        "  return ImageOps.posterize(pil_img, 4 - level)\n",
        "\n",
        "\n",
        "def rotate(pil_img, level):\n",
        "  degrees = int_parameter(sample_level(level), 30)\n",
        "  if np.random.uniform() > 0.5:\n",
        "    degrees = -degrees\n",
        "  return pil_img.rotate(degrees, resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def solarize(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), 256)\n",
        "  return ImageOps.solarize(pil_img, 256 - level)\n",
        "\n",
        "\n",
        "def shear_x(pil_img, level):\n",
        "  level = float_parameter(sample_level(level), 0.3)\n",
        "  if np.random.uniform() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                           Image.AFFINE, (1, level, 0, 0, 1, 0),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def shear_y(pil_img, level):\n",
        "  level = float_parameter(sample_level(level), 0.3)\n",
        "  if np.random.uniform() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                           Image.AFFINE, (1, 0, 0, level, 1, 0),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def translate_x(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n",
        "  if np.random.random() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                           Image.AFFINE, (1, 0, level, 0, 1, 0),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def translate_y(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n",
        "  if np.random.random() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                           Image.AFFINE, (1, 0, 0, 0, 1, level),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def color(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Color(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def contrast(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Contrast(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def brightness(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Brightness(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def sharpness(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Sharpness(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "augmentations = [\n",
        "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
        "    translate_x, translate_y\n",
        "]\n",
        "\n",
        "augmentations_all = [\n",
        "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
        "    translate_x, translate_y, color, contrast, brightness, sharpness\n",
        "]\n",
        "\n",
        "def aug(image, preprocess):\n",
        "  \"\"\"Perform AugMix augmentations and compute mixture.\n",
        "\n",
        "  Args:\n",
        "    image: PIL.Image input image\n",
        "    preprocess: Preprocessing function which should return a torch tensor.\n",
        "\n",
        "  Returns:\n",
        "    mixed: Augmented and mixed image.\n",
        "  \"\"\"\n",
        "  aug_list = augmentations\n",
        "  if args.all_ops == 'True':\n",
        "    aug_list = augmentations_all\n",
        "\n",
        "  ws = np.float32(np.random.dirichlet([1] * args.mixture_width))\n",
        "  m = np.float32(np.random.beta(1, 1))\n",
        "\n",
        "  mix = torch.zeros_like(preprocess(image))\n",
        "  for i in range(args.mixture_width):\n",
        "    image_aug = image.copy()\n",
        "    depth = args.mixture_depth if args.mixture_depth > 0 else np.random.randint(\n",
        "        1, 4)\n",
        "    for _ in range(depth):\n",
        "      op = np.random.choice(aug_list)\n",
        "      image_aug = op(image_aug, args.aug_severity)\n",
        "    # Preprocessing commutes since all coefficients are convex\n",
        "    mix += ws[i] * preprocess(image_aug)\n",
        "\n",
        "  mixed = (1 - m) * preprocess(image) + m * mix\n",
        "  return mixed\n",
        "\n",
        "\n",
        "class AugMixDataset(torch.utils.data.Dataset):\n",
        "  \"\"\"Dataset wrapper to perform AugMix augmentation.\"\"\"\n",
        "\n",
        "  def __init__(self, dataset, preprocess, no_jsd='True'):\n",
        "    self.dataset = dataset\n",
        "    self.preprocess = preprocess\n",
        "    self.no_jsd = no_jsd\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    x, y = self.dataset[i]\n",
        "    if self.no_jsd == 'True':\n",
        "      return aug(x, self.preprocess), y\n",
        "    else:\n",
        "      im_tuple = (self.preprocess(x), aug(x, self.preprocess),\n",
        "                  aug(x, self.preprocess))\n",
        "      return im_tuple, y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "### End AugMix ###"
      ],
      "metadata": {
        "id": "cm1bwjZPAgg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR-100 contains 500000 samples in training set. We split to 40000/10000 for train and validation."
      ],
      "metadata": {
        "id": "bCbkD5Nn-cGa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cl9-qEBSy8KO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import argparse\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "def seed_everything(seed=12):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "parser = argparse.ArgumentParser(description='CIFAR-10H Training')\n",
        "parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "parser.add_argument('--lr_schedule', default=0, type=int, help='lr scheduler')\n",
        "parser.add_argument('--batch_size', default=1024, type=int, help='batch size')\n",
        "parser.add_argument('--test_batch_size', default=2048, type=int, help='batch size')\n",
        "parser.add_argument('--num_epoch', default=100, type=int, help='epoch number')\n",
        "parser.add_argument('--num_classes', type=int, default=100, help='number classes')\n",
        "\n",
        "# AugMix #\n",
        "parser.add_argument('--augmix', default='True', type=str, help='Turn off JSD consistency loss.')\n",
        "parser.add_argument('--no-jsd', default='True', type=str, help='Turn off JSD consistency loss.')\n",
        "parser.add_argument('--all-ops', default='True', type=str, help='Turn on all operations (+brightness,contrast,color,sharpness).')\n",
        "parser.add_argument('--mixture-width', default=3, type=int, help='Number of augmentation chains to mix per augmented example')\n",
        "parser.add_argument('--mixture-depth', default=-1, type=int, help='Depth of augmentation chains. -1 denotes stochastic depth in [1, 3]')\n",
        "parser.add_argument('--aug-severity', default=3, type=int, help='Severity of base augmentation operators')\n",
        "############\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "def train(model, trainloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def test(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR-100 TrainValid Dataloader"
      ],
      "metadata": {
        "id": "J48533tD-_Cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class CIFAR100_TrainValid(torchvision.datasets.CIFAR100):\n",
        "\n",
        "    def __init__(self, root,  rand_number=0, istrain=True, train=True, transform=None, target_transform=None,\n",
        "                 download=False):\n",
        "        super(CIFAR100_TrainValid, self).__init__(root, train, transform, target_transform, download) \n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        if istrain:\n",
        "            self.data, self.targets = self.data[:40000], self.targets[:40000]\n",
        "            \n",
        "        else:\n",
        "            self.data, self.targets = self.data[40000:], self.targets[40000:]\n",
        "\n",
        "        hist = np.histogram(self.targets, bins=100, range=(0,100))[0]\n",
        "        print(hist)\n",
        "        #plt.hist(self.targets, bins='auto')\n",
        "        plt.bar(np.arange(len(hist)),hist)\n",
        "        plt.show()\n",
        "    def __getitem__(self, index: int):\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "        img = Image.fromarray(img)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "        return img, target"
      ],
      "metadata": {
        "id": "23p0uVBzzRFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "mean_cifar100, std_cifar100 = (0.5071, 0.4866, 0.4409), (0.2009, 0.1984, 0.2023)\n",
        "\n",
        "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomApply(transforms=[GammaCorrectionTransform(gamma=0.1)], p=0.5),\n",
        "            transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
        "            transforms.Normalize(mean_cifar100, std_cifar100), ])\n",
        "train_dataset = CIFAR100_TrainValid(root='./data', istrain=True, download=True, transform=transform_train)\n",
        "    \n",
        "transform_test = transforms.Compose([transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_cifar100, std_cifar100),])\n",
        "\n",
        "### Apply AugMix ###\n",
        "if args.augmix == 'True':\n",
        "    transform_train_augmix = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomApply(transforms=[GammaCorrectionTransform(gamma=0.1)], p=0.5),\n",
        "            transforms.RandomHorizontalFlip(),])\n",
        "    train_dataset = CIFAR100_TrainValid(root='./data', istrain=True, download=True, transform=transform_train_augmix)\n",
        "    preprocess = transform_test\n",
        "    train_dataset = AugMixDataset(train_dataset, preprocess, args.no_jsd) # Turn off JSD consistency loss\n",
        "#######################\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
        "test_dataset = CIFAR100_TrainValid(root='./data', istrain=False, download=True, transform=transform_train)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
        "print('train samples:',len(train_dataset), 'valid samples:',len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9d_jCBljzTOz",
        "outputId": "5c7568d4-09ca-449c-e680-a2b65d697820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "[397 387 402 398 389 391 404 391 423 398 374 398 398 393 415 393 414 408\n",
            " 413 416 398 409 412 396 395 386 396 398 382 390 391 413 417 412 409 401\n",
            " 401 390 408 391 409 396 410 413 396 394 394 388 399 403 388 395 383 389\n",
            " 415 396 398 396 413 414 416 414 399 402 402 408 413 411 406 410 405 417\n",
            " 412 398 395 394 395 395 408 394 387 408 395 401 391 397 389 405 393 405\n",
            " 392 386 414 405 384 392 386 386 398 406]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "[397 387 402 398 389 391 404 391 423 398 374 398 398 393 415 393 414 408\n",
            " 413 416 398 409 412 396 395 386 396 398 382 390 391 413 417 412 409 401\n",
            " 401 390 408 391 409 396 410 413 396 394 394 388 399 403 388 395 383 389\n",
            " 415 396 398 396 413 414 416 414 399 402 402 408 413 411 406 410 405 417\n",
            " 412 398 395 394 395 395 408 394 387 408 395 401 391 397 389 405 393 405\n",
            " 392 386 414 405 384 392 386 386 398 406]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "[103 113  98 102 111 109  96 109  77 102 126 102 102 107  85 107  86  92\n",
            "  87  84 102  91  88 104 105 114 104 102 118 110 109  87  83  88  91  99\n",
            "  99 110  92 109  91 104  90  87 104 106 106 112 101  97 112 105 117 111\n",
            "  85 104 102 104  87  86  84  86 101  98  98  92  87  89  94  90  95  83\n",
            "  88 102 105 106 105 105  92 106 113  92 105  99 109 103 111  95 107  95\n",
            " 108 114  86  95 116 108 114 114 102  94]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train samples: 40000 valid samples: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet34(pretrained=True).to(device)\n",
        "model.fc = nn.Linear(model.fc.in_features, args.num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, nesterov=False, weight_decay=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "best_epoch, best_acc = 0.0, 0\n",
        "for epoch in range(args.num_epoch):\n",
        "    train(model, train_loader, criterion, optimizer)\n",
        "    accuracy = test(model, test_loader)\n",
        "    if accuracy > best_acc:\n",
        "        patience = 0\n",
        "        best_acc = accuracy\n",
        "        best_epoch = epoch\n",
        "        best_model = copy.deepcopy(model)\n",
        "        torch.save(best_model.state_dict(), 'best_model_cifar10h.pth.tar')\n",
        "    print('epoch: {}  acc: {:.4f}  best epoch: {}  best acc: {:.4f}'.format(\n",
        "            epoch, accuracy, best_epoch, best_acc, optimizer.param_groups[0]['lr']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU9S-DVk7qEY",
        "outputId": "8c2af5ec-72ea-4b54-c059-86a1ee7c40b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0  acc: 0.0143  best epoch: 0  best acc: 0.0143\n",
            "epoch: 1  acc: 0.0134  best epoch: 0  best acc: 0.0143\n",
            "epoch: 2  acc: 0.0372  best epoch: 2  best acc: 0.0372\n",
            "epoch: 3  acc: 0.0636  best epoch: 3  best acc: 0.0636\n",
            "epoch: 4  acc: 0.0772  best epoch: 4  best acc: 0.0772\n",
            "epoch: 5  acc: 0.0904  best epoch: 5  best acc: 0.0904\n",
            "epoch: 6  acc: 0.0910  best epoch: 6  best acc: 0.0910\n",
            "epoch: 7  acc: 0.1091  best epoch: 7  best acc: 0.1091\n",
            "epoch: 8  acc: 0.1068  best epoch: 7  best acc: 0.1091\n",
            "epoch: 9  acc: 0.1215  best epoch: 9  best acc: 0.1215\n",
            "epoch: 10  acc: 0.1512  best epoch: 10  best acc: 0.1512\n",
            "epoch: 11  acc: 0.1655  best epoch: 11  best acc: 0.1655\n",
            "epoch: 12  acc: 0.1747  best epoch: 12  best acc: 0.1747\n",
            "epoch: 13  acc: 0.1698  best epoch: 12  best acc: 0.1747\n",
            "epoch: 14  acc: 0.1851  best epoch: 14  best acc: 0.1851\n",
            "epoch: 15  acc: 0.1918  best epoch: 15  best acc: 0.1918\n",
            "epoch: 16  acc: 0.1942  best epoch: 16  best acc: 0.1942\n",
            "epoch: 17  acc: 0.1760  best epoch: 16  best acc: 0.1942\n",
            "epoch: 18  acc: 0.2209  best epoch: 18  best acc: 0.2209\n",
            "epoch: 19  acc: 0.2116  best epoch: 18  best acc: 0.2209\n",
            "epoch: 20  acc: 0.2176  best epoch: 18  best acc: 0.2209\n",
            "epoch: 21  acc: 0.2375  best epoch: 21  best acc: 0.2375\n",
            "epoch: 22  acc: 0.2268  best epoch: 21  best acc: 0.2375\n",
            "epoch: 23  acc: 0.2509  best epoch: 23  best acc: 0.2509\n",
            "epoch: 24  acc: 0.2746  best epoch: 24  best acc: 0.2746\n",
            "epoch: 25  acc: 0.2626  best epoch: 24  best acc: 0.2746\n",
            "epoch: 26  acc: 0.2493  best epoch: 24  best acc: 0.2746\n",
            "epoch: 27  acc: 0.2732  best epoch: 24  best acc: 0.2746\n",
            "epoch: 28  acc: 0.2878  best epoch: 28  best acc: 0.2878\n",
            "epoch: 29  acc: 0.2943  best epoch: 29  best acc: 0.2943\n",
            "epoch: 30  acc: 0.2880  best epoch: 29  best acc: 0.2943\n",
            "epoch: 31  acc: 0.2800  best epoch: 29  best acc: 0.2943\n",
            "epoch: 32  acc: 0.2855  best epoch: 29  best acc: 0.2943\n",
            "epoch: 33  acc: 0.3070  best epoch: 33  best acc: 0.3070\n",
            "epoch: 34  acc: 0.3008  best epoch: 33  best acc: 0.3070\n",
            "epoch: 35  acc: 0.2974  best epoch: 33  best acc: 0.3070\n",
            "epoch: 36  acc: 0.3088  best epoch: 36  best acc: 0.3088\n",
            "epoch: 37  acc: 0.3274  best epoch: 37  best acc: 0.3274\n",
            "epoch: 38  acc: 0.3369  best epoch: 38  best acc: 0.3369\n",
            "epoch: 39  acc: 0.3398  best epoch: 39  best acc: 0.3398\n",
            "epoch: 40  acc: 0.3188  best epoch: 39  best acc: 0.3398\n",
            "epoch: 41  acc: 0.3177  best epoch: 39  best acc: 0.3398\n",
            "epoch: 42  acc: 0.3437  best epoch: 42  best acc: 0.3437\n",
            "epoch: 43  acc: 0.3488  best epoch: 43  best acc: 0.3488\n",
            "epoch: 44  acc: 0.3498  best epoch: 44  best acc: 0.3498\n",
            "epoch: 45  acc: 0.3573  best epoch: 45  best acc: 0.3573\n",
            "epoch: 46  acc: 0.3617  best epoch: 46  best acc: 0.3617\n",
            "epoch: 47  acc: 0.3615  best epoch: 46  best acc: 0.3617\n",
            "epoch: 48  acc: 0.3786  best epoch: 48  best acc: 0.3786\n",
            "epoch: 49  acc: 0.3755  best epoch: 48  best acc: 0.3786\n",
            "epoch: 50  acc: 0.3605  best epoch: 48  best acc: 0.3786\n",
            "epoch: 51  acc: 0.3851  best epoch: 51  best acc: 0.3851\n",
            "epoch: 52  acc: 0.3513  best epoch: 51  best acc: 0.3851\n",
            "epoch: 53  acc: 0.3912  best epoch: 53  best acc: 0.3912\n",
            "epoch: 54  acc: 0.3513  best epoch: 53  best acc: 0.3912\n",
            "epoch: 55  acc: 0.3954  best epoch: 55  best acc: 0.3954\n",
            "epoch: 56  acc: 0.3737  best epoch: 55  best acc: 0.3954\n",
            "epoch: 57  acc: 0.3699  best epoch: 55  best acc: 0.3954\n",
            "epoch: 58  acc: 0.3866  best epoch: 55  best acc: 0.3954\n",
            "epoch: 59  acc: 0.3802  best epoch: 55  best acc: 0.3954\n",
            "epoch: 60  acc: 0.3981  best epoch: 60  best acc: 0.3981\n",
            "epoch: 61  acc: 0.3635  best epoch: 60  best acc: 0.3981\n",
            "epoch: 62  acc: 0.3848  best epoch: 60  best acc: 0.3981\n",
            "epoch: 63  acc: 0.3999  best epoch: 63  best acc: 0.3999\n",
            "epoch: 64  acc: 0.3928  best epoch: 63  best acc: 0.3999\n",
            "epoch: 65  acc: 0.3906  best epoch: 63  best acc: 0.3999\n",
            "epoch: 66  acc: 0.3893  best epoch: 63  best acc: 0.3999\n",
            "epoch: 67  acc: 0.3914  best epoch: 63  best acc: 0.3999\n",
            "epoch: 68  acc: 0.3644  best epoch: 63  best acc: 0.3999\n",
            "epoch: 69  acc: 0.3960  best epoch: 63  best acc: 0.3999\n",
            "epoch: 70  acc: 0.3960  best epoch: 63  best acc: 0.3999\n",
            "epoch: 71  acc: 0.3913  best epoch: 63  best acc: 0.3999\n",
            "epoch: 72  acc: 0.4093  best epoch: 72  best acc: 0.4093\n",
            "epoch: 73  acc: 0.4081  best epoch: 72  best acc: 0.4093\n",
            "epoch: 74  acc: 0.4056  best epoch: 72  best acc: 0.4093\n",
            "epoch: 75  acc: 0.4045  best epoch: 72  best acc: 0.4093\n",
            "epoch: 76  acc: 0.4197  best epoch: 76  best acc: 0.4197\n",
            "epoch: 77  acc: 0.4072  best epoch: 76  best acc: 0.4197\n",
            "epoch: 78  acc: 0.4092  best epoch: 76  best acc: 0.4197\n",
            "epoch: 79  acc: 0.4213  best epoch: 79  best acc: 0.4213\n",
            "epoch: 80  acc: 0.3915  best epoch: 79  best acc: 0.4213\n",
            "epoch: 81  acc: 0.4187  best epoch: 79  best acc: 0.4213\n",
            "epoch: 82  acc: 0.3983  best epoch: 79  best acc: 0.4213\n",
            "epoch: 83  acc: 0.4171  best epoch: 79  best acc: 0.4213\n",
            "epoch: 84  acc: 0.4002  best epoch: 79  best acc: 0.4213\n",
            "epoch: 85  acc: 0.4057  best epoch: 79  best acc: 0.4213\n",
            "epoch: 86  acc: 0.4287  best epoch: 86  best acc: 0.4287\n",
            "epoch: 87  acc: 0.4102  best epoch: 86  best acc: 0.4287\n",
            "epoch: 88  acc: 0.4196  best epoch: 86  best acc: 0.4287\n",
            "epoch: 89  acc: 0.4215  best epoch: 86  best acc: 0.4287\n",
            "epoch: 90  acc: 0.4059  best epoch: 86  best acc: 0.4287\n",
            "epoch: 91  acc: 0.4004  best epoch: 86  best acc: 0.4287\n",
            "epoch: 92  acc: 0.4259  best epoch: 86  best acc: 0.4287\n",
            "epoch: 93  acc: 0.4313  best epoch: 93  best acc: 0.4313\n",
            "epoch: 94  acc: 0.4300  best epoch: 93  best acc: 0.4313\n",
            "epoch: 95  acc: 0.3614  best epoch: 93  best acc: 0.4313\n",
            "epoch: 96  acc: 0.3896  best epoch: 93  best acc: 0.4313\n",
            "epoch: 97  acc: 0.4004  best epoch: 93  best acc: 0.4313\n",
            "epoch: 98  acc: 0.4269  best epoch: 93  best acc: 0.4313\n",
            "epoch: 99  acc: 0.4321  best epoch: 99  best acc: 0.4321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XPW9TIDj-RWs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}