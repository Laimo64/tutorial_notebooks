{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VIT_ALL.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPzJ0mVa4YbtRboT8l7ZTdE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/VIT_ALL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sentence-transformers Vs transformers"
      ],
      "metadata": {
        "id": "gzE3UD4_g5Cq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sentence-transformers by UKPLab (To classify text)\n",
        "\n",
        "page: https://www.libhunt.com/r/sentence-transformers\n",
        "\n",
        "github: https://github.com/UKPLab/sentence-transformers"
      ],
      "metadata": {
        "id": "KD0JctxMgpa7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation"
      ],
      "metadata": {
        "id": "TX6pp1NrhCG_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PlNBV2LIggqG"
      },
      "outputs": [],
      "source": [
        "! pip -q install sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Feature Extraction"
      ],
      "metadata": {
        "id": "yfIaaE0whg-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "\n",
        "query = \"I ate dinner\"\n",
        "query_vec = sbert_model.encode([query])[0]\n",
        "print('Sample BERT embedding vector - length', len(query_vec))"
      ],
      "metadata": {
        "id": "QeDUDO8chHhH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## transformer by huggingface (ViT: To classify Image)\n",
        "page: https://www.libhunt.com/r/transformers\n",
        "\n",
        "Github: https://github.com/huggingface/transformers\n",
        "\n",
        "Installation"
      ],
      "metadata": {
        "id": "tZsvsAZgiq_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip -q install transformers"
      ],
      "metadata": {
        "id": "iUIFckHNin19"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torchvision\n",
        "\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification, BatchFeature\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor, Normalize, Resize, Compose\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import argparse\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "def seed_everything(seed=12):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "parser = argparse.ArgumentParser(description='CIFAR-10H Training')\n",
        "parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "parser.add_argument('--lr_schedule', default=0, type=int, help='lr scheduler')\n",
        "parser.add_argument('--batch_size', default=58, type=int, help='batch size')\n",
        "parser.add_argument('--test_batch_size', default=64, type=int, help='batch size')\n",
        "parser.add_argument('--num_epoch', default=2, type=int, help='epoch number')\n",
        "parser.add_argument('--num_classes', type=int, default=100, help='number classes')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "def train(model, trainloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs).logits\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Iter:',batch_idx,'/',len(trainloader), ' Loss:',loss.item())\n",
        "\n",
        "def test(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs).logits\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "class ViTFeatureExtractorTransforms:\n",
        "    def __init__(self, model_name_or_path):\n",
        "        feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)\n",
        "        transform = []\n",
        "\n",
        "        if feature_extractor.do_resize:\n",
        "            transform.append(Resize(feature_extractor.size))\n",
        "\n",
        "        transform.append(ToTensor())\n",
        "\n",
        "        if feature_extractor.do_normalize:\n",
        "            transform.append(Normalize(feature_extractor.image_mean, feature_extractor.image_std))\n",
        "\n",
        "        self.transform = Compose(transform)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.transform(x)\n",
        "\n",
        "\n",
        "def main():\n",
        "    seed_everything()\n",
        "    model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
        "    transform_vit = ViTFeatureExtractorTransforms(model_name_or_path)\n",
        "    train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_vit)\n",
        "    test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_vit)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,num_workers=2)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    model = ViTForImageClassification.from_pretrained(model_name_or_path, num_labels=args.num_classes)\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, nesterov=False, weight_decay=0.0001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    best_epoch, best_acc = 0.0, 0\n",
        "    for epoch in range(args.num_epoch):\n",
        "        train(model, train_loader, criterion, optimizer)\n",
        "        accuracy = test(model, test_loader)\n",
        "        if accuracy > best_acc:\n",
        "            patience = 0\n",
        "            best_acc = accuracy\n",
        "            best_epoch = epoch\n",
        "            best_model = copy.deepcopy(model)\n",
        "            torch.save(best_model.state_dict(), 'best_model_cifar10h_vit.pth.tar')\n",
        "        print('epoch: {}  acc: {:.4f}  best epoch: {}  best acc: {:.4f}'.format(\n",
        "                epoch, accuracy, best_epoch, best_acc, optimizer.param_groups[0]['lr']))\n",
        "        \n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7EwDUnTjB3I",
        "outputId": "9d8e25fb-7809-45d0-ea49-faa13828eb71"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
            "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter: 0 / 863  Loss: 4.627674579620361\n",
            "Iter: 100 / 863  Loss: 2.7157750129699707\n",
            "Iter: 200 / 863  Loss: 1.976897954940796\n",
            "Iter: 300 / 863  Loss: 2.129338264465332\n",
            "Iter: 400 / 863  Loss: 1.4080332517623901\n",
            "Iter: 500 / 863  Loss: 1.377852201461792\n",
            "Iter: 600 / 863  Loss: 1.5307177305221558\n",
            "Iter: 700 / 863  Loss: 1.1656787395477295\n",
            "Iter: 800 / 863  Loss: 1.4090977907180786\n",
            "epoch: 0  acc: 0.6377  best epoch: 0  best acc: 0.6377\n",
            "Iter: 0 / 863  Loss: 1.3454694747924805\n",
            "Iter: 100 / 863  Loss: 1.5767067670822144\n",
            "Iter: 200 / 863  Loss: 0.8645036220550537\n",
            "Iter: 300 / 863  Loss: 0.9081160426139832\n",
            "Iter: 400 / 863  Loss: 0.9121677875518799\n",
            "Iter: 500 / 863  Loss: 0.9224331974983215\n",
            "Iter: 600 / 863  Loss: 0.9078149199485779\n",
            "Iter: 700 / 863  Loss: 0.7008175253868103\n",
            "Iter: 800 / 863  Loss: 0.7572551965713501\n",
            "epoch: 1  acc: 0.7246  best epoch: 1  best acc: 0.7246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L8SrjJWmw93j"
      }
    }
  ]
}