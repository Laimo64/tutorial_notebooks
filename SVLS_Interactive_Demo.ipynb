{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SVLS_Interactive_Demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/SVLS_Interactive_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ5MCVytMBzZ"
      },
      "source": [
        "# Spatially Varying Label Smoothing: Capturing Uncertainty from Expert Annotations\n",
        "[Preprint](https://arxiv.org/pdf/2104.05788.pdf)\n",
        "[Code](https://github.com/mobarakol/SVLS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiSbpb1EwjnY"
      },
      "source": [
        "Downloading SVLS and Surface Dice codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFNfvBfdKsT7",
        "outputId": "0a60f71b-a7b3-485f-ee1b-74c6c1afdbd4"
      },
      "source": [
        "!rm -rf SVLS\n",
        "!git clone https://github.com/mobarakol/SVLS.git\n",
        "%cd SVLS\n",
        "!git clone https://github.com/deepmind/surface-distance.git\n",
        "!mv surface-distance surface_distance"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SVLS'...\n",
            "remote: Enumerating objects: 394, done.\u001b[K\n",
            "remote: Counting objects: 100% (394/394), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 394 (delta 348), reused 372 (delta 336), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (394/394), 66.33 KiB | 2.76 MiB/s, done.\n",
            "Resolving deltas: 100% (348/348), done.\n",
            "/content/SVLS\n",
            "Cloning into 'surface-distance'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 50 (delta 9), reused 9 (delta 8), pack-reused 35\u001b[K\n",
            "Unpacking objects: 100% (50/50), 38.18 KiB | 1.53 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZNhk4-Od3FR"
      },
      "source": [
        "Install require packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdbUhZNUd6kl",
        "outputId": "528f26fa-0759-492c-ccb7-baa8103ae0a0"
      },
      "source": [
        "!pip install -U -q SimpleITK"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBq96oSpM7Da"
      },
      "source": [
        "### Download Dataset and Trained Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keDB9x0yNH4J"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgGSo3tNNwaF"
      },
      "source": [
        "Trained Models: https://drive.google.com/file/d/1evE2VqBGdY-0VPB8OeArHMPdRXhWuxFm/view?usp=sharing <br>\n",
        "Validation Data: https://drive.google.com/file/d/1oZ9z-l9lBjKGNZCCTK819Z1ufwe90mg3/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhX7jTGxNxEr"
      },
      "source": [
        "ids = ['1evE2VqBGdY-0VPB8OeArHMPdRXhWuxFm', '1oZ9z-l9lBjKGNZCCTK819Z1ufwe90mg3']\n",
        "zip_files = ['ckpt_brats19.zip','train_valid.zip']\n",
        "for id, zip_file in zip(ids, zip_files):\n",
        "    downloaded = drive.CreateFile({'id':id})\n",
        "    downloaded.GetContentFile(zip_file)\n",
        "    !unzip -q $zip_file"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0PdKAYPWBx8"
      },
      "source": [
        "Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "ZkknSZEls29B",
        "outputId": "2f9b7c0e-1be9-47eb-d5e3-c8d4d9868c1f"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from model import UNet3D\n",
        "from datasets import get_datasets_brats\n",
        "from utils import seed_everything, EDiceLoss\n",
        "from calibration_metrics import ece_eval, tace_eval, reliability_diagram\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def step_valid(data_loader, model, metric):\n",
        "    ece_all, acc_all, conf_all, tace_all = [], [], [], []\n",
        "    losses, metrics, metrics_sd = [], [], []\n",
        "    model.eval()\n",
        "    for i, batch in enumerate(data_loader):\n",
        "        targets = batch[\"label\"].squeeze(1).cuda(non_blocking=True)\n",
        "        inputs = batch[\"image\"].float().cuda()\n",
        "        segs = model(inputs)\n",
        "        outputs = F.softmax(segs, dim=1).detach().cpu().numpy()\n",
        "        if len(targets.shape) < 4:#if batch size=1\n",
        "            targets = targets.unsqueeze(0)\n",
        "        labels = targets.detach().cpu().numpy()\n",
        "\n",
        "        ece, acc, conf, _ = ece_eval(outputs,labels)\n",
        "        tace, _, _, _ = tace_eval(outputs,labels)\n",
        "        ece_all.append(ece)\n",
        "        acc_all.append(acc)\n",
        "        conf_all.append(conf)\n",
        "        tace_all.append(tace)\n",
        "        segs = segs.data.max(1)[1].squeeze_(1)\n",
        "        metric_ = metric.metric_brats(segs, targets)\n",
        "        metrics_sd.extend(metric.get_surface_dice(segs.detach().cpu().numpy(), targets.detach().cpu().numpy()))\n",
        "        metrics.extend(metric_)\n",
        "\n",
        "    ece_avg = np.stack(ece_all).mean(0)\n",
        "    acc_avg = np.stack(acc_all).mean(0)\n",
        "    conf_avg = np.stack(conf_all).mean(0)\n",
        "    tace_avg = np.stack(tace_all).mean(0)\n",
        "    return metrics, metrics_sd, ece_avg, acc_avg, conf_avg, tace_avg\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='SVLS Brats Training')\n",
        "    parser.add_argument('--batch_size', default=2, type=int,help='mini-batch size')\n",
        "    parser.add_argument('--num_classes', default=4, type=int, help=\"num of classes\")\n",
        "    parser.add_argument('--in_channels', default=4, type=int, help=\"num of input channels\")\n",
        "    parser.add_argument('--train_option', default='SVLS', help=\"options:[SVLS, LS, OH]\")\n",
        "    parser.add_argument('--epochs', default=200, type=int, help='number of total epochs to run')\n",
        "    parser.add_argument('--data_root', default='train_valid', help='data directory')\n",
        "    parser.add_argument('--ckpt_dir', default='ckpt_brats19', help='ckpt directory')\n",
        "    args = parser.parse_args(args=[])\n",
        "\n",
        "    _, val_dataset = get_datasets_brats(data_root=args.data_root)\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\n",
        "        pin_memory=False, num_workers=2)\n",
        "\n",
        "    print('valid sample:',len(val_dataset), 'valid minibatch:',len(val_loader))\n",
        "\n",
        "    model = UNet3D(inplanes=args.in_channels, num_classes=args.num_classes).cuda()\n",
        "\n",
        "    model = torch.nn.DataParallel(model)\n",
        "    criterion_dice = EDiceLoss().cuda()\n",
        "\n",
        "    legends = ['OH', 'LS(0.1)', 'LS(0.2)', 'LS(0.3)', 'SVLS']\n",
        "    model_list = ['best_oh.pth.tar', 'best_ls0.1.pth.tar', 'best_ls0.2.pth.tar', 'best_ls0.3.pth.tar', 'best_svls.pth.tar']\n",
        "    for model_name, legend in zip(model_list, legends):\n",
        "        model.load_state_dict(torch.load(os.path.join(args.ckpt_dir, model_name)))\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            dice_metrics, metrics_sd, ece_avg, acc_avg, conf_avg, tace_avg = step_valid(val_loader, model, criterion_dice)\n",
        "        if legend != 'LS(0.3)':\n",
        "            reliability_diagram(conf_avg, acc_avg, legend=legend)\n",
        "        dice_metrics = list(zip(*dice_metrics))\n",
        "        dice_metrics = [torch.tensor(dice, device=\"cpu\").numpy() for dice in dice_metrics]\n",
        "        avg_dices = np.mean(dice_metrics,1)\n",
        "        avg_std = np.std(dice_metrics,1)\n",
        "\n",
        "        metrics_sd = list(zip(*metrics_sd))\n",
        "        metrics_sd = [torch.tensor(dice, device=\"cpu\").numpy() for dice in metrics_sd]\n",
        "        avg_sd = np.mean(metrics_sd,1)\n",
        "        avg_std_sd = np.std(metrics_sd,1)\n",
        "\n",
        "        print('model:%s , dice[ET:%.3f ± %.3f, TC:%.3f ± %.3f, WT:%.3f ± %.3f], ECE:%.4f, TACE:%.4f'%(\n",
        "            model_name, avg_dices[0],avg_std[0], avg_dices[1],avg_std[1], avg_dices[2],avg_std[2], ece_avg, tace_avg))\n",
        "\n",
        "        print('model:%s , Surface dice[ET:%.3f ± %.3f, TC:%.3f ± %.3f, WT:%.3f ± %.3f]'%(\n",
        "            model_name, avg_sd[0],avg_std_sd[0], avg_sd[1],avg_std_sd[1], avg_sd[2],avg_std_sd[2]))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    seed_everything()\n",
        "    main()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid sample: 66 valid minibatch: 33\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1675b9582942>\u001b[0m in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mseed_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-1675b9582942>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mdice_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_sd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mece_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtace_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_dice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlegend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'LS(0.3)'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mreliability_diagram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-1675b9582942>\u001b[0m in \u001b[0;36mstep_valid\u001b[0;34m(data_loader, model, metric)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mece\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mece_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mtace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtace_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mece_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mece\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0macc_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/SVLS/calibration_metrics.py\u001b[0m in \u001b[0;36mtace_eval\u001b[0;34m(preds, targets, n_bins, threshold, bg_cls)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mcur_class_conf_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_class_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtargets_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mtargets_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_class_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mtargets_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_class_conf_sorted\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mcur_class_conf_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur_class_conf_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_class_conf_sorted\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from model import UNet3D\n",
        "from datasets import get_datasets_brats\n",
        "from utils import seed_everything, EDiceLoss\n",
        "from calibration_metrics import ece_eval, tace_eval, reliability_diagram\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description='SVLS Brats Training')\n",
        "parser.add_argument('--batch_size', default=2, type=int,help='mini-batch size')\n",
        "parser.add_argument('--num_classes', default=4, type=int, help=\"num of classes\")\n",
        "parser.add_argument('--in_channels', default=4, type=int, help=\"num of input channels\")\n",
        "parser.add_argument('--train_option', default='SVLS', help=\"options:[SVLS, LS, OH]\")\n",
        "parser.add_argument('--epochs', default=200, type=int, help='number of total epochs to run')\n",
        "parser.add_argument('--data_root', default='train_valid', help='data directory')\n",
        "parser.add_argument('--ckpt_dir', default='ckpt_brats19', help='ckpt directory')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "_, val_dataset = get_datasets_brats(data_root=args.data_root)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\n",
        "    pin_memory=False, num_workers=2)\n",
        "\n",
        "print('valid sample:',len(val_dataset), 'valid minibatch:',len(val_loader))\n",
        "\n",
        "model = UNet3D(inplanes=args.in_channels, num_classes=args.num_classes).cuda()\n",
        "\n",
        "model = torch.nn.DataParallel(model)\n",
        "criterion_dice = EDiceLoss().cuda()\n",
        "\n",
        "model.load_state_dict(torch.load(os.path.join(args.ckpt_dir, 'best_oh.pth.tar')))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(val_loader):\n",
        "        targets = batch[\"label\"].squeeze(1).cuda(non_blocking=True)\n",
        "        inputs = batch[\"image\"].float().cuda()\n",
        "        print(inputs.shape)\n",
        "        segs = model(inputs)\n",
        "        outputs = F.softmax(segs, dim=1).detach().cpu().numpy()\n",
        "        if len(targets.shape) < 4:#if batch size=1\n",
        "            targets = targets.unsqueeze(0)\n",
        "        labels = targets.detach().cpu().numpy()\n",
        "        print(labels.shape)\n",
        "        break\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBAKCxNQT-7d",
        "outputId": "c6f5826d-22f6-4cce-82ef-cd2be3a4265d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid sample: 66 valid minibatch: 33\n",
            "torch.Size([2, 4, 128, 192, 192])\n",
            "(2, 128, 192, 192)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "from glob import glob\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data._utils.collate import default_collate\n",
        "from datasets import custom_collate, determinist_collate, pad_batch_to_max_shape, \\\n",
        "pad_batch1_to_compatible_size, irm_min_max_preprocess, pad_or_crop_image\n",
        "\n",
        "def get_datasets_brats(data_root=None, normalisation=\"zscore\"):\n",
        "\n",
        "    data_root = pathlib.Path(data_root)\n",
        "    base_folder_train = pathlib.Path('data/BraTS19/train_train/').resolve()\n",
        "    base_folder_valid = pathlib.Path('data/BraTS19/train_valid/').resolve()\n",
        "    patients_dir_train = sorted([data_root/x.name for x in base_folder_train.iterdir() if (data_root/x.name).is_dir()])\n",
        "    patients_dir_valid = sorted([data_root/x.name for x in base_folder_valid.iterdir() if (data_root/x.name).is_dir()])\n",
        "    train_dataset = brats19(patients_dir_train, training=True, normalisation=normalisation)\n",
        "    val_dataset = brats19(patients_dir_valid, training=False, normalisation=normalisation)\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "\n",
        "class brats19(Dataset):\n",
        "    def __init__(self, patients_dir, training=True, no_seg=False, normalisation=\"minmax\"):\n",
        "        super(brats19, self).__init__()\n",
        "        self.normalisation = normalisation\n",
        "        self.training = training\n",
        "        self.datas = []\n",
        "        self.validation = no_seg\n",
        "        self.patterns = [ \"_flair\", \"_t1\", \"_t1ce\", \"_t2\"]\n",
        "        self.mean = dict(flair=0.0860377, t1=0.1216296, t1ce=0.07420689, t2=0.09033176)\n",
        "        if not no_seg:\n",
        "            self.patterns += [\"_seg\"]\n",
        "        for patient_dir in patients_dir:\n",
        "            patient_id = patient_dir.name\n",
        "            paths = [patient_dir / f\"{patient_id}{value}.nii.gz\" for value in self.patterns]\n",
        "            patient = dict(\n",
        "                id=patient_id, flair=paths[0], t1=paths[1], t1ce=paths[2],\n",
        "                t2=paths[3], seg=paths[4] if not no_seg else None\n",
        "            )\n",
        "            self.datas.append(patient)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        _patient = self.datas[idx]\n",
        "        patient_image = {key: self.load_nii(_patient[key]) for key in _patient if key not in [\"id\", \"seg\"]}\n",
        "        if _patient[\"seg\"] is not None:\n",
        "            patient_label = self.load_nii(_patient[\"seg\"])\n",
        "\n",
        "        patient_image = {key: (irm_min_max_preprocess(patient_image[key]) - self.mean[key]) for key in patient_image}\n",
        "        patient_image = np.stack([patient_image[key] for key in patient_image])\n",
        "        patient_label[patient_label==4] = 3\n",
        "        patient_label = patient_label[None,:,:,:]\n",
        "        # Remove maximum extent of the zero-background to make future crop more useful\n",
        "        z_indexes, y_indexes, x_indexes = np.nonzero(np.sum(patient_image, axis=0) != 0)\n",
        "        # print(z_indexes, y_indexes, x_indexes)\n",
        "        # Add 1 pixel in each side\n",
        "        zmin, ymin, xmin = [max(0, int(np.min(arr) - 1)) for arr in (z_indexes, y_indexes, x_indexes)]\n",
        "        zmax, ymax, xmax = [int(np.max(arr) + 1) for arr in (z_indexes, y_indexes, x_indexes)]\n",
        "        # print(zmin, ymin, xmin, zmax, ymax, xmax)\n",
        "        # patient_image = patient_image[:, zmin:zmax, ymin:ymax, xmin:xmax]\n",
        "        # patient_label = patient_label[:, zmin:zmax, ymin:ymax, xmin:xmax]\n",
        "        # # default to 128, 192, 192\n",
        "        # patient_image, patient_label = pad_or_crop_image(patient_image, patient_label, target_size=(128, 192, 192))\n",
        "\n",
        "        patient_image, patient_label = patient_image.astype(\"float16\"), patient_label.astype(\"long\")\n",
        "        patient_image, patient_label = [torch.from_numpy(x) for x in [patient_image, patient_label]]\n",
        "        return dict(patient_id=_patient[\"id\"],\n",
        "                    image=patient_image, label=patient_label,\n",
        "                    seg_path=str(_patient[\"seg\"]),\n",
        "                    crop_indexes=((zmin, zmax), (ymin, ymax), (xmin, xmax)),\n",
        "                    )\n",
        "\n",
        "    @staticmethod\n",
        "    def load_nii(path_folder):\n",
        "        return sitk.GetArrayFromImage(sitk.ReadImage(str(path_folder)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datas)\n",
        "\n",
        "\n",
        "def save_prediction_to_mri(args, predictions, patient_ids):\n",
        "    os.makedirs('predicted_segs', exist_ok=True)\n",
        "    for idx, patient_id in enumerate(patient_ids):\n",
        "        path = os.path.join(args.data_root, patient_id, patient_id+'_t1.nii.gz')\n",
        "        img_original = nib.load(path)\n",
        "        img_nifti = nib.Nifti1Image(predictions[idx], img_original.affine, header=img_original.header)\n",
        "        nib.save(img_nifti,'predicted_segs/'+patient_id+'_pred.nii.gz') #not as expected\n",
        "\n",
        "_, val_dataset = get_datasets_brats(data_root=args.data_root)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\n",
        "    pin_memory=False, num_workers=2)\n",
        "\n",
        "print('valid sample:',len(val_dataset), 'valid minibatch:',len(val_loader))\n",
        "\n",
        "model = UNet3D(inplanes=args.in_channels, num_classes=args.num_classes).cuda()\n",
        "\n",
        "model = torch.nn.DataParallel(model)\n",
        "criterion_dice = EDiceLoss().cuda()\n",
        "\n",
        "model.load_state_dict(torch.load(os.path.join(args.ckpt_dir, 'best_oh.pth.tar')))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(val_loader):\n",
        "        targets = batch[\"label\"].squeeze(1).cuda(non_blocking=True)\n",
        "        inputs = batch[\"image\"].float().cuda()\n",
        "        print(inputs.shape)\n",
        "        preds = model(inputs)\n",
        "        preds = preds.data.max(1)[1].squeeze_(1)\n",
        "        preds = preds.detach().cpu().numpy()\n",
        "        save_prediction_to_mri(args, preds, batch['patient_id'])\n",
        "        print(outputs.shape)\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3M_BFs5f_Da",
        "outputId": "3a2e1d4f-9f8d-42a2-c44e-46d449e6c6a7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid sample: 66 valid minibatch: 33\n",
            "torch.Size([2, 4, 155, 240, 240])\n",
            "(2, 4, 155, 240, 240)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset1[0]['patient_id'], val_dataset[0]['crop_indexes']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQZqJQ0gUsFb",
        "outputId": "df4db1ba-1550-45e3-d17c-12d7320cd894"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0   0 ... 154 154 154] [  0   0   0 ... 239 239 239] [  0   1   2 ... 237 238 239]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('BraTS19_2013_0_1', ((0, 155), (0, 240), (0, 240)))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "|batch['crop_indexes'][0][0], batch['crop_indexes'][0][1],"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbVHVf1ZYcN8",
        "outputId": "742d87a9-a854-4157-8351-162ae03daf02"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 0]), tensor([155, 155]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch['crop_indexes'][0], batch['crop_indexes'][1],batch['crop_indexes'][2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ1XIUFjY-QZ",
        "outputId": "4d67c8d1-ce59-4cdd-bfed-444fb49200fe"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([tensor([0, 0]), tensor([155, 155])],\n",
              " [tensor([0, 0]), tensor([240, 240])],\n",
              " [tensor([0, 0]), tensor([240, 240])])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "img = nib.load(path)\n",
        "img_array = img.get_fdata()\n",
        "mri_mask = (img_array>0).astype(int)\n",
        "img_nifti = nib.Nifti1Image(mri_mask, img.affine, header=img.header)\n",
        "nib.save(img_nifti,'mask_nibabel.nii.gz') #not as expected"
      ],
      "metadata": {
        "id": "N63AJUu8aF4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args.data_root"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nEXqSHh4bqvI",
        "outputId": "16a1662f-902f-44d2-d2ab-691987684e5a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'train_valid'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls train_valid/BraTS19_2013_0_1/BraTS19_2013_0_1_t1.nii.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb5PMaFWbrDn",
        "outputId": "930092d8-c7da-4ee6-d66c-f70bf6d4b369"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BraTS19_2013_0_1_flair.nii.gz  BraTS19_2013_0_1_t1.nii.gz\n",
            "BraTS19_2013_0_1_seg.nii.gz    BraTS19_2013_0_1_t2.nii.gz\n",
            "BraTS19_2013_0_1_t1ce.nii.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import os\n",
        "path = os.path.join(args.data_root, batch['patient_id'][0], batch['patient_id'][0]+'_t1.nii.gz')\n",
        "path\n",
        "img = nib.load(path)"
      ],
      "metadata": {
        "id": "pvVzV8-WbtFr"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fqiwrvgcDy9",
        "outputId": "d9d829f8-3ef2-4fe2-fe3a-f59517ad9007"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(240, 240, 155)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oPAZ2Bk-cR01"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}