{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_TrustScore.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "58e40812e227465a8ae45411620f2177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_db1a90fae35c4101b6fe0af3228651d6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f6018e3ea7f14f9883ca653af676a006",
              "IPY_MODEL_6cba399a5e4e4d25a52ac6a49dfef54d",
              "IPY_MODEL_17d17c242d114fbd9e3d6d227fe2e81b"
            ]
          }
        },
        "db1a90fae35c4101b6fe0af3228651d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6018e3ea7f14f9883ca653af676a006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8eabb3afecd414d93839f8e2a6f7e38",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_397b51bc2db7470fb8069f1f6304520f"
          }
        },
        "6cba399a5e4e4d25a52ac6a49dfef54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8652fe24a5574ac7ad8c0553777a0e07",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bbf9911c256c4396aa7b98b9b9cb9f7f"
          }
        },
        "17d17c242d114fbd9e3d6d227fe2e81b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_406e6fdc8e644edd92675ab1184ed59b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 59022149.89it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eadffaebdf554a3a8143d1f8e75c7af3"
          }
        },
        "c8eabb3afecd414d93839f8e2a6f7e38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "397b51bc2db7470fb8069f1f6304520f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8652fe24a5574ac7ad8c0553777a0e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bbf9911c256c4396aa7b98b9b9cb9f7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "406e6fdc8e644edd92675ab1184ed59b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eadffaebdf554a3a8143d1f8e75c7af3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "789087e97f614ab5841704290ba5ff3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76b7d825c3e04d04ad331b521da890ee",
              "IPY_MODEL_d1f38fe1b6f547a6abc38a73b83cac9e",
              "IPY_MODEL_dc11fcb48c60428f926fd7cb7c7513b6"
            ],
            "layout": "IPY_MODEL_0e90dc3756fc44098c16ce92c6be18c0"
          }
        },
        "76b7d825c3e04d04ad331b521da890ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baae2f09a4eb43bc9b274cfa01e5f992",
            "placeholder": "​",
            "style": "IPY_MODEL_dcf69fd818c24b5c82a6c0b4dae70982",
            "value": ""
          }
        },
        "d1f38fe1b6f547a6abc38a73b83cac9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8612264791b4048945ce9b45a535d6e",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4b7aedaf8a24c9996243fa15cf0b8bb",
            "value": 170498071
          }
        },
        "dc11fcb48c60428f926fd7cb7c7513b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e0714e6df124b6aaaec74f8254acebc",
            "placeholder": "​",
            "style": "IPY_MODEL_86068294cec441579f7272b3728ed894",
            "value": " 170499072/? [00:05&lt;00:00, 27523976.70it/s]"
          }
        },
        "0e90dc3756fc44098c16ce92c6be18c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baae2f09a4eb43bc9b274cfa01e5f992": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcf69fd818c24b5c82a6c0b4dae70982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8612264791b4048945ce9b45a535d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4b7aedaf8a24c9996243fa15cf0b8bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e0714e6df124b6aaaec74f8254acebc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86068294cec441579f7272b3728ed894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/cifar10_TrustScore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ87J3fmDxjE"
      },
      "source": [
        "# CIFAR10:\n",
        "Original CIFAR10 [0: airplane, 1: automobile, 2: bird, 3: cat, 4: deer, 5: dog, 6: frog, 7: horse, 8: ship, 9: truck] <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny77mwOy5rwX"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import argparse\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "def seed_everything(seed=12):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "parser = argparse.ArgumentParser(description='BalancedLSF Training')\n",
        "parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "parser.add_argument('--lr_schedule', default=0, type=int, help='lr scheduler')\n",
        "parser.add_argument('--batch_size', default=1024, type=int, help='batch size')\n",
        "parser.add_argument('--test_batch_size', default=2048, type=int, help='batch size')\n",
        "parser.add_argument('--num_epoch', default=50, type=int, help='epoch number')\n",
        "parser.add_argument('--num_classes', type=int, default=10, help='number classes')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "def train(model, trainloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def test(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ9xCxgxhmsn"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "mean_cifar10, std_cifar10 = (0.5071, 0.4866, 0.4409), (0.2009, 0.1984, 0.2023)\n",
        "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
        "            transforms.Normalize(mean_cifar10, std_cifar10), ])\n",
        "transform_test = transforms.Compose([transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_cifar10, std_cifar10),])\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=2048, shuffle=False, num_workers=2)\n",
        "\n",
        "model = models.resnet18().to(device)\n",
        "model.fc = nn.Linear(model.fc.in_features, args.num_classes)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "789087e97f614ab5841704290ba5ff3c",
            "76b7d825c3e04d04ad331b521da890ee",
            "d1f38fe1b6f547a6abc38a73b83cac9e",
            "dc11fcb48c60428f926fd7cb7c7513b6",
            "0e90dc3756fc44098c16ce92c6be18c0",
            "baae2f09a4eb43bc9b274cfa01e5f992",
            "dcf69fd818c24b5c82a6c0b4dae70982",
            "a8612264791b4048945ce9b45a535d6e",
            "f4b7aedaf8a24c9996243fa15cf0b8bb",
            "6e0714e6df124b6aaaec74f8254acebc",
            "86068294cec441579f7272b3728ed894"
          ]
        },
        "id": "ylEr5myINLRG",
        "outputId": "7e7721af-bbe5-46ea-8179-4f504fd8f4bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "789087e97f614ab5841704290ba5ff3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## This cell can be ignored if you wanna use the trained weights from next cell"
      ],
      "metadata": {
        "id": "J3SzNoN6-n0y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "58e40812e227465a8ae45411620f2177",
            "db1a90fae35c4101b6fe0af3228651d6",
            "f6018e3ea7f14f9883ca653af676a006",
            "6cba399a5e4e4d25a52ac6a49dfef54d",
            "17d17c242d114fbd9e3d6d227fe2e81b",
            "c8eabb3afecd414d93839f8e2a6f7e38",
            "397b51bc2db7470fb8069f1f6304520f",
            "8652fe24a5574ac7ad8c0553777a0e07",
            "bbf9911c256c4396aa7b98b9b9cb9f7f",
            "406e6fdc8e644edd92675ab1184ed59b",
            "eadffaebdf554a3a8143d1f8e75c7af3"
          ]
        },
        "id": "wsei6ouF6IXy",
        "outputId": "f01165d8-44bc-424e-db0f-ba39e9e230f6"
      },
      "source": [
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, nesterov=False, weight_decay=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "best_epoch, best_acc = 0.0, 0\n",
        "for epoch in range(args.num_epoch):\n",
        "    train(model, train_loader, criterion, optimizer)\n",
        "    accuracy = test(model, test_loader)\n",
        "    if accuracy > best_acc:\n",
        "        patience = 0\n",
        "        best_acc = accuracy\n",
        "        best_epoch = epoch\n",
        "        best_model = copy.deepcopy(model)\n",
        "        torch.save(best_model.state_dict(), 'best_model_cifar10_lt.pth.tar')\n",
        "    print('epoch: {}  acc: {:.4f}  best epoch: {}  best acc: {:.4f}'.format(\n",
        "            epoch, accuracy, best_epoch, best_acc, optimizer.param_groups[0]['lr']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58e40812e227465a8ae45411620f2177",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0  acc: 0.3396  best epoch: 0  best acc: 0.3396\n",
            "epoch: 1  acc: 0.4535  best epoch: 1  best acc: 0.4535\n",
            "epoch: 2  acc: 0.4862  best epoch: 2  best acc: 0.4862\n",
            "epoch: 3  acc: 0.5457  best epoch: 3  best acc: 0.5457\n",
            "epoch: 4  acc: 0.5827  best epoch: 4  best acc: 0.5827\n",
            "epoch: 5  acc: 0.6101  best epoch: 5  best acc: 0.6101\n",
            "epoch: 6  acc: 0.6508  best epoch: 6  best acc: 0.6508\n",
            "epoch: 7  acc: 0.6524  best epoch: 7  best acc: 0.6524\n",
            "epoch: 8  acc: 0.6677  best epoch: 8  best acc: 0.6677\n",
            "epoch: 9  acc: 0.6693  best epoch: 9  best acc: 0.6693\n",
            "epoch: 10  acc: 0.6973  best epoch: 10  best acc: 0.6973\n",
            "epoch: 11  acc: 0.7084  best epoch: 11  best acc: 0.7084\n",
            "epoch: 12  acc: 0.7154  best epoch: 12  best acc: 0.7154\n",
            "epoch: 13  acc: 0.7101  best epoch: 12  best acc: 0.7154\n",
            "epoch: 14  acc: 0.7298  best epoch: 14  best acc: 0.7298\n",
            "epoch: 15  acc: 0.7326  best epoch: 15  best acc: 0.7326\n",
            "epoch: 16  acc: 0.7393  best epoch: 16  best acc: 0.7393\n",
            "epoch: 17  acc: 0.7389  best epoch: 16  best acc: 0.7393\n",
            "epoch: 18  acc: 0.7393  best epoch: 16  best acc: 0.7393\n",
            "epoch: 19  acc: 0.7548  best epoch: 19  best acc: 0.7548\n",
            "epoch: 20  acc: 0.7664  best epoch: 20  best acc: 0.7664\n",
            "epoch: 21  acc: 0.7456  best epoch: 20  best acc: 0.7664\n",
            "epoch: 22  acc: 0.7581  best epoch: 20  best acc: 0.7664\n",
            "epoch: 23  acc: 0.7631  best epoch: 20  best acc: 0.7664\n",
            "epoch: 24  acc: 0.7752  best epoch: 24  best acc: 0.7752\n",
            "epoch: 25  acc: 0.7567  best epoch: 24  best acc: 0.7752\n",
            "epoch: 26  acc: 0.7763  best epoch: 26  best acc: 0.7763\n",
            "epoch: 27  acc: 0.7649  best epoch: 26  best acc: 0.7763\n",
            "epoch: 28  acc: 0.7792  best epoch: 28  best acc: 0.7792\n",
            "epoch: 29  acc: 0.7814  best epoch: 29  best acc: 0.7814\n",
            "epoch: 30  acc: 0.7874  best epoch: 30  best acc: 0.7874\n",
            "epoch: 31  acc: 0.7860  best epoch: 30  best acc: 0.7874\n",
            "epoch: 32  acc: 0.7973  best epoch: 32  best acc: 0.7973\n",
            "epoch: 33  acc: 0.8004  best epoch: 33  best acc: 0.8004\n",
            "epoch: 34  acc: 0.7868  best epoch: 33  best acc: 0.8004\n",
            "epoch: 35  acc: 0.7937  best epoch: 33  best acc: 0.8004\n",
            "epoch: 36  acc: 0.7890  best epoch: 33  best acc: 0.8004\n",
            "epoch: 37  acc: 0.8013  best epoch: 37  best acc: 0.8013\n",
            "epoch: 38  acc: 0.7855  best epoch: 37  best acc: 0.8013\n",
            "epoch: 39  acc: 0.7969  best epoch: 37  best acc: 0.8013\n",
            "epoch: 40  acc: 0.7965  best epoch: 37  best acc: 0.8013\n",
            "epoch: 41  acc: 0.8008  best epoch: 37  best acc: 0.8013\n",
            "epoch: 42  acc: 0.8084  best epoch: 42  best acc: 0.8084\n",
            "epoch: 43  acc: 0.8013  best epoch: 42  best acc: 0.8084\n",
            "epoch: 44  acc: 0.7983  best epoch: 42  best acc: 0.8084\n",
            "epoch: 45  acc: 0.8069  best epoch: 42  best acc: 0.8084\n",
            "epoch: 46  acc: 0.8096  best epoch: 46  best acc: 0.8096\n",
            "epoch: 47  acc: 0.8034  best epoch: 46  best acc: 0.8096\n",
            "epoch: 48  acc: 0.7988  best epoch: 46  best acc: 0.8096\n",
            "epoch: 49  acc: 0.7968  best epoch: 46  best acc: 0.8096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download trained model"
      ],
      "metadata": {
        "id": "byghfr0qOBkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = ['1rDyWMpo1RYa9wFx5gZsXf_mHMwCTr2oz']\n",
        "downloaded = drive.CreateFile({'id':id[0]}) \n",
        "downloaded.GetContentFile('best_model_cifar10_lt.pth.tar')"
      ],
      "metadata": {
        "id": "FRUd5P0JOBBM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## confusion matrix: scratch"
      ],
      "metadata": {
        "id": "kWXG58TvNcUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def get_confusion_matrix(model, testloader):\n",
        "    model.eval()\n",
        "    confusion_matrix = torch.zeros(args.num_classes, args.num_classes)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    acc_per_class = torch.zeros(args.num_classes)\n",
        "    samples_per_class = torch.zeros(args.num_classes)\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            for t, p in zip(targets.view(-1), preds.view(-1)):\n",
        "                    confusion_matrix[t.long(), p.long()] += 1\n",
        "            \n",
        "            total += targets.size(0)\n",
        "            correct_matrix = preds.eq(targets)\n",
        "            correct += correct_matrix.sum().item()\n",
        "            for cls in range (args.num_classes):\n",
        "                acc_per_class[cls] += correct_matrix[targets==cls].sum().item()\n",
        "                samples_per_class[cls] += (targets==cls).sum().item()\n",
        "\n",
        "    return correct / total, confusion_matrix, acc_per_class/samples_per_class\n",
        "\n",
        "def get_tp_tn_fp_fn(conf_matrix, nb_classes):\n",
        "    TP = conf_matrix.diag()\n",
        "    for c in range(nb_classes):\n",
        "        idx = torch.ones(nb_classes).byte()\n",
        "        idx[c] = 0\n",
        "        # all non-class samples classified as non-class\n",
        "        TN = conf_matrix[idx.nonzero()[:, None], idx.nonzero()].sum() #conf_matrix[idx[:, None], idx].sum() - conf_matrix[idx, c].sum()\n",
        "        # all non-class samples classified as class\n",
        "        FP = conf_matrix[idx, c].sum()\n",
        "        # all class samples not classified as class\n",
        "        FN = conf_matrix[c, idx].sum()\n",
        "        \n",
        "        print('Class {}\\nTP {}, TN {}, FP {}, FN {}, acc={}, recall={}, prec={}, total= {}'.format(\n",
        "            c, TP[c], TN, FP, FN,(TP[c]+TN)/(TP[c]+TN+FP+FN), TP[c]/(TP[c]+FN), TP[c]/(TP[c]+FP), (TP[c]+TN+FP+FN) ))\n",
        "    \n",
        "\n",
        "model.load_state_dict(torch.load('best_model_cifar10_lt.pth.tar'))\n",
        "acc, confusion_matrix, acc_per_class = get_confusion_matrix(model, test_loader)\n",
        "print('confusion matrix:\\n', confusion_matrix)\n",
        "class_wise_acc = confusion_matrix.diag()/confusion_matrix.sum(1)\n",
        "print('per-class accuracy from CM:', class_wise_acc)\n",
        "print('per-class accuracy from scratch:', acc_per_class)\n",
        "print('accuracy-with CM:',class_wise_acc.mean(), ',directly:',acc)\n",
        "\n",
        "get_tp_tn_fp_fn(confusion_matrix, args.num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLHhlr2w_6jx",
        "outputId": "943c238d-665c-4e66-98c2-4843a4931e49"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix:\n",
            " tensor([[855.,   6.,  44.,  11.,   9.,   3.,   6.,   4.,  43.,  19.],\n",
            "        [ 22., 905.,   7.,   5.,   1.,   1.,   3.,   0.,  16.,  40.],\n",
            "        [ 28.,   1., 841.,  24.,  43.,  13.,  29.,   9.,   6.,   6.],\n",
            "        [ 20.,   3., 109., 666.,  33.,  65.,  49.,  28.,  10.,  17.],\n",
            "        [ 12.,   1.,  62.,  60., 752.,   8.,  45.,  53.,   5.,   2.],\n",
            "        [ 12.,   0.,  96., 203.,  33., 579.,  19.,  46.,   7.,   5.],\n",
            "        [  4.,   4.,  41.,  50.,  15.,   8., 870.,   3.,   3.,   2.],\n",
            "        [ 15.,   1.,  44.,  44.,  20.,  10.,   1., 848.,   6.,  11.],\n",
            "        [ 43.,  12.,   8.,   8.,   3.,   1.,   5.,   2., 908.,  10.],\n",
            "        [ 39.,  48.,   7.,   5.,   0.,   2.,   5.,   2.,  20., 872.]])\n",
            "per-class accuracy from CM: tensor([0.8550, 0.9050, 0.8410, 0.6660, 0.7520, 0.5790, 0.8700, 0.8480, 0.9080,\n",
            "        0.8720])\n",
            "per-class accuracy from scratch: tensor([0.8550, 0.9050, 0.8410, 0.6660, 0.7520, 0.5790, 0.8700, 0.8480, 0.9080,\n",
            "        0.8720])\n",
            "accuracy-with CM: tensor(0.8096) ,directly: 0.8096\n",
            "Class 0\n",
            "TP 855.0, TN 8805.0, FP 195.0, FN 145.0, acc=0.9660000205039978, recall=0.8550000190734863, prec=0.8142856955528259, total= 10000.0\n",
            "Class 1\n",
            "TP 905.0, TN 8924.0, FP 76.0, FN 95.0, acc=0.9829000234603882, recall=0.9049999713897705, prec=0.9225280284881592, total= 10000.0\n",
            "Class 2\n",
            "TP 841.0, TN 8582.0, FP 418.0, FN 159.0, acc=0.942300021648407, recall=0.8410000205039978, prec=0.6679904460906982, total= 10000.0\n",
            "Class 3\n",
            "TP 666.0, TN 8590.0, FP 410.0, FN 334.0, acc=0.925599992275238, recall=0.6660000085830688, prec=0.6189591288566589, total= 10000.0\n",
            "Class 4\n",
            "TP 752.0, TN 8843.0, FP 157.0, FN 248.0, acc=0.9595000147819519, recall=0.7519999742507935, prec=0.827282726764679, total= 10000.0\n",
            "Class 5\n",
            "TP 579.0, TN 8889.0, FP 111.0, FN 421.0, acc=0.9467999935150146, recall=0.5789999961853027, prec=0.8391304612159729, total= 10000.0\n",
            "Class 6\n",
            "TP 870.0, TN 8838.0, FP 162.0, FN 130.0, acc=0.97079998254776, recall=0.8700000047683716, prec=0.8430232405662537, total= 10000.0\n",
            "Class 7\n",
            "TP 848.0, TN 8853.0, FP 147.0, FN 152.0, acc=0.9700999855995178, recall=0.8479999899864197, prec=0.8522613048553467, total= 10000.0\n",
            "Class 8\n",
            "TP 908.0, TN 8884.0, FP 116.0, FN 92.0, acc=0.979200005531311, recall=0.9079999923706055, prec=0.88671875, total= 10000.0\n",
            "Class 9\n",
            "TP 872.0, TN 8888.0, FP 112.0, FN 128.0, acc=0.9760000109672546, recall=0.871999979019165, prec=0.8861788511276245, total= 10000.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:36: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:30.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TrustScore"
      ],
      "metadata": {
        "id": "ZXuzwbLggqlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import KDTree, KNeighborsClassifier\n",
        "\n",
        "\n",
        "class TrustScore:\n",
        "    \"\"\"\n",
        "    Trust Score: a measure of classifier uncertainty based on nearest neighbors.\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self, k=10, alpha=0.0, filtering=\"none\", min_dist=1e-12):\n",
        "        \"\"\"\n",
        "        k and alpha are the tuning parameters for the filtering,\n",
        "        filtering: method of filtering. option are \"none\", \"density\",\n",
        "        \"uncertainty\"\n",
        "        min_dist: some small number to mitigate possible division by 0.\n",
        "    \"\"\"\n",
        "        self.k = k\n",
        "        self.filtering = filtering\n",
        "        self.alpha = alpha\n",
        "        self.min_dist = min_dist\n",
        "\n",
        "    def filter_by_density(self, X: np.array):\n",
        "        \"\"\"Filter out points with low kNN density.\n",
        "    Args:\n",
        "    X: an array of sample points.\n",
        "    Returns:\n",
        "    A subset of the array without points in the bottom alpha-fraction of\n",
        "    original points of kNN density.\n",
        "    \"\"\"\n",
        "        kdtree = KDTree(X)\n",
        "        knn_radii = kdtree.query(X, k=self.k)[0][:, -1]\n",
        "        eps = np.percentile(knn_radii, (1 - self.alpha) * 100)\n",
        "        return X[np.where(knn_radii <= eps)[0], :]\n",
        "\n",
        "    def filter_by_uncertainty(self, X: np.array, y: np.array):\n",
        "        \"\"\"Filter out points with high label disagreement amongst its kNN neighbors.\n",
        "    Args:\n",
        "    X: an array of sample points.\n",
        "    Returns:\n",
        "    A subset of the array without points in the bottom alpha-fraction of\n",
        "    samples with highest disagreement amongst its k nearest neighbors.\n",
        "    \"\"\"\n",
        "        neigh = KNeighborsClassifier(n_neighbors=self.k)\n",
        "        neigh.fit(X, y)\n",
        "        confidence = neigh.predict_proba(X)\n",
        "        cutoff = np.percentile(confidence, self.alpha * 100)\n",
        "        unfiltered_idxs = np.where(confidence >= cutoff)[0]\n",
        "        return X[unfiltered_idxs, :], y[unfiltered_idxs]\n",
        "\n",
        "    def fit(self, X: np.array, y: np.array):\n",
        "        \"\"\"Initialize trust score precomputations with training data.\n",
        "    WARNING: assumes that the labels are 0-indexed (i.e.\n",
        "    0, 1,..., n_labels-1).\n",
        "    Args:\n",
        "    X: an array of sample points.\n",
        "    y: corresponding labels.\n",
        "    \"\"\"\n",
        "\n",
        "        self.n_labels = np.max(y) + 1\n",
        "        self.kdtrees = [None] * self.n_labels\n",
        "        if self.filtering == \"uncertainty\":\n",
        "            X_filtered, y_filtered = self.filter_by_uncertainty(X, y)\n",
        "        for label in range(self.n_labels):\n",
        "            if self.filtering == \"none\":\n",
        "                X_to_use = X[np.where(y == label)[0]]\n",
        "                self.kdtrees[label] = KDTree(X_to_use)\n",
        "            elif self.filtering == \"density\":\n",
        "                X_to_use = self.filter_by_density(X[np.where(y == label)[0]])\n",
        "                self.kdtrees[label] = KDTree(X_to_use)\n",
        "            elif self.filtering == \"uncertainty\":\n",
        "                X_to_use = X_filtered[np.where(y_filtered == label)[0]]\n",
        "                self.kdtrees[label] = KDTree(X_to_use)\n",
        "\n",
        "            if len(X_to_use) == 0:\n",
        "                print(\n",
        "                    \"Filtered too much or missing examples from a label! Please lower \"\n",
        "                    \"alpha or check data.\"\n",
        "                )\n",
        "\n",
        "    def get_score(self, X: np.array, y_pred: np.array):\n",
        "        \"\"\"Compute the trust scores.\n",
        "    Given a set of points, determines the distance to each class.\n",
        "    Args:\n",
        "    X: an array of sample points.\n",
        "    y_pred: The predicted labels for these points.\n",
        "    Returns:\n",
        "    The trust score, which is ratio of distance to closest class that was not\n",
        "    the predicted class to the distance to the predicted class.\n",
        "    \"\"\"\n",
        "        d = np.tile(None, (X.shape[0], self.n_labels))\n",
        "        for label_idx in range(self.n_labels):\n",
        "            d[:, label_idx] = self.kdtrees[label_idx].query(X, k=2)[0][:, -1]\n",
        "\n",
        "        sorted_d = np.sort(d, axis=1)\n",
        "        d_to_pred = d[range(d.shape[0]), y_pred]\n",
        "        d_to_closest_not_pred = np.where(\n",
        "            sorted_d[:, 0] != d_to_pred, sorted_d[:, 0], sorted_d[:, 1]\n",
        "        )\n",
        "        return d_to_closest_not_pred / (d_to_pred + self.min_dist)\n",
        "\n",
        "\n",
        "class KNNConfidence:\n",
        "    \"\"\"Baseline which uses disagreement to kNN classifier.\n",
        "  \"\"\"\n",
        "\n",
        "    def __init__(self, k=10):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.kdtree = KDTree(X)\n",
        "        self.y = y\n",
        "\n",
        "    def get_score(self, X, y_pred):\n",
        "        knn_idxs = self.kdtree.query(X, k=self.k)[1]\n",
        "        knn_outputs = self.y[knn_idxs]\n",
        "        return np.mean(\n",
        "            knn_outputs == np.transpose(np.tile(y_pred, (self.k, 1))), axis=1\n",
        "        )\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JtlgZtWGQr18"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate on trustscore (V1):"
      ],
      "metadata": {
        "id": "cmc5xUpyqNqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_trust_model(trust_model, testloader):\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs_array = np.array(inputs.view(inputs.shape[0], -1).cpu())\n",
        "            targets_array = np.array(targets.cpu())\n",
        "            trust_model.fit(inputs_array, targets_array)\n",
        "        \n",
        "    return trust_model\n",
        "\n",
        "def test_trust_score(model, trust_model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    trust_score_all = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            # ========= Get Trust Score ============ #\n",
        "            inputs_array = np.array(inputs.view(inputs.shape[0], -1).cpu())\n",
        "            predicted_array = np.array(predicted.cpu())\n",
        "            trust_score = trust_model.get_score(inputs_array, predicted_array)\n",
        "            trust_score_all.extend(trust_score)\n",
        "        \n",
        "        acc = correct / total \n",
        "    return acc, trust_score_all\n",
        "\n",
        "trust_model = TrustScore()\n",
        "trust_model = fit_trust_model(trust_model, test_loader)\n",
        "\n",
        "model.load_state_dict(torch.load('best_model_cifar10_lt.pth.tar'))\n",
        "acc, trust_score_all = test_trust_score(model, trust_model, test_loader)\n",
        "print('Accuracy:', acc)\n",
        "print('Trust Score for First 2 Samples:',trust_score_all[:2] )\n"
      ],
      "metadata": {
        "id": "niX10vjcmVdv",
        "outputId": "0c7eeed2-5eef-49e8-c016-a816860ab4fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8096\n",
            "Trust Score for First 2 Samples: [0.9062759867500153, 1.0645652828689323]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate on trustscore (V2):"
      ],
      "metadata": {
        "id": "scDZVZkXqW1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_processed(testloader):\n",
        "    with torch.no_grad():\n",
        "        inputs_array_all = []\n",
        "        targets_array_all = []\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs_array = np.array(inputs.view(inputs.shape[0], -1).cpu())\n",
        "            targets_array = np.array(targets.cpu())\n",
        "            inputs_array_all.extend(inputs_array)\n",
        "            targets_array_all.extend(targets_array)\n",
        "\n",
        "        return inputs_array_all, targets_array_all\n",
        "\n",
        "def test_trust_score(model, trust_model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    trust_score_all = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            # ========= Get Trust Score ============ #\n",
        "            inputs_array = np.array(inputs.view(inputs.shape[0], -1).cpu())\n",
        "            predicted_array = np.array(predicted.cpu())\n",
        "            trust_score = trust_model.get_score(inputs_array, predicted_array)\n",
        "            trust_score_all.extend(trust_score)\n",
        "        \n",
        "        acc = correct / total \n",
        "    return acc, trust_score_all\n",
        "\n",
        "\n",
        "trust_model = TrustScore()\n",
        "inputs_array_all, targets_array_all = get_data_processed(test_loader)\n",
        "print('Processed data:',np.array(inputs_array_all).shape, np.array(targets_array_all).shape)\n",
        "trust_model.fit(np.array(inputs_array_all), np.array(targets_array_all))\n",
        "\n",
        "model.load_state_dict(torch.load('best_model_cifar10_lt.pth.tar'))\n",
        "acc, trust_score_all = test_trust_score(model, trust_model, test_loader)\n",
        "print('Accuracy:', acc)\n",
        "print('Trust Score for First 2 Samples:',trust_score_all[:2] )"
      ],
      "metadata": {
        "id": "xdmLgU3mqfPD",
        "outputId": "b2d16414-6a1e-4087-fe27-6f40b494d529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed data: (10000, 3072) (10000,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8096\n",
            "Trust Score for First 2 Samples: [0.9431595669648173, 1.2162421698977732]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate on trustscore (V3):"
      ],
      "metadata": {
        "id": "3Kj0XlpHhGcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('best_model_cifar10_lt.pth.tar'))\n",
        "trust_model = TrustScore()\n",
        "trust_score_all = []\n",
        "\n",
        "def test_trust_score(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            \n",
        "            # ========= Get Trust Score ============ #\n",
        "            # prepare array format\n",
        "            inputs_array = np.array(inputs.view(inputs.shape[0], -1).cpu())\n",
        "            predicted_array = np.array(predicted.cpu())\n",
        "            targets_array = np.array(targets.cpu())\n",
        "  \n",
        "            trust_model.fit(inputs_array, targets_array)\n",
        "            # Compute trusts score, given (unlabeled) testing examples and (hard) model predictions.\n",
        "            #print(inputs_array.shape, predicted_array.shape)\n",
        "            trust_score = trust_model.get_score(inputs_array, predicted_array)\n",
        "            #print('trust_score of one-batch data', trust_score)\n",
        "            trust_score_all.extend(trust_score)\n",
        "            # ========================================= #\n",
        "    return correct / total, trust_score\n",
        "acc, trust_score_all = test_trust_score(model, test_loader)\n",
        "print('Accuracy:', acc)\n",
        "print('Trust Score for First 2 Samples:',trust_score_all[:2] )"
      ],
      "metadata": {
        "id": "ynksggXFhEqZ",
        "outputId": "b3caabd9-a97d-4d23-ea08-769f81df006a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8096\n",
            "Trust Score for First 2 Samples: [1.0244807582711073 1.0753678777737252]\n"
          ]
        }
      ]
    }
  ]
}