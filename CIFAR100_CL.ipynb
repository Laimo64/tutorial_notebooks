{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR100_CL.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMbBwShOhQD1d0yC8smf07h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c81b351d09f44b6c99ba433c324a63dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b36ac3996acd4382a2fc207b86e1b3ec",
              "IPY_MODEL_24a8fc093be64a2aa24782582aaac688",
              "IPY_MODEL_e3d2086546804719843839b5017ece4b"
            ],
            "layout": "IPY_MODEL_40557c3bee5c47ef8a2396c3c21e66b8"
          }
        },
        "b36ac3996acd4382a2fc207b86e1b3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ac191f76fa6484c889c6f8631668fde",
            "placeholder": "​",
            "style": "IPY_MODEL_aa8923e65d92489091ae3ffc1d15c9fe",
            "value": "100%"
          }
        },
        "24a8fc093be64a2aa24782582aaac688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1198a7daed534a1697cac650198189db",
            "max": 169001437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8554d08f70354914a342b3bee79f47b5",
            "value": 169001437
          }
        },
        "e3d2086546804719843839b5017ece4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f81c45f314ee4d389b844caa2362ec8e",
            "placeholder": "​",
            "style": "IPY_MODEL_eec730372ae64425a02d62dd118ce773",
            "value": " 169001437/169001437 [00:01&lt;00:00, 104733600.14it/s]"
          }
        },
        "40557c3bee5c47ef8a2396c3c21e66b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac191f76fa6484c889c6f8631668fde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa8923e65d92489091ae3ffc1d15c9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1198a7daed534a1697cac650198189db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8554d08f70354914a342b3bee79f47b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f81c45f314ee4d389b844caa2362ec8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eec730372ae64425a02d62dd118ce773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f61f621de2ce420abdaabd24f9296a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a4c7ca9559d4ffa9191fdc64dc55520",
              "IPY_MODEL_69d39e5b3c6b4620bf0d857e6d743343",
              "IPY_MODEL_af44274a419b4924aeb2cdcd50251268"
            ],
            "layout": "IPY_MODEL_60208e88d71d45d39f08b5b9cef1c4d5"
          }
        },
        "5a4c7ca9559d4ffa9191fdc64dc55520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deacc33ec6624596b960751de534a122",
            "placeholder": "​",
            "style": "IPY_MODEL_cef915a44d8b4344bb7924c2497c62d5",
            "value": "100%"
          }
        },
        "69d39e5b3c6b4620bf0d857e6d743343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19ade0ab5c16494d950453e15496769b",
            "max": 87319819,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_265c7ef52af644448e511354afda1488",
            "value": 87319819
          }
        },
        "af44274a419b4924aeb2cdcd50251268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2b4f994c64142aeb6dc434531cef161",
            "placeholder": "​",
            "style": "IPY_MODEL_7d593ffd92934bad8015a40769ae5c88",
            "value": " 83.3M/83.3M [00:00&lt;00:00, 174MB/s]"
          }
        },
        "60208e88d71d45d39f08b5b9cef1c4d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deacc33ec6624596b960751de534a122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cef915a44d8b4344bb7924c2497c62d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19ade0ab5c16494d950453e15496769b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "265c7ef52af644448e511354afda1488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2b4f994c64142aeb6dc434531cef161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d593ffd92934bad8015a40769ae5c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/CIFAR100_CL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training on Split"
      ],
      "metadata": {
        "id": "P4P-ayaFVd5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import copy \n",
        "import os\n",
        "import argparse\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def seed_everything(seed=12):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser(description='CIFAR-10H Training')\n",
        "    parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "    parser.add_argument('--lr_schedule', default=0, type=int, help='lr scheduler')\n",
        "    parser.add_argument('--batch_size', default=256, type=int, help='batch size')\n",
        "    parser.add_argument('--test_batch_size', default=2048, type=int, help='batch size')\n",
        "    parser.add_argument('--num_epoch', default=200, type=int, help='epoch number')\n",
        "    parser.add_argument('--num_classes', type=int, default=100, help='number classes')\n",
        "    parser.add_argument('-warm', type=int, default=1, help='warm up training phase')\n",
        "    #Hyperparameters for CL\n",
        "    parser.add_argument('--init_ratio', default=0.80, type=float, help='initial data ratio')\n",
        "    parser.add_argument('--end_epoch', default=10, type=float, help='End epoch')\n",
        "    if 'ipykernel' in sys.modules:\n",
        "        args = parser.parse_args([])\n",
        "    else:\n",
        "        args = parser.parse_args()\n",
        "\n",
        "    return args\n",
        "\n",
        "def train(model, trainloader, criterion, optimizer, epoch, warm, warmup_scheduler):\n",
        "    model.train()\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch <= warm:\n",
        "            warmup_scheduler.step()\n",
        "\n",
        "def test(model, testloader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "class WarmUpLR(_LRScheduler):\n",
        "    \"\"\"\n",
        "        optimizer: optimzier(e.g. SGD)\n",
        "        total_iters: totoal_iters of warmup phase\n",
        "    \"\"\"\n",
        "    def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
        "\n",
        "        self.total_iters = total_iters\n",
        "        super().__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]\n",
        "\n",
        "class CELossWithLS(torch.nn.Module):\n",
        "    def __init__(self, classes=None, ls_factor=0.1, ignore_index=-1):\n",
        "        super(CELossWithLS, self).__init__()\n",
        "        self.ls_factor = ls_factor\n",
        "        self.complement = 1.0 - self.ls_factor\n",
        "        self.cls = classes\n",
        "        self.log_softmax = torch.nn.LogSoftmax(dim=1)\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, logits, target):\n",
        "        with torch.no_grad():\n",
        "            oh_labels = F.one_hot(target.to(torch.int64), num_classes = self.cls).contiguous()\n",
        "            smoothen_ohlabel = oh_labels * self.complement + self.ls_factor / self.cls\n",
        "        logs = self.log_softmax(logits[target!=self.ignore_index])\n",
        "        return -torch.sum(logs * smoothen_ohlabel[target!=self.ignore_index], dim=1).mean()\n",
        "\n",
        "class CIFAR100_TrainValid(torchvision.datasets.CIFAR100):\n",
        "\n",
        "    def __init__(self, root, istrain=True, train=True, transform=None,\n",
        "                 download=False):\n",
        "        super(CIFAR100_TrainValid, self).__init__(root=root, train=train, download=download, transform=transform) \n",
        "        self.transform = transform\n",
        "        if istrain:\n",
        "            self.data, self.targets = self.data[:40000], self.targets[:40000]            \n",
        "        else:\n",
        "            self.data, self.targets = self.data[40000:], self.targets[40000:]\n",
        "\n",
        "        #hist = np.histogram(self.targets, bins=100, range=(0,100))[0]\n",
        "        # plt.bar(np.arange(len(hist)),hist)\n",
        "        # plt.savefig('cifar100_train_{}.png'.format(int(train)))\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "        img = Image.fromarray(img)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, target\n",
        "\n",
        "\n",
        "def main():\n",
        "    seed_everything()\n",
        "    args = get_args()\n",
        "    mean_cifar100, std_cifar100 = (0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)\n",
        "    transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "                transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
        "                transforms.Normalize(mean_cifar100, std_cifar100), ])\n",
        "    transform_test = transforms.Compose([transforms.ToTensor(),\n",
        "        transforms.Normalize(mean_cifar100, std_cifar100),])\n",
        "\n",
        "    # train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "    # test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "    train_dataset = CIFAR100_TrainValid(root='./data', istrain=True, download=True, transform=transform_train)\n",
        "    test_dataset = CIFAR100_TrainValid(root='./data', istrain=False, download=True, transform=transform_test)\n",
        "\n",
        "    train_loader_split = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,num_workers=2)\n",
        "    test_loader_split = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
        "    \n",
        "    model = models.resnet34(pretrained=True).to(device)\n",
        "\n",
        "    #Modify the pre-existing Resnet architecture from TorchVision. The pre-existing architecture is based on ImageNet \n",
        "    #images (224x224) as input. So we need to modify it for CIFAR10 images (32x32).\n",
        "    model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, args.num_classes)\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n",
        "    #criterion = nn.CrossEntropyLoss()\n",
        "    criterion = CELossWithLS(classes=args.num_classes, ls_factor=0.1)\n",
        "    train_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.2) #learning rate decay\n",
        "    iter_per_epoch = len(train_loader_split)\n",
        "    warmup_scheduler = WarmUpLR(optimizer, iter_per_epoch * args.warm)\n",
        "\n",
        "    best_epoch, best_acc = 0.0, 0\n",
        "    for epoch in range(1, args.num_epoch + 1):\n",
        "        if epoch > args.warm:\n",
        "            train_scheduler.step()\n",
        "        train(model, train_loader_split, criterion, optimizer, epoch, args.warm, warmup_scheduler)\n",
        "        accuracy = test(model, test_loader_split)\n",
        "        if accuracy > best_acc:\n",
        "            best_acc = accuracy\n",
        "            best_epoch = epoch\n",
        "            torch.save(model.state_dict(), 'best_model_cifar100.pth.tar')\n",
        "        print('epoch: {}  acc: {:.4f}  best epoch: {}  best acc: {:.4f}, lr: {:.4f}'.format(\n",
        "                epoch, accuracy, best_epoch, best_acc, optimizer.param_groups[0]['lr']))"
      ],
      "metadata": {
        "id": "UW-6tgcv72nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c81b351d09f44b6c99ba433c324a63dd",
            "b36ac3996acd4382a2fc207b86e1b3ec",
            "24a8fc093be64a2aa24782582aaac688",
            "e3d2086546804719843839b5017ece4b",
            "40557c3bee5c47ef8a2396c3c21e66b8",
            "9ac191f76fa6484c889c6f8631668fde",
            "aa8923e65d92489091ae3ffc1d15c9fe",
            "1198a7daed534a1697cac650198189db",
            "8554d08f70354914a342b3bee79f47b5",
            "f81c45f314ee4d389b844caa2362ec8e",
            "eec730372ae64425a02d62dd118ce773",
            "f61f621de2ce420abdaabd24f9296a6e",
            "5a4c7ca9559d4ffa9191fdc64dc55520",
            "69d39e5b3c6b4620bf0d857e6d743343",
            "af44274a419b4924aeb2cdcd50251268",
            "60208e88d71d45d39f08b5b9cef1c4d5",
            "deacc33ec6624596b960751de534a122",
            "cef915a44d8b4344bb7924c2497c62d5",
            "19ade0ab5c16494d950453e15496769b",
            "265c7ef52af644448e511354afda1488",
            "b2b4f994c64142aeb6dc434531cef161",
            "7d593ffd92934bad8015a40769ae5c88"
          ]
        },
        "id": "-yc5ryfm4Fwf",
        "outputId": "c81a971d-151f-4f50-df02-ba55261615da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/169001437 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c81b351d09f44b6c99ba433c324a63dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f61f621de2ce420abdaabd24f9296a6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1  acc: 0.1897  best epoch: 1  best acc: 0.1897, lr: 0.1000\n",
            "epoch: 2  acc: 0.3442  best epoch: 2  best acc: 0.3442, lr: 0.1000\n",
            "epoch: 3  acc: 0.4179  best epoch: 3  best acc: 0.4179, lr: 0.1000\n",
            "epoch: 4  acc: 0.1029  best epoch: 3  best acc: 0.4179, lr: 0.1000\n",
            "epoch: 5  acc: 0.4403  best epoch: 5  best acc: 0.4403, lr: 0.1000\n",
            "epoch: 6  acc: 0.4898  best epoch: 6  best acc: 0.4898, lr: 0.1000\n",
            "epoch: 7  acc: 0.4741  best epoch: 6  best acc: 0.4898, lr: 0.1000\n",
            "epoch: 8  acc: 0.4910  best epoch: 8  best acc: 0.4910, lr: 0.1000\n",
            "epoch: 9  acc: 0.5267  best epoch: 9  best acc: 0.5267, lr: 0.1000\n",
            "epoch: 10  acc: 0.5519  best epoch: 10  best acc: 0.5519, lr: 0.1000\n",
            "epoch: 11  acc: 0.5313  best epoch: 10  best acc: 0.5519, lr: 0.1000\n",
            "epoch: 12  acc: 0.4873  best epoch: 10  best acc: 0.5519, lr: 0.1000\n",
            "epoch: 13  acc: 0.2754  best epoch: 10  best acc: 0.5519, lr: 0.1000\n",
            "epoch: 14  acc: 0.4857  best epoch: 10  best acc: 0.5519, lr: 0.1000\n",
            "epoch: 15  acc: 0.5478  best epoch: 10  best acc: 0.5519, lr: 0.1000\n",
            "epoch: 16  acc: 0.5499  best epoch: 10  best acc: 0.5519, lr: 0.1000\n",
            "epoch: 17  acc: 0.5378  best epoch: 10  best acc: 0.5519, lr: 0.1000\n",
            "epoch: 18  acc: 0.5249  best epoch: 10  best acc: 0.5519, lr: 0.1000\n",
            "epoch: 19  acc: 0.5591  best epoch: 19  best acc: 0.5591, lr: 0.1000\n",
            "epoch: 20  acc: 0.5292  best epoch: 19  best acc: 0.5591, lr: 0.1000\n",
            "epoch: 21  acc: 0.5347  best epoch: 19  best acc: 0.5591, lr: 0.1000\n",
            "epoch: 22  acc: 0.5512  best epoch: 19  best acc: 0.5591, lr: 0.1000\n",
            "epoch: 23  acc: 0.5440  best epoch: 19  best acc: 0.5591, lr: 0.1000\n",
            "epoch: 24  acc: 0.5431  best epoch: 19  best acc: 0.5591, lr: 0.1000\n",
            "epoch: 25  acc: 0.5574  best epoch: 19  best acc: 0.5591, lr: 0.1000\n",
            "epoch: 26  acc: 0.5268  best epoch: 19  best acc: 0.5591, lr: 0.1000\n",
            "epoch: 27  acc: 0.5322  best epoch: 19  best acc: 0.5591, lr: 0.1000\n",
            "epoch: 28  acc: 0.5366  best epoch: 19  best acc: 0.5591, lr: 0.1000\n",
            "epoch: 29  acc: 0.5738  best epoch: 29  best acc: 0.5738, lr: 0.1000\n",
            "epoch: 30  acc: 0.5341  best epoch: 29  best acc: 0.5738, lr: 0.1000\n",
            "epoch: 31  acc: 0.5461  best epoch: 29  best acc: 0.5738, lr: 0.1000\n",
            "epoch: 32  acc: 0.5490  best epoch: 29  best acc: 0.5738, lr: 0.1000\n",
            "epoch: 33  acc: 0.5777  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 34  acc: 0.5283  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 35  acc: 0.5509  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 36  acc: 0.5523  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 37  acc: 0.5455  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 38  acc: 0.5589  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 39  acc: 0.5664  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 40  acc: 0.5649  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 41  acc: 0.5501  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 42  acc: 0.5397  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 43  acc: 0.5230  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 44  acc: 0.5481  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 45  acc: 0.5638  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 46  acc: 0.5587  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 47  acc: 0.5462  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 48  acc: 0.5525  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 49  acc: 0.5360  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 50  acc: 0.5578  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 51  acc: 0.5624  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 52  acc: 0.5533  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 53  acc: 0.5498  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 54  acc: 0.5557  best epoch: 33  best acc: 0.5777, lr: 0.1000\n",
            "epoch: 55  acc: 0.5780  best epoch: 55  best acc: 0.5780, lr: 0.1000\n",
            "epoch: 56  acc: 0.5395  best epoch: 55  best acc: 0.5780, lr: 0.1000\n",
            "epoch: 57  acc: 0.5432  best epoch: 55  best acc: 0.5780, lr: 0.1000\n",
            "epoch: 58  acc: 0.5319  best epoch: 55  best acc: 0.5780, lr: 0.1000\n",
            "epoch: 59  acc: 0.5595  best epoch: 55  best acc: 0.5780, lr: 0.1000\n",
            "epoch: 60  acc: 0.5217  best epoch: 55  best acc: 0.5780, lr: 0.1000\n",
            "epoch: 61  acc: 0.6807  best epoch: 61  best acc: 0.6807, lr: 0.0200\n",
            "epoch: 62  acc: 0.6862  best epoch: 62  best acc: 0.6862, lr: 0.0200\n",
            "epoch: 63  acc: 0.6900  best epoch: 63  best acc: 0.6900, lr: 0.0200\n",
            "epoch: 64  acc: 0.6869  best epoch: 63  best acc: 0.6900, lr: 0.0200\n",
            "epoch: 65  acc: 0.6892  best epoch: 63  best acc: 0.6900, lr: 0.0200\n",
            "epoch: 66  acc: 0.6832  best epoch: 63  best acc: 0.6900, lr: 0.0200\n",
            "epoch: 67  acc: 0.6845  best epoch: 63  best acc: 0.6900, lr: 0.0200\n",
            "epoch: 68  acc: 0.6909  best epoch: 68  best acc: 0.6909, lr: 0.0200\n",
            "epoch: 69  acc: 0.6853  best epoch: 68  best acc: 0.6909, lr: 0.0200\n",
            "epoch: 70  acc: 0.6895  best epoch: 68  best acc: 0.6909, lr: 0.0200\n",
            "epoch: 71  acc: 0.6920  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 72  acc: 0.6860  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 73  acc: 0.6865  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 74  acc: 0.6905  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 75  acc: 0.6885  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 76  acc: 0.6879  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 77  acc: 0.6882  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 78  acc: 0.6798  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 79  acc: 0.6825  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 80  acc: 0.6817  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 81  acc: 0.6838  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 82  acc: 0.6809  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 83  acc: 0.6748  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 84  acc: 0.6781  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 85  acc: 0.6653  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 86  acc: 0.6687  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 87  acc: 0.6644  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 88  acc: 0.6664  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 89  acc: 0.6653  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 90  acc: 0.6578  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 91  acc: 0.6592  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 92  acc: 0.6604  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 93  acc: 0.6463  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 94  acc: 0.6547  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 95  acc: 0.6455  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 96  acc: 0.6595  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 97  acc: 0.6482  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 98  acc: 0.6507  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 99  acc: 0.6540  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 100  acc: 0.6457  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 101  acc: 0.6476  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 102  acc: 0.6447  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 103  acc: 0.6408  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 104  acc: 0.6415  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 105  acc: 0.6325  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 106  acc: 0.6377  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 107  acc: 0.6380  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 108  acc: 0.6414  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 109  acc: 0.6255  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 110  acc: 0.6321  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 111  acc: 0.6317  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 112  acc: 0.6404  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 113  acc: 0.6173  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 114  acc: 0.6256  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 115  acc: 0.6261  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 116  acc: 0.6320  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 117  acc: 0.6398  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 118  acc: 0.6420  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 119  acc: 0.6421  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 120  acc: 0.6306  best epoch: 71  best acc: 0.6920, lr: 0.0200\n",
            "epoch: 121  acc: 0.6778  best epoch: 71  best acc: 0.6920, lr: 0.0040\n",
            "epoch: 122  acc: 0.6826  best epoch: 71  best acc: 0.6920, lr: 0.0040\n",
            "epoch: 123  acc: 0.6849  best epoch: 71  best acc: 0.6920, lr: 0.0040\n",
            "epoch: 124  acc: 0.6838  best epoch: 71  best acc: 0.6920, lr: 0.0040\n",
            "epoch: 125  acc: 0.6924  best epoch: 125  best acc: 0.6924, lr: 0.0040\n",
            "epoch: 126  acc: 0.6915  best epoch: 125  best acc: 0.6924, lr: 0.0040\n",
            "epoch: 127  acc: 0.6925  best epoch: 127  best acc: 0.6925, lr: 0.0040\n",
            "epoch: 128  acc: 0.6928  best epoch: 128  best acc: 0.6928, lr: 0.0040\n",
            "epoch: 129  acc: 0.6941  best epoch: 129  best acc: 0.6941, lr: 0.0040\n",
            "epoch: 130  acc: 0.6918  best epoch: 129  best acc: 0.6941, lr: 0.0040\n",
            "epoch: 131  acc: 0.6938  best epoch: 129  best acc: 0.6941, lr: 0.0040\n",
            "epoch: 132  acc: 0.6927  best epoch: 129  best acc: 0.6941, lr: 0.0040\n",
            "epoch: 133  acc: 0.6950  best epoch: 133  best acc: 0.6950, lr: 0.0040\n",
            "epoch: 134  acc: 0.6944  best epoch: 133  best acc: 0.6950, lr: 0.0040\n",
            "epoch: 135  acc: 0.6952  best epoch: 135  best acc: 0.6952, lr: 0.0040\n",
            "epoch: 136  acc: 0.6939  best epoch: 135  best acc: 0.6952, lr: 0.0040\n",
            "epoch: 137  acc: 0.6956  best epoch: 137  best acc: 0.6956, lr: 0.0040\n",
            "epoch: 138  acc: 0.6960  best epoch: 138  best acc: 0.6960, lr: 0.0040\n",
            "epoch: 139  acc: 0.6952  best epoch: 138  best acc: 0.6960, lr: 0.0040\n",
            "epoch: 140  acc: 0.6931  best epoch: 138  best acc: 0.6960, lr: 0.0040\n",
            "epoch: 141  acc: 0.6983  best epoch: 141  best acc: 0.6983, lr: 0.0040\n",
            "epoch: 142  acc: 0.6986  best epoch: 142  best acc: 0.6986, lr: 0.0040\n",
            "epoch: 143  acc: 0.6986  best epoch: 142  best acc: 0.6986, lr: 0.0040\n",
            "epoch: 144  acc: 0.6989  best epoch: 144  best acc: 0.6989, lr: 0.0040\n",
            "epoch: 145  acc: 0.6978  best epoch: 144  best acc: 0.6989, lr: 0.0040\n",
            "epoch: 146  acc: 0.6961  best epoch: 144  best acc: 0.6989, lr: 0.0040\n",
            "epoch: 147  acc: 0.6977  best epoch: 144  best acc: 0.6989, lr: 0.0040\n",
            "epoch: 148  acc: 0.6970  best epoch: 144  best acc: 0.6989, lr: 0.0040\n",
            "epoch: 149  acc: 0.6980  best epoch: 144  best acc: 0.6989, lr: 0.0040\n",
            "epoch: 150  acc: 0.6984  best epoch: 144  best acc: 0.6989, lr: 0.0040\n",
            "epoch: 151  acc: 0.6988  best epoch: 144  best acc: 0.6989, lr: 0.0040\n",
            "epoch: 152  acc: 0.7011  best epoch: 152  best acc: 0.7011, lr: 0.0040\n",
            "epoch: 153  acc: 0.6997  best epoch: 152  best acc: 0.7011, lr: 0.0040\n",
            "epoch: 154  acc: 0.6998  best epoch: 152  best acc: 0.7011, lr: 0.0040\n",
            "epoch: 155  acc: 0.6982  best epoch: 152  best acc: 0.7011, lr: 0.0040\n",
            "epoch: 156  acc: 0.6974  best epoch: 152  best acc: 0.7011, lr: 0.0040\n",
            "epoch: 157  acc: 0.6970  best epoch: 152  best acc: 0.7011, lr: 0.0040\n",
            "epoch: 158  acc: 0.7000  best epoch: 152  best acc: 0.7011, lr: 0.0040\n",
            "epoch: 159  acc: 0.6998  best epoch: 152  best acc: 0.7011, lr: 0.0040\n",
            "epoch: 160  acc: 0.6995  best epoch: 152  best acc: 0.7011, lr: 0.0040\n",
            "epoch: 161  acc: 0.7011  best epoch: 152  best acc: 0.7011, lr: 0.0008\n",
            "epoch: 162  acc: 0.6996  best epoch: 152  best acc: 0.7011, lr: 0.0008\n",
            "epoch: 163  acc: 0.7008  best epoch: 152  best acc: 0.7011, lr: 0.0008\n",
            "epoch: 164  acc: 0.7033  best epoch: 164  best acc: 0.7033, lr: 0.0008\n",
            "epoch: 165  acc: 0.7014  best epoch: 164  best acc: 0.7033, lr: 0.0008\n",
            "epoch: 166  acc: 0.7038  best epoch: 166  best acc: 0.7038, lr: 0.0008\n",
            "epoch: 167  acc: 0.7019  best epoch: 166  best acc: 0.7038, lr: 0.0008\n",
            "epoch: 168  acc: 0.7016  best epoch: 166  best acc: 0.7038, lr: 0.0008\n",
            "epoch: 169  acc: 0.7025  best epoch: 166  best acc: 0.7038, lr: 0.0008\n",
            "epoch: 170  acc: 0.7034  best epoch: 166  best acc: 0.7038, lr: 0.0008\n",
            "epoch: 171  acc: 0.7028  best epoch: 166  best acc: 0.7038, lr: 0.0008\n",
            "epoch: 172  acc: 0.7020  best epoch: 166  best acc: 0.7038, lr: 0.0008\n",
            "epoch: 173  acc: 0.7027  best epoch: 166  best acc: 0.7038, lr: 0.0008\n",
            "epoch: 174  acc: 0.7038  best epoch: 166  best acc: 0.7038, lr: 0.0008\n",
            "epoch: 175  acc: 0.7032  best epoch: 166  best acc: 0.7038, lr: 0.0008\n",
            "epoch: 176  acc: 0.7052  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 177  acc: 0.7031  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 178  acc: 0.7028  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 179  acc: 0.7046  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 180  acc: 0.7043  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 181  acc: 0.7026  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 182  acc: 0.7039  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 183  acc: 0.7020  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 184  acc: 0.7026  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 185  acc: 0.7030  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 186  acc: 0.7048  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 187  acc: 0.7030  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 188  acc: 0.7025  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 189  acc: 0.7018  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 190  acc: 0.7021  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 191  acc: 0.7040  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 192  acc: 0.7028  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 193  acc: 0.7039  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 194  acc: 0.7031  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 195  acc: 0.7034  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 196  acc: 0.7037  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 197  acc: 0.7014  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 198  acc: 0.7040  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 199  acc: 0.7018  best epoch: 176  best acc: 0.7052, lr: 0.0008\n",
            "epoch: 200  acc: 0.7027  best epoch: 176  best acc: 0.7052, lr: 0.0008\n"
          ]
        }
      ],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Curriculum Learning"
      ],
      "metadata": {
        "id": "bhPkl0FFVlXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CELossWithLS(torch.nn.Module):\n",
        "    def __init__(self, classes=None, ls_factor=0.1, ignore_index=-1):\n",
        "        super(CELossWithLS, self).__init__()\n",
        "        self.ls_factor = ls_factor\n",
        "        self.complement = 1.0 - self.ls_factor\n",
        "        self.cls = classes\n",
        "        self.log_softmax = torch.nn.LogSoftmax(dim=1)\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, logits, target):\n",
        "        with torch.no_grad():\n",
        "            oh_labels = F.one_hot(target.to(torch.int64), num_classes = self.cls).contiguous()\n",
        "            smoothen_ohlabel = oh_labels * self.complement + self.ls_factor / self.cls\n",
        "        logs = self.log_softmax(logits[target!=self.ignore_index])\n",
        "        return -torch.sum(logs * smoothen_ohlabel[target!=self.ignore_index], dim=1)\n",
        "\n",
        "\n",
        "def get_threshold_confidence(model_rank, trainloader_rank, init_ratio=0.80):  \n",
        "    conf_list_all = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(trainloader_rank):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model_rank(inputs)\n",
        "            conf = F.softmax(outputs, dim=1)\n",
        "            conf_list = [conf_each[targets[i]] for i, conf_each in enumerate(conf)]\n",
        "            conf_list_all.extend(torch.tensor(conf_list))\n",
        "\n",
        "    conf_list_all = torch.tensor(conf_list_all)\n",
        "    sample_total = len(conf_list_all)\n",
        "    for mu in np.arange(1, 0, -0.001):\n",
        "        sample_mu = len(conf_list_all[conf_list_all>mu])\n",
        "        ratio = sample_mu / sample_total\n",
        "        if ratio >= init_ratio:\n",
        "            break\n",
        "\n",
        "    return mu, conf_list_all\n",
        "\n",
        "\n",
        "class CIFAR100_MC(torchvision.datasets.CIFAR100):\n",
        "    def __init__(self, root, train=True, transform=None, download=False, model_confidence=None):\n",
        "        super(CIFAR100_MC, self).__init__(root=root, train=train, download=download, transform=transform) \n",
        "        self.transform = transform\n",
        "        self.train = train\n",
        "        if self.train:\n",
        "            self.mc = model_confidence\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "        img = Image.fromarray(img)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.train:\n",
        "            return img, target, self.mc[index]\n",
        "        else:\n",
        "            return img, target\n",
        "\n",
        "def train(model, model_rank, trainloader, criterion, optimizer, epoch, warmup_scheduler, args):\n",
        "    model.train()\n",
        "    for batch_idx, (inputs, targets, conf_list) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)[conf_list>args.mu].mean()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch <= args.warm:\n",
        "            warmup_scheduler.step()\n",
        "\n",
        "def main():\n",
        "    seed_everything()\n",
        "    args = get_args()\n",
        "\n",
        "    ##### main model to train with CL######\n",
        "    model = models.resnet34(pretrained=True).to(device)\n",
        "    model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, args.num_classes)\n",
        "    model.to(device)\n",
        "\n",
        "    ##### Ranking model and dataloader for CL######\n",
        "    model_rank = copy.deepcopy(model)\n",
        "    model_rank.load_state_dict(torch.load('best_model_cifar100.pth.tar'))\n",
        "    model_rank.to(device)\n",
        "    model_rank.eval()\n",
        "\n",
        "    mean_cifar100, std_cifar100 = (0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)\n",
        "    transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "                transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
        "                transforms.Normalize(mean_cifar100, std_cifar100), ])\n",
        "    transform_test = transforms.Compose([transforms.ToTensor(),\n",
        "        transforms.Normalize(mean_cifar100, std_cifar100),])\n",
        "\n",
        "    train_dataset_rank = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_test)\n",
        "    train_loader_rank = torch.utils.data.DataLoader(train_dataset_rank, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    ##### Hyperparameters for CL######\n",
        "    args.init_ratio = 0.80\n",
        "    args.end_epoch = 10\n",
        "    args.mu, conf_list_all = get_threshold_confidence(model_rank, train_loader_rank, init_ratio=args.init_ratio)\n",
        "    args.mu = 0 if args.init_ratio == 1 else args.mu\n",
        "    beta = args.mu / args.end_epoch\n",
        "    print('Init ratio:{}, end epoch:{}, mu:{:.4f}, beta:{:.4f}'.format(args.init_ratio, args.end_epoch, args.mu, beta))\n",
        "\n",
        "    ##### Dataloaders ####\n",
        "    train_dataset = CIFAR100_MC(root='./data', train=True, download=True, transform=transform_train, model_confidence=conf_list_all)\n",
        "    test_dataset = CIFAR100_MC(root='./data', train=False, download=True, transform=transform_test)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
        "    print('Sample size: Training:{}, Valid:{}'.format(len(train_dataset), len(test_dataset)))\n",
        "\n",
        "    ##### Optimizers and scheduler####\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n",
        "    criterion = CELossWithLS(classes=args.num_classes, ls_factor=0.1)\n",
        "    train_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.2) #learning rate decay\n",
        "    iter_per_epoch = len(train_loader)\n",
        "    warmup_scheduler = WarmUpLR(optimizer, iter_per_epoch * args.warm)\n",
        "\n",
        "    ##### Trainer####\n",
        "    best_epoch, best_acc = 0.0, 0\n",
        "    for epoch in range(1, args.num_epoch + 1):\n",
        "        if epoch > args.warm:\n",
        "            train_scheduler.step()\n",
        "        train(model, model_rank, train_loader, criterion, optimizer, epoch, warmup_scheduler, args)\n",
        "\n",
        "        if epoch <= args.end_epoch:\n",
        "            args.mu -= beta\n",
        "            args.mu = max(args.mu, 0)\n",
        "        else:\n",
        "            args.mu = 0\n",
        "\n",
        "        accuracy = test(model, test_loader)\n",
        "        if accuracy > best_acc:\n",
        "            best_acc = accuracy\n",
        "            best_epoch = epoch\n",
        "            torch.save(model.state_dict(), 'best_model_cifar100_cl.pth.tar')\n",
        "\n",
        "        print('epoch:{}  acc:{:.4f}  best epoch:{}  best acc:{:.4f}, lr:{:.4f}, mu:{:.4f}'.format(\n",
        "                epoch, accuracy, best_epoch, best_acc, optimizer.param_groups[0]['lr'], args.mu))\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNacmI-Ra61w",
        "outputId": "7ee0218b-14e6-4c4e-a5f8-d16405ae9e0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Init ratio:0.8, end epoch:10, mu:0.8880, beta:0.0888\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Sample size: Training:50000, Valid:10000\n",
            "epoch:1  acc:0.2463  best epoch:1  best acc:0.2463, lr:0.1000, mu:0.7992\n",
            "epoch:2  acc:0.4239  best epoch:2  best acc:0.4239, lr:0.1000, mu:0.7104\n",
            "epoch:3  acc:0.4619  best epoch:3  best acc:0.4619, lr:0.1000, mu:0.6216\n",
            "epoch:4  acc:0.3882  best epoch:3  best acc:0.4619, lr:0.1000, mu:0.5328\n",
            "epoch:5  acc:0.4990  best epoch:5  best acc:0.4990, lr:0.1000, mu:0.4440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code testing without CL (init_ratio=100%)"
      ],
      "metadata": {
        "id": "qG2T-20LWEbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CELossWithLS(torch.nn.Module):\n",
        "    def __init__(self, classes=None, ls_factor=0.1, ignore_index=-1):\n",
        "        super(CELossWithLS, self).__init__()\n",
        "        self.ls_factor = ls_factor\n",
        "        self.complement = 1.0 - self.ls_factor\n",
        "        self.cls = classes\n",
        "        self.log_softmax = torch.nn.LogSoftmax(dim=1)\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, logits, target):\n",
        "        with torch.no_grad():\n",
        "            oh_labels = F.one_hot(target.to(torch.int64), num_classes = self.cls).contiguous()\n",
        "            smoothen_ohlabel = oh_labels * self.complement + self.ls_factor / self.cls\n",
        "        logs = self.log_softmax(logits[target!=self.ignore_index])\n",
        "        return -torch.sum(logs * smoothen_ohlabel[target!=self.ignore_index], dim=1)\n",
        "\n",
        "\n",
        "def get_threshold_confidence(model_rank, trainloader_rank, init_ratio=0.80):  \n",
        "    conf_list_all = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(trainloader_rank):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model_rank(inputs)\n",
        "            conf = F.softmax(outputs, dim=1)\n",
        "            conf_list = [conf_each[targets[i]] for i, conf_each in enumerate(conf)]\n",
        "            conf_list_all.extend(torch.tensor(conf_list))\n",
        "\n",
        "    conf_list_all = torch.tensor(conf_list_all)\n",
        "    sample_total = len(conf_list_all)\n",
        "    for mu in np.arange(1, 0, -0.001):\n",
        "        sample_mu = len(conf_list_all[conf_list_all>mu])\n",
        "        ratio = sample_mu / sample_total\n",
        "        if ratio >= init_ratio:\n",
        "            break\n",
        "\n",
        "    return mu, conf_list_all\n",
        "\n",
        "\n",
        "class CIFAR100_MC(torchvision.datasets.CIFAR100):\n",
        "    def __init__(self, root, train=True, transform=None, download=False, model_confidence=None):\n",
        "        super(CIFAR100_MC, self).__init__(root=root, train=train, download=download, transform=transform) \n",
        "        self.transform = transform\n",
        "        self.train = train\n",
        "        if self.train:\n",
        "            self.mc = model_confidence\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "        img = Image.fromarray(img)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.train:\n",
        "            return img, target, self.mc[index]\n",
        "        else:\n",
        "            return img, target\n",
        "\n",
        "def train(model, model_rank, trainloader, criterion, optimizer, epoch, warmup_scheduler, args):\n",
        "    model.train()\n",
        "    for batch_idx, (inputs, targets, conf_list) in enumerate(trainloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)[conf_list>args.mu].mean()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch <= args.warm:\n",
        "            warmup_scheduler.step()\n",
        "\n",
        "def main():\n",
        "    seed_everything()\n",
        "    args = get_args()\n",
        "\n",
        "    ##### main model to train with CL######\n",
        "    model = models.resnet34(pretrained=True).to(device)\n",
        "    model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, args.num_classes)\n",
        "    model.to(device)\n",
        "\n",
        "    ##### Ranking model and dataloader for CL######\n",
        "    model_rank = copy.deepcopy(model)\n",
        "    model_rank.load_state_dict(torch.load('best_model_cifar100.pth.tar'))\n",
        "    model_rank.to(device)\n",
        "    model_rank.eval()\n",
        "\n",
        "    mean_cifar100, std_cifar100 = (0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)\n",
        "    transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "                transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
        "                transforms.Normalize(mean_cifar100, std_cifar100), ])\n",
        "    transform_test = transforms.Compose([transforms.ToTensor(),\n",
        "        transforms.Normalize(mean_cifar100, std_cifar100),])\n",
        "\n",
        "    train_dataset_rank = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_test)\n",
        "    train_loader_rank = torch.utils.data.DataLoader(train_dataset_rank, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    ##### Hyperparameters for CL######\n",
        "    args.init_ratio = 1#0.80\n",
        "    args.end_epoch = 10\n",
        "    args.mu, conf_list_all = get_threshold_confidence(model_rank, train_loader_rank, init_ratio=args.init_ratio)\n",
        "    args.mu = 0 if args.init_ratio == 1 else args.mu\n",
        "    beta = args.mu / args.end_epoch\n",
        "    print('Init ratio:{}, end epoch:{}, mu:{:.4f}, beta:{:.4f}'.format(args.init_ratio, args.end_epoch, args.mu, beta))\n",
        "\n",
        "    ##### Dataloaders ####\n",
        "    train_dataset = CIFAR100_MC(root='./data', train=True, download=True, transform=transform_train, model_confidence=conf_list_all)\n",
        "    test_dataset = CIFAR100_MC(root='./data', train=False, download=True, transform=transform_test)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
        "    print('Sample size: Training:{}, Valid:{}'.format(len(train_dataset), len(test_dataset)))\n",
        "\n",
        "    ##### Optimizers and scheduler####\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)\n",
        "    criterion = CELossWithLS(classes=args.num_classes, ls_factor=0.1)\n",
        "    train_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.2) #learning rate decay\n",
        "    iter_per_epoch = len(train_loader)\n",
        "    warmup_scheduler = WarmUpLR(optimizer, iter_per_epoch * args.warm)\n",
        "\n",
        "    ##### Trainer####\n",
        "    best_epoch, best_acc = 0.0, 0\n",
        "    for epoch in range(1, args.num_epoch + 1):\n",
        "        if epoch > args.warm:\n",
        "            train_scheduler.step()\n",
        "        train(model, model_rank, train_loader, criterion, optimizer, epoch, warmup_scheduler, args)\n",
        "\n",
        "        if epoch <= args.end_epoch:\n",
        "            args.mu -= beta\n",
        "            args.mu = max(args.mu, 0)\n",
        "        else:\n",
        "            args.mu = 0\n",
        "\n",
        "        accuracy = test(model, test_loader)\n",
        "        if accuracy > best_acc:\n",
        "            best_acc = accuracy\n",
        "            best_epoch = epoch\n",
        "            torch.save(model.state_dict(), 'best_model_cifar100_cl.pth.tar')\n",
        "\n",
        "        print('epoch:{}  acc:{:.4f}  best epoch:{}  best acc:{:.4f}, lr:{:.4f}, mu:{:.4f}'.format(\n",
        "                epoch, accuracy, best_epoch, best_acc, optimizer.param_groups[0]['lr'], args.mu))\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "hEdbwW1ZWAH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ablation Study"
      ],
      "metadata": {
        "id": "vkfu_-WoSetQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything()\n",
        "args = get_args()\n",
        "import copy \n",
        "model = models.resnet34(pretrained=True).to(device)\n",
        "model.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, args.num_classes)\n",
        "model.to(device)\n",
        "\n",
        "model_rank = copy.deepcopy(model)\n",
        "model_rank.load_state_dict(torch.load('best_model_cifar100.pth.tar'))\n",
        "model_rank.to(device)\n",
        "model_rank.eval()\n",
        "\n",
        "mean_cifar100, std_cifar100 = (0.5071, 0.4865, 0.4409), (0.2673, 0.2564, 0.2762)\n",
        "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(), transforms.ToTensor(),\n",
        "            transforms.Normalize(mean_cifar100, std_cifar100), ])\n",
        "transform_test = transforms.Compose([transforms.ToTensor(),\n",
        "    transforms.Normalize(mean_cifar100, std_cifar100),])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=False, num_workers=2)\n",
        "with torch.no_grad():\n",
        "    total, correct = 0, 0\n",
        "    conf_list_all = []\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model_rank(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        conf = F.softmax(outputs, dim=1)\n",
        "        conf_list = [conf_each[targets[i]] for i, conf_each in enumerate(conf)]\n",
        "        conf_list_all.extend(conf_list)\n",
        "acc = correct / total\n",
        "print('Acc:',acc,, 'len:',len(conf_list_all))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "conf_list_all = torch.tensor(conf_list_all)\n",
        "hist, range_val = np.histogram(conf_list_all, bins=10, range=(0,1))\n",
        "plt.bar(np.arange(len(hist)),hist)\n",
        "plt.xticks(ticks=np.arange(len(range_val)), labels=range_val);\n",
        "\n",
        "init_ratio = 0.80\n",
        "for mu in np.arange(1, 0, -0.001):\n",
        "    ratio = len(conf_list_all[conf_list_all>mu]) / len(conf_list_all)\n",
        "    if ratio >= init_ratio:\n",
        "        break\n",
        "    \n",
        "print('mu for desired intit ratio:', mu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ggxnzU_AQlH",
        "outputId": "becad7fe-2fb6-4edb-be56-95c085cf6435"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "0.93864 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(30,10))\n",
        "conf_list_all = torch.tensor(conf_list_all)\n",
        "hist, range_val = np.histogram(conf_list_all, bins=20, range=(0,1))\n",
        "plt.bar(np.arange(len(hist)),hist)\n",
        "plt.xticks(ticks=np.arange(len(range_val)), labels=range_val);\n",
        "#plt.xticklabels(range_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "MgP-XZJgcyAf",
        "outputId": "95e1b8cb-20da-4aab-e6ff-11bcf252657f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(30,10))\n",
        "conf_list_all = torch.tensor(conf_list_all)\n",
        "hist, range_val = np.histogram(conf_list_all, bins=20, range=(0,1))\n",
        "\n",
        "count_bin = np.zeros(len(hist))\n",
        "prev = 0\n",
        "for idx in range(0, len(hist)):\n",
        "    count_bin[idx] = prev + hist[idx]\n",
        "    prev = count_bin[idx]\n",
        "\n",
        "plt.bar(np.arange(len(hist)),count_bin)\n",
        "plt.xticks(ticks=np.arange(len(range_val)), labels=range_val);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "mEGYSmQKeIMT",
        "outputId": "4e01f50d-2336-45a9-9d07-40ddc49090cd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(30,10))\n",
        "conf_list_all = torch.tensor(conf_list_all)\n",
        "hist, range_val = np.histogram(conf_list_all, bins=20, range=(0,1))\n",
        "\n",
        "count_bin = np.zeros(len(hist))\n",
        "prev = 0\n",
        "for idx in range(len(hist)-1, -1, -1):\n",
        "    count_bin[idx] = prev + hist[idx]\n",
        "    prev = count_bin[idx]\n",
        "\n",
        "print(count_bin)\n",
        "plt.bar(np.arange(len(hist)),count_bin)\n",
        "plt.xticks(ticks=np.arange(len(range_val)), labels=range_val);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "gvDX877Se4X_",
        "outputId": "45e1e13c-df02-4343-e36c-052e78766660"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50000. 47773. 47406. 47202. 47059. 46952. 46843. 46733. 46634. 46556.\n",
            " 46450. 46345. 46229. 46099. 45960. 45765. 45531. 45023. 30601.   253.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "init = 0.88\n",
        "for i in range(10):\n",
        "    init = init * 0.8\n",
        "    print(i, init)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6p_4gmwhdqs",
        "outputId": "21303728-68f0-4480-a939-a615170404e8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.7040000000000001\n",
            "1 0.5632\n",
            "2 0.45056000000000007\n",
            "3 0.3604480000000001\n",
            "4 0.28835840000000007\n",
            "5 0.23068672000000007\n",
            "6 0.18454937600000007\n",
            "7 0.14763950080000007\n",
            "8 0.11811160064000006\n",
            "9 0.09448928051200006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "#out = 0.000001 / pow(0.88,10)\n",
        "(0.1/0.88)**(1/3), (1e-16/0.88)**(1/3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFonn4p0iL-k",
        "outputId": "6c70b0fb-94c3-450c-f4ea-a615bfefce36"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4843646530757322, 4.843646530757324e-06)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mu = 0.88\n",
        "b1 = (0.1/0.88)**(1/3)\n",
        "b2 = (1e-5/0.88)**(1/3)\n",
        "for i in range(10):\n",
        "    mu = mu*b1\n",
        "    print(mu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KnixSeDeWOd",
        "outputId": "081523a2-9ba7-4451-f494-d6c6d5a69398"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.42624089470664434\n",
            "0.20645602309127348\n",
            "0.10000000000000003\n",
            "0.048436465307573236\n",
            "0.02346091171491745\n",
            "0.011363636363636371\n",
            "0.005504143784951505\n",
            "0.0026660126948769834\n",
            "0.001291322314049588\n",
            "0.0006254708846535804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R28eluz1hfDg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}