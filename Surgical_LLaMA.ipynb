{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/Surgical_LLaMA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pU4iPZR0ucs",
        "outputId": "5136ee24-3511-41ab-f455-4854225c3b71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SurgicalGPT'...\n",
            "remote: Enumerating objects: 89, done.\u001b[K\n",
            "remote: Counting objects: 100% (89/89), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 89 (delta 42), reused 82 (delta 35), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (89/89), 749.26 KiB | 1.15 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lalithjets/SurgicalGPT.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SWZYckbo1Wuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d067af-a888-43af-861a-21aab0ef91bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Installing required dependencies\n",
        "!pip -q install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "google drive: https://drive.google.com/file/d/1K5YnSPMPvn2x1gtRAw2ZfxIqoIo2DX3I"
      ],
      "metadata": {
        "id": "hvfERkLBGAM8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7wl6PSm0xF9",
        "outputId": "2de2b992-6f3e-4046-c146-e60cce5e4b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WGdztykX3nW6pi_BKp4rO8nA7ESNRfVN\n",
            "To: /content/EndoVis-18-VQA.zip\n",
            "100% 2.70G/2.70G [00:41<00:00, 65.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Downloading the VQA EndoVis18 Dataset https://drive.google.com/file/d/1WGdztykX3nW6pi_BKp4rO8nA7ESNRfVN/view?usp=sharing\n",
        "!gdown --id 1WGdztykX3nW6pi_BKp4rO8nA7ESNRfVN\n",
        "\n",
        "# Unzipping the VQA EndoVis18 Dataset\\\n",
        "!unzip -q EndoVis-18-VQA.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset path correction as repo\n",
        "!mv -f EndoVis-18-VQA /content/SurgicalGPT/dataset"
      ],
      "metadata": {
        "id": "NtzbQyOoNypt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kcMJ5Prm0_dL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a02a820-833f-4873-eb75-a0bcff318dfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SurgicalGPT\n",
            "2023-10-20 21:38:59.073664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "efvlegpt2Swin v1 zeroes m18 cat1 1e-05 checkpoints/efvlegpt2Swin/m18_v1_z_qf_\n",
            "device = cuda\n",
            "Downloading (…)olve/main/vocab.json: 100% 1.04M/1.04M [00:00<00:00, 3.94MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 3.45MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 4.08MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 665/665 [00:00<00:00, 4.05MB/s]\n",
            "Downloading (…)rocessor_config.json: 100% 255/255 [00:00<00:00, 1.33MB/s]\n",
            "Total files: 1560 | Total question: 9014\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Total files: 447 | Total question: 2769\n",
            "Downloading (…)lve/main/config.json: 100% 71.8k/71.8k [00:00<00:00, 215MB/s]\n",
            "Downloading model.safetensors: 100% 113M/113M [00:01<00:00, 87.2MB/s]\n",
            "Downloading model.safetensors: 100% 548M/548M [00:07<00:00, 77.2MB/s]\n",
            "model params:  190960524\n",
            "Train: epoch: 1 loss: 349.300427 | Acc: 0.532172 | Precision: 0.257939 | Recall: 0.215611 | FScore: 0.216388\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Test: epoch: 1 loss: 70.736336 | Acc: 0.596244 | Precision: 0.747001 | Recall: 0.310399 | FScore: 0.276300\n"
          ]
        }
      ],
      "source": [
        "# Running the training loop with all arguments\n",
        "%cd /content/SurgicalGPT\n",
        "import os\n",
        "os.makedirs('checkpoints/efvlegpt2Swin', exist_ok=True)\n",
        "!python train.py \\\n",
        "--lr=0.00001 \\\n",
        "--checkpoint_dir='checkpoints/efvlegpt2Swin/m18_v1_z_qf_' \\\n",
        "--dataset_type='m18' \\\n",
        "--tokenizer_ver='gpt2v1' \\\n",
        "--model_ver='efvlegpt2Swin' \\\n",
        "--model_subver='v1' \\\n",
        "--vis_pos_emb='zeroes'\\\n",
        "--batch_size=40 \\\n",
        "--epochs=2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/SurgicalGPT\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data  import DataLoader\n",
        "from transformers import BertTokenizer, GPT2Tokenizer\n",
        "from train import seed_everything, validate, train\n",
        "from dataloaders.dataloaderGPT2Classification import EndoVis18VQAGPTClassification\n",
        "from models.EFGPT2Classification import EFVLEGPT2RS18Classification, EFVLEGPT2SwinClassification\n",
        "from utils import save_clf_checkpoint, adjust_learning_rate\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "def get_arg():\n",
        "    parser = argparse.ArgumentParser(description='VisualQuestionAnswerClassification')\n",
        "\n",
        "    # VB Model parameters\n",
        "    parser.add_argument('--emb_dim',        type=int,   default=300,                                help='dimension of word embeddings.')\n",
        "    parser.add_argument('--n_heads',        type=int,   default=8,                                  help='Multi-head attention.')\n",
        "    parser.add_argument('--dropout',        type=float, default=0.1,                                help='dropout')\n",
        "    parser.add_argument('--encoder_layers', type=int,   default=6,                                  help='the number of layers of encoder in Transformer.')\n",
        "\n",
        "    # Training parameters\n",
        "    parser.add_argument('--epochs',         type=int,   default=2,                                 help='number of epochs to train for (if early stopping is not triggered).') #80, 26\n",
        "    parser.add_argument('--batch_size',     type=int,   default=40,                                 help='batch_size')\n",
        "    parser.add_argument('--workers',        type=int,   default=1,                                  help='for data-loading; right now, only 1 works with h5pys.')\n",
        "    parser.add_argument('--print_freq',     type=int,   default=100,                                help='print training/validation stats every __ batches.')\n",
        "\n",
        "    # existing checkpoint\n",
        "    parser.add_argument('--checkpoint',     default=None,                                           help='path to checkpoint, None if none.')\n",
        "\n",
        "    parser.add_argument('--lr',             type=float, default=0.00001,                           help='0.000005, 0.00001, 0.000005')\n",
        "    parser.add_argument('--checkpoint_dir', default= 'checkpoints/efvlegpt2Swin/m18_v1_z_qf_',            help='med_vqa_c$version$/m18/c80/m18_vid$temporal_size$/c80_vid$temporal_size$') #clf_v1_2_1x1/med_vqa_c3\n",
        "    parser.add_argument('--dataset_type',   default= 'm18',                                          help='med_vqa/m18/c80/m18_vid/c80_vid')\n",
        "    parser.add_argument('--dataset_cat',    default= 'cat1',                                        help='cat1/cat2/cat3')\n",
        "    parser.add_argument('--tokenizer_ver',  default= 'gpt2v1',                                      help='btv2/btv3/gpt2v1')\n",
        "    parser.add_argument('--question_len',   default= 25,                                            help='25')\n",
        "    parser.add_argument('--model_ver',      default= 'efvlegpt2Swin',                                          help='vb/vbrm/efvlegpt2rs18/efvlegpt2Swin/\"')  #vrvb/gpt2rs18/gpt2ViT/gpt2Swin/biogpt2rs18/vilgpt2vqa/efgpt2rs18gr/efvlegpt2Swingr\n",
        "    parser.add_argument('--model_subver',   default= 'v1',                                          help='V0,v1/v2/v3/v4')\n",
        "    parser.add_argument('--vis_pos_emb',   default= 'zeroes',                                           help='None, zeroes, pos')\n",
        "    parser.add_argument('--patch_size',     default= 5,                                             help='1/2/3/4/5')\n",
        "\n",
        "    parser.add_argument('--num_class',      default= 2,                                             help='25')\n",
        "    # parser.add_argument('--temporal_size',  default= 1,                                             help='1/2/3/4/5')\n",
        "    parser.add_argument('--validate',       default=False,                                          help='When only validation required False/True')\n",
        "\n",
        "    if 'ipykernel' in sys.modules:\n",
        "        args = parser.parse_args([])\n",
        "    else:\n",
        "        args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    args = get_arg()\n",
        "    os.makedirs('checkpoints/efvlegpt2Swin', exist_ok=True)\n",
        "    seed_everything()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    start_epoch = 1\n",
        "    best_epoch = [0]\n",
        "    best_results = [0.0]\n",
        "    epochs_since_improvement = 0\n",
        "    final_args = {\"emb_dim\": args.emb_dim, \"n_heads\": args.n_heads, \"dropout\": args.dropout, \"encoder_layers\": args.encoder_layers}\n",
        "\n",
        "    if args.dataset_type == 'm18':\n",
        "        # tokenizer\n",
        "        if args.tokenizer_ver == 'gpt2v1':\n",
        "            tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "        # data location\n",
        "        train_seq = [2, 3, 4, 6, 7, 9, 10, 11, 12, 14, 15]\n",
        "        val_seq = [1, 5, 16]\n",
        "\n",
        "        folder_head = 'dataset/EndoVis-18-VQA/seq_'\n",
        "        folder_tail = '/vqa/Classification/*.txt'\n",
        "\n",
        "        # dataloader\n",
        "        if args.model_ver == 'efvlegpt2rs18' or args.model_ver == \"efvlegpt2Swin\" or args.model_ver == 'efvlegpt2ViT':\n",
        "            train_dataset = EndoVis18VQAGPTClassification(train_seq, folder_head, folder_tail, model_ver=args.model_ver)\n",
        "            train_dataloader = DataLoader(dataset=train_dataset, batch_size= args.batch_size, shuffle=True, num_workers=8)\n",
        "            val_dataset = EndoVis18VQAGPTClassification(val_seq, folder_head, folder_tail, model_ver=args.model_ver)\n",
        "            val_dataloader = DataLoader(dataset=val_dataset, batch_size= args.batch_size, shuffle=False, num_workers=8)\n",
        "\n",
        "        # num_classes\n",
        "        args.num_class = 18\n",
        "\n",
        "        if args.model_ver == 'efvlegpt2Swin':\n",
        "            model = EFVLEGPT2SwinClassification(num_class = args.num_class, model_subver = args.model_subver, vis_pos_emb = args.vis_pos_emb)\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "        model = model.to(device)\n",
        "        criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "        for epoch in range(start_epoch, args.epochs):\n",
        "\n",
        "            if epochs_since_improvement > 0 and epochs_since_improvement % 5 == 0:\n",
        "                adjust_learning_rate(optimizer, 0.8)\n",
        "\n",
        "            # train\n",
        "            train_acc = train(args, train_dataloader=train_dataloader, model = model, criterion=criterion, optimizer=optimizer, epoch=epoch, tokenizer = tokenizer, device = device)\n",
        "\n",
        "            # validation\n",
        "            test_acc, test_c_acc, test_precision, test_recall, test_fscore = validate(args, val_loader=val_dataloader, model = model, criterion=criterion, epoch=epoch, tokenizer = tokenizer, device = device)\n",
        "\n",
        "            if test_acc >= best_results[0]:\n",
        "                print('Best Epoch:', epoch)\n",
        "                epochs_since_improvement = 0\n",
        "\n",
        "                best_results[0] = test_acc\n",
        "                best_epoch[0] = epoch\n",
        "                save_clf_checkpoint(args.checkpoint_dir, epoch, epochs_since_improvement, model, optimizer, best_results[0], final_args)\n",
        "\n"
      ],
      "metadata": {
        "id": "Wj1Az0gsWW6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ade333c-bca5-4e62-a509-0ec9969342df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SurgicalGPT\n",
            "Total files: 1560 | Total question: 9014\n",
            "Total files: 447 | Total question: 2769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xfstGr_kIkFJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}