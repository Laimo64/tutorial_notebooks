{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/ImageNet_Download_All.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ImageNet (ILSVRC2012)\n",
        "\n",
        "It contains 1000 classes, 1.28 million training images, and 50 thousand validation images. There are 1,281,167 images and 732-1300 per class in the ILSVRC2012 training set. This dataset spans 1000 object classes and contains 1,281,167 training images, 50,000 validation images and 100,000 test images. It requires more than 150GB of storage, and training a resnet50 on it will take around 215 hours using a T4 GPU on Google Colab. Folder name to actual class mapping: https://www.image-net.org/challenges/LSVRC/2012/browse-synsets.php <br>\n",
        "Sample size is not equal in ImageNet. For example top 10 classes:<br>\n",
        "n02094433:    3047 (Yorkshire terrier)<br>\n",
        "n02086240:    2563 (Shih-Tzu)<br>\n",
        "n01882714:    2469 (koala bear, kangaroo bear, native bear, )<br>\n",
        "n02087394:    2449 (Rhodesian ridgeback)<br>\n",
        "n02100735:    2426 (English setter)<br>\n",
        "n00483313:    2410 (singles)<br>\n",
        "n02279972:    2386 (monarch butterfly, Danaus plexippus)<br>\n",
        "n09428293:    2382 (seashore)<br>\n",
        "n02138441:    2341 (meerkat)<br>\n",
        "n02100583:    2334 (vizsla, Hungarian pointer)<br>\n",
        "\n",
        "\n",
        "Task-1. Image classification (2010-2014): Algorithms produce a list of object categories present in the image.<br>\n",
        "Task-2. Single-object localization (2011-2014): Algorithms\n",
        "produce a list of object categories present in the image, along with an axis-aligned bounding box indicating the position and scale of one instance of each object category.<br>\n",
        "Task-3. Object detection (2013-2014): Algorithms produce\n",
        "a list of object categories present in the image along\n",
        "with an axis-aligned bounding box indicating the\n",
        "position and scale of every instance of each object\n",
        "category.<br>\n",
        "\n",
        "#Download Links:\n",
        "\n",
        "Training Images (taskl&2): https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_train.tar <br>\n",
        "Training Annotations (taskl&2): https://image-net.org/data/ILSVRC/2012/ILSVRC2012_bbox_train_v2.tar.gz <br>\n",
        "\n",
        "Validation Images (all tasks): https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar\n",
        "\n",
        "Validation Annotations (all tasks): https://image-net.org/data/ILSVRC/2012/ILSVRC2012_bbox_val_v3.tgz\n"
      ],
      "metadata": {
        "id": "KHwLWpzQGmJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download specific number of classes and samples per class:"
      ],
      "metadata": {
        "id": "3-gUdorcTs0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/mf1024/ImageNet-Datasets-Downloader.git\n",
        "%cd ImageNet-Datasets-Downloader\n",
        "! mkdir imagenet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz9X_MWyFTdd",
        "outputId": "7a0efd9b-74c6-4e83-9ce8-95038464aeec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ImageNet-Datasets-Downloader' already exists and is not an empty directory.\n",
            "/content/ImageNet-Datasets-Downloader\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YSZ0Qq79ZoO"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import numpy as np\n",
        "import requests\n",
        "import argparse\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import csv\n",
        "\n",
        "from multiprocessing import Pool, Process, Value, Lock\n",
        "\n",
        "from requests.exceptions import ConnectionError, ReadTimeout, TooManyRedirects, MissingSchema, InvalidURL\n",
        "\n",
        "parser = argparse.ArgumentParser(description='ImageNet image scraper')\n",
        "parser.add_argument('-scrape_only_flickr', default=True, type=lambda x: (str(x).lower() == 'true'))\n",
        "parser.add_argument('-number_of_classes', default = 1000, type=int)\n",
        "parser.add_argument('-images_per_class', default = 10, type=int)\n",
        "parser.add_argument('-data_root', default='imagenet' , type=str)\n",
        "parser.add_argument('-use_class_list', default=False,type=lambda x: (str(x).lower() == 'true'))\n",
        "parser.add_argument('-class_list', default=[], nargs='*')\n",
        "parser.add_argument('-debug', default=False,type=lambda x: (str(x).lower() == 'true'))\n",
        "\n",
        "parser.add_argument('-multiprocessing_workers', default = 8, type=int)\n",
        "\n",
        "args, args_other = parser.parse_known_args([])\n",
        "\n",
        "if args.debug:\n",
        "    logging.basicConfig(filename='imagenet_scarper.log', level=logging.DEBUG)\n",
        "\n",
        "if len(args.data_root) == 0:\n",
        "    logging.error(\"-data_root is required to run downloader!\")\n",
        "    exit()\n",
        "\n",
        "if not os.path.isdir(args.data_root):\n",
        "    logging.error(f'folder {args.data_root} does not exist! please provide existing folder in -data_root arg!')\n",
        "    exit()\n",
        "\n",
        "\n",
        "IMAGENET_API_WNID_TO_URLS = lambda wnid: f'http://www.image-net.org/api/imagenet.synset.geturls?wnid={wnid}'\n",
        "\n",
        "current_folder = os.path.dirname(os.path.realpath('__file__'))\n",
        "\n",
        "class_info_json_filename = 'imagenet_class_info.json'\n",
        "class_info_json_filepath = os.path.join(current_folder, class_info_json_filename)\n",
        "\n",
        "class_info_dict = dict()\n",
        "\n",
        "with open(class_info_json_filepath) as class_info_json_f:\n",
        "    class_info_dict = json.load(class_info_json_f)\n",
        "\n",
        "classes_to_scrape = []\n",
        "\n",
        "if args.use_class_list == True:\n",
        "   for item in args.class_list:\n",
        "       classes_to_scrape.append(item)\n",
        "       if item not in class_info_dict:\n",
        "           logging.error(f'Class {item} not found in ImageNete')\n",
        "           exit()\n",
        "\n",
        "elif args.use_class_list == False:\n",
        "    potential_class_pool = []\n",
        "    for key, val in class_info_dict.items():\n",
        "\n",
        "        if args.scrape_only_flickr:\n",
        "            if int(val['flickr_img_url_count']) * 0.9 > args.images_per_class:\n",
        "                potential_class_pool.append(key)\n",
        "        else:\n",
        "            if int(val['img_url_count']) * 0.8 > args.images_per_class:\n",
        "                potential_class_pool.append(key)\n",
        "\n",
        "    if (len(potential_class_pool) < args.number_of_classes):\n",
        "        logging.error(f\"With {args.images_per_class} images per class there are {len(potential_class_pool)} to choose from.\")\n",
        "        logging.error(f\"Decrease number of classes or decrease images per class.\")\n",
        "        exit()\n",
        "\n",
        "    picked_classes_idxes = np.random.choice(len(potential_class_pool), args.number_of_classes, replace = False)\n",
        "\n",
        "    for idx in picked_classes_idxes:\n",
        "        classes_to_scrape.append(potential_class_pool[idx])\n",
        "\n",
        "\n",
        "print(\"Picked the following clases:\")\n",
        "print([ class_info_dict[class_wnid]['class_name'] for class_wnid in classes_to_scrape ])\n",
        "\n",
        "imagenet_images_folder = os.path.join(args.data_root, 'imagenet_images')\n",
        "if not os.path.isdir(imagenet_images_folder):\n",
        "    os.mkdir(imagenet_images_folder)\n",
        "\n",
        "\n",
        "scraping_stats = dict(\n",
        "    all=dict(\n",
        "        tried=0,\n",
        "        success=0,\n",
        "        time_spent=0,\n",
        "    ),\n",
        "    is_flickr=dict(\n",
        "        tried=0,\n",
        "        success=0,\n",
        "        time_spent=0,\n",
        "    ),\n",
        "    not_flickr=dict(\n",
        "        tried=0,\n",
        "        success=0,\n",
        "        time_spent=0,\n",
        "    )\n",
        ")\n",
        "\n",
        "def add_debug_csv_row(row):\n",
        "    with open('stats.csv', \"a\") as csv_f:\n",
        "        csv_writer = csv.writer(csv_f, delimiter=\",\")\n",
        "        csv_writer.writerow(row)\n",
        "\n",
        "class MultiStats():\n",
        "    def __init__(self):\n",
        "\n",
        "        self.lock = Lock()\n",
        "\n",
        "        self.stats = dict(\n",
        "            all=dict(\n",
        "                tried=Value('d', 0),\n",
        "                success=Value('d',0),\n",
        "                time_spent=Value('d',0),\n",
        "            ),\n",
        "            is_flickr=dict(\n",
        "                tried=Value('d', 0),\n",
        "                success=Value('d',0),\n",
        "                time_spent=Value('d',0),\n",
        "            ),\n",
        "            not_flickr=dict(\n",
        "                tried=Value('d', 0),\n",
        "                success=Value('d', 0),\n",
        "                time_spent=Value('d', 0),\n",
        "            )\n",
        "        )\n",
        "    def inc(self, cls, stat, val):\n",
        "        with self.lock:\n",
        "            self.stats[cls][stat].value += val\n",
        "\n",
        "    def get(self, cls, stat):\n",
        "        with self.lock:\n",
        "            ret = self.stats[cls][stat].value\n",
        "        return ret\n",
        "\n",
        "multi_stats = MultiStats()\n",
        "\n",
        "\n",
        "if args.debug:\n",
        "    row = [\n",
        "        \"all_tried\",\n",
        "        \"all_success\",\n",
        "        \"all_time_spent\",\n",
        "        \"is_flickr_tried\",\n",
        "        \"is_flickr_success\",\n",
        "        \"is_flickr_time_spent\",\n",
        "        \"not_flickr_tried\",\n",
        "        \"not_flickr_success\",\n",
        "        \"not_flickr_time_spent\"\n",
        "    ]\n",
        "    add_debug_csv_row(row)\n",
        "\n",
        "def add_stats_to_debug_csv():\n",
        "    row = [\n",
        "        multi_stats.get('all', 'tried'),\n",
        "        multi_stats.get('all', 'success'),\n",
        "        multi_stats.get('all', 'time_spent'),\n",
        "        multi_stats.get('is_flickr', 'tried'),\n",
        "        multi_stats.get('is_flickr', 'success'),\n",
        "        multi_stats.get('is_flickr', 'time_spent'),\n",
        "        multi_stats.get('not_flickr', 'tried'),\n",
        "        multi_stats.get('not_flickr', 'success'),\n",
        "        multi_stats.get('not_flickr', 'time_spent'),\n",
        "    ]\n",
        "    add_debug_csv_row(row)\n",
        "\n",
        "def print_stats(cls, print_func):\n",
        "\n",
        "    actual_all_time_spent = time.time() - scraping_t_start.value\n",
        "    processes_all_time_spent = multi_stats.get('all', 'time_spent')\n",
        "\n",
        "    if processes_all_time_spent == 0:\n",
        "        actual_processes_ratio = 1.0\n",
        "    else:\n",
        "        actual_processes_ratio = actual_all_time_spent / processes_all_time_spent\n",
        "\n",
        "    #print(f\"actual all time: {actual_all_time_spent} proc all time {processes_all_time_spent}\")\n",
        "\n",
        "    print_func(f'STATS For class {cls}:')\n",
        "    print_func(f' tried {multi_stats.get(cls, \"tried\")} urls with'\n",
        "               f' {multi_stats.get(cls, \"success\")} successes')\n",
        "\n",
        "    if multi_stats.get(cls, \"tried\") > 0:\n",
        "        print_func(f'{100.0 * multi_stats.get(cls, \"success\")/multi_stats.get(cls, \"tried\")}% success rate for {cls} urls ')\n",
        "    if multi_stats.get(cls, \"success\") > 0:\n",
        "        print_func(f'{multi_stats.get(cls,\"time_spent\") * actual_processes_ratio / multi_stats.get(cls,\"success\")} seconds spent per {cls} succesful image download')\n",
        "\n",
        "\n",
        "\n",
        "lock = Lock()\n",
        "url_tries = Value('d', 0)\n",
        "scraping_t_start = Value('d', time.time())\n",
        "class_folder = ''\n",
        "class_images = Value('d', 0)\n",
        "\n",
        "def get_image(img_url):\n",
        "\n",
        "    #print(f'Processing {img_url}')\n",
        "\n",
        "    #time.sleep(3)\n",
        "\n",
        "    if len(img_url) <= 1:\n",
        "        return\n",
        "\n",
        "\n",
        "    cls_imgs = 0\n",
        "    with lock:\n",
        "        cls_imgs = class_images.value\n",
        "\n",
        "    if cls_imgs >= args.images_per_class:\n",
        "        return\n",
        "\n",
        "    logging.debug(img_url)\n",
        "\n",
        "    cls = ''\n",
        "\n",
        "    if 'flickr' in img_url:\n",
        "        cls = 'is_flickr'\n",
        "    else:\n",
        "        cls = 'not_flickr'\n",
        "        if args.scrape_only_flickr:\n",
        "            return\n",
        "\n",
        "    t_start = time.time()\n",
        "\n",
        "    def finish(status):\n",
        "        t_spent = time.time() - t_start\n",
        "        multi_stats.inc(cls, 'time_spent', t_spent)\n",
        "        multi_stats.inc('all', 'time_spent', t_spent)\n",
        "\n",
        "        multi_stats.inc(cls,'tried', 1)\n",
        "        multi_stats.inc('all', 'tried', 1)\n",
        "\n",
        "        if status == 'success':\n",
        "            multi_stats.inc(cls,'success', 1)\n",
        "            multi_stats.inc('all', 'success', 1)\n",
        "\n",
        "        elif status == 'failure':\n",
        "            pass\n",
        "        else:\n",
        "            logging.error(f'No such status {status}!!')\n",
        "            exit()\n",
        "        return\n",
        "\n",
        "\n",
        "    with lock:\n",
        "        url_tries.value += 1\n",
        "        if url_tries.value % 250 == 0:\n",
        "            print(f'\\nScraping stats:')\n",
        "            print_stats('is_flickr', print)\n",
        "            print_stats('not_flickr', print)\n",
        "            print_stats('all', print)\n",
        "            if args.debug:\n",
        "                add_stats_to_debug_csv()\n",
        "\n",
        "    try:\n",
        "        img_resp = requests.get(img_url, timeout = 1)\n",
        "    except ConnectionError:\n",
        "        logging.debug(f\"Connection Error for url {img_url}\")\n",
        "        return finish('failure')\n",
        "    except ReadTimeout:\n",
        "        logging.debug(f\"Read Timeout for url {img_url}\")\n",
        "        return finish('failure')\n",
        "    except TooManyRedirects:\n",
        "        logging.debug(f\"Too many redirects {img_url}\")\n",
        "        return finish('failure')\n",
        "    except MissingSchema:\n",
        "        return finish('failure')\n",
        "    except InvalidURL:\n",
        "        return finish('failure')\n",
        "\n",
        "    if not 'content-type' in img_resp.headers:\n",
        "        return finish('failure')\n",
        "\n",
        "    if not 'image' in img_resp.headers['content-type']:\n",
        "        logging.debug(\"Not an image\")\n",
        "        return finish('failure')\n",
        "\n",
        "    if (len(img_resp.content) < 1000):\n",
        "        return finish('failure')\n",
        "\n",
        "    logging.debug(img_resp.headers['content-type'])\n",
        "    logging.debug(f'image size {len(img_resp.content)}')\n",
        "\n",
        "    img_name = img_url.split('/')[-1]\n",
        "    img_name = img_name.split(\"?\")[0]\n",
        "\n",
        "    if (len(img_name) <= 1):\n",
        "        return finish('failure')\n",
        "\n",
        "    img_file_path = os.path.join(class_folder, img_name)\n",
        "    logging.debug(f'Saving image in {img_file_path}')\n",
        "\n",
        "    with open(img_file_path, 'wb') as img_f:\n",
        "        img_f.write(img_resp.content)\n",
        "\n",
        "        with lock:\n",
        "            class_images.value += 1\n",
        "\n",
        "        logging.debug(f'Scraping stats')\n",
        "        print_stats('is_flickr', logging.debug)\n",
        "        print_stats('not_flickr', logging.debug)\n",
        "        print_stats('all', logging.debug)\n",
        "\n",
        "        return finish('success')\n",
        "\n",
        "\n",
        "for class_wnid in classes_to_scrape:\n",
        "\n",
        "    class_name = class_info_dict[class_wnid][\"class_name\"]\n",
        "    print(f'Scraping images for class \\\"{class_name}\\\"')\n",
        "    url_urls = IMAGENET_API_WNID_TO_URLS(class_wnid)\n",
        "\n",
        "    time.sleep(0.05)\n",
        "    resp = requests.get(url_urls)\n",
        "\n",
        "    class_folder = os.path.join(imagenet_images_folder, class_name)\n",
        "    if not os.path.exists(class_folder):\n",
        "        os.mkdir(class_folder)\n",
        "\n",
        "    class_images.value = 0\n",
        "\n",
        "    urls = [url.decode('utf-8') for url in resp.content.splitlines()]\n",
        "\n",
        "    #for url in  urls:\n",
        "    #    get_image(url)\n",
        "\n",
        "    print(f\"Multiprocessing workers: {args.multiprocessing_workers}\")\n",
        "    with Pool(processes=args.multiprocessing_workers) as p:\n",
        "        p.map(get_image,urls)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download only Validation Set"
      ],
      "metadata": {
        "id": "2SlLraVFT635"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar\n",
        "! mkdir ILSVRC2012_img_val\n",
        "! mkdir ILSVRC2012_img_val/images\n",
        "! tar -xvf ILSVRC2012_img_val.tar --directory ILSVRC2012_img_val/images\n",
        "! tar -xvf ILSVRC2012_bbox_val_v3.tgz --directory ILSVRC2012_img_val/annotations/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTp6QGkL-KPP",
        "outputId": "2dcc1696-e9e8-4ed1-e632-75f92daf0dcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-05 17:39:30--  https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar\n",
            "Resolving image-net.org (image-net.org)... 171.64.68.16\n",
            "Connecting to image-net.org (image-net.org)|171.64.68.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6744924160 (6.3G) [application/x-tar]\n",
            "Saving to: ‘ILSVRC2012_img_val.tar’\n",
            "\n",
            "ILSVRC2012_img_val. 100%[===================>]   6.28G  22.9MB/s    in 3m 3s   \n",
            "\n",
            "2022-10-05 17:42:34 (35.1 MB/s) - ‘ILSVRC2012_img_val.tar’ saved [6744924160/6744924160]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ILSVRC2012_img_val/annotations"
      ],
      "metadata": {
        "id": "iFEzrZl3XCf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! tar -xvf ILSVRC2012_bbox_val_v3.tgz --directory ILSVRC2012_img_val/annotations/"
      ],
      "metadata": {
        "id": "q5TJnUZnXdJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r  ILSVRC2012_img_val/.* ILSVRC2012_img_val/images/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPKVMk1qWjII",
        "outputId": "75a41c16-8b95-4453-fd62-432d41b429e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! tar -xvf ILSVRC2012_img_val.tar --directory ILSVRC2012_img_val"
      ],
      "metadata": {
        "id": "ZeMGVxPvNJvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ILSVRC2012_img_val | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Gz5WbmCQwpY",
        "outputId": "e1de302d-c300-4ee1-9b32-943c9bfb764c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_bbox_val_v3.tgz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVOY6LC5VzPa",
        "outputId": "9c994b47-7920-4db5-bc26-fa233f342689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-05 18:17:55--  https://image-net.org/data/ILSVRC/2012/ILSVRC2012_bbox_val_v3.tgz\n",
            "Resolving image-net.org (image-net.org)... 171.64.68.16\n",
            "Connecting to image-net.org (image-net.org)|171.64.68.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2221290 (2.1M) [application/x-gzip]\n",
            "Saving to: ‘ILSVRC2012_bbox_val_v3.tgz’\n",
            "\n",
            "ILSVRC2012_bbox_val 100%[===================>]   2.12M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-10-05 18:17:55 (16.7 MB/s) - ‘ILSVRC2012_bbox_val_v3.tgz’ saved [2221290/2221290]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t56HZzprXk_9",
        "outputId": "8a5ca74b-f28d-4ed4-af26-ee9ce5cf83ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classes_in_imagenet.csv     ILSVRC2012_img_val.tar    README.md\n",
            "downloader.py\t\t    imagenet\t\t      requirements.txt\n",
            "ILSVRC2012_bbox_val_v3.tgz  imagenet_class_info.json  words.txt\n",
            "ILSVRC2012_img_val\t    prepare_stats.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1OM08LKYXnXY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}