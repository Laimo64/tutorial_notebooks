{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/SAMed_BraTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customized Segment Anything Model for Medical Image Segmentation\n",
        "### [[Paper](https://arxiv.org/pdf/2304.13785.pdf)] [[Github](https://github.com/hitachinsk/SAMed)]\n",
        "---\n",
        "[Kaidong Zhang](https://hitachinsk.github.io/), and [Dong Liu](https://faculty.ustc.edu.cn/dongeliu/), technical report, 2023\n",
        "\n",
        "All rights reserved by the authors of SAMed\n",
        "\n",
        "We provide the entire inference pipeline in this page."
      ],
      "metadata": {
        "id": "1P2M4gZbKZWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup environment"
      ],
      "metadata": {
        "id": "Id3D1PuuLQMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q einops==0.6.1 icecream==2.1.3 MedPy==0.4.0 monai==1.1.0 opencv_python==4.5.4.58 SimpleITK==2.2.1 tensorboardX==2.6 ml-collections==0.1.1 onnx==1.13.1 onnxruntime==1.14.1 tensorboardX torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmmYvx7FLUif",
        "outputId": "317bc0c7-2d14-4d55-d32b-ed528e624328"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m780.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for MedPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download codes, pretrained weights and test data"
      ],
      "metadata": {
        "id": "m-tSMFkgPhyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare codes\n",
        "import os\n",
        "CODE_DIR = 'samed_codes'\n",
        "os.makedirs(f'./{CODE_DIR}')\n",
        "!git clone https://github.com/hitachinsk/SAMed.git $CODE_DIR\n",
        "os.chdir(f'./{CODE_DIR}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyB2eYACPtEX",
        "outputId": "68e8b73f-7bc8-48ca-fbdf-f5e3902e52a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'samed_codes'...\n",
            "remote: Enumerating objects: 225, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 225 (delta 86), reused 72 (delta 72), pack-reused 123\u001b[K\n",
            "Receiving objects: 100% (225/225), 635.01 KiB | 33.42 MiB/s, done.\n",
            "Resolving deltas: 100% (105/105), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset\n",
        "!gdown https://drive.google.com/uc?id=1nHZWlCBpudbT4zzPyqyu2Vi5uILcxSrv\n",
        "import zipfile\n",
        "with zipfile.ZipFile('Slices.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "#weights\n",
        "!gdown https://drive.google.com/uc?id=1P0Bm-05l-rfeghbrT1B62v5eN-3A-uOr #'epoch_159.pth'\n",
        "!gdown https://drive.google.com/uc?id=1_oCdoEEu3mNhRfFxeWyRerOKt8OEUvcg #'sam_vit_b_01ec64.pth'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fAoOVHvAxPh",
        "outputId": "eae727b9-964a-4aa7-b31f-281efaa958f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nHZWlCBpudbT4zzPyqyu2Vi5uILcxSrv\n",
            "To: /content/samed_codes/Slices.zip\n",
            "100% 56.1M/56.1M [00:02<00:00, 25.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1P0Bm-05l-rfeghbrT1B62v5eN-3A-uOr\n",
            "To: /content/samed_codes/epoch_159.pth\n",
            "100% 19.7M/19.7M [00:00<00:00, 57.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_oCdoEEu3mNhRfFxeWyRerOKt8OEUvcg\n",
            "To: /content/samed_codes/sam_vit_b_01ec64.pth\n",
            "100% 375M/375M [00:13<00:00, 28.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataloader:"
      ],
      "metadata": {
        "id": "LnQmJASbCqUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/samed_codes\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from glob import glob\n",
        "import imageio.v2 as iio\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from scipy.ndimage import zoom\n",
        "from einops import repeat\n",
        "\n",
        "def normalise_intensity(image, ROI_thres=0.1):\n",
        "    pixel_thres = np.percentile(image, ROI_thres)\n",
        "    ROI = np.where(image > pixel_thres, image, 0) # If image value is greater than pixel threshold, return image value, otherwise return 0\n",
        "    mean = np.mean(ROI)\n",
        "    std = np.std(ROI)\n",
        "    ROI_norm = (ROI - mean) / (std + 1e-8) # Normalise ROI\n",
        "    return ROI_norm\n",
        "\n",
        "def map_labels(label):\n",
        "    label_map = {0: 0, 85: 1, 128:0, 170: 2, 255: 3}\n",
        "    mapped_label = label.copy()\n",
        "    for k, v in label_map.items():\n",
        "        mapped_label[label == k] = v\n",
        "    return mapped_label\n",
        "\n",
        "class BratsDataset(Dataset):\n",
        "    def __init__(self, root='brats_train', low_res=None,  transform=None):\n",
        "        self.img_path_all = glob(root + '/BraTS-GLI-t1c/*.png')\n",
        "        self.mask_path_all = [img_path.replace('t1c', 'seg') for img_path in self.img_path_all]\n",
        "        self.transform = transform\n",
        "        self.low_res = low_res\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.img_path_all)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = iio.imread(self.img_path_all[index])\n",
        "        image = normalise_intensity(image)\n",
        "        image = zoom(image, (512/image.shape[0], 512/image.shape[1]), order=0)\n",
        "        image = repeat(np.expand_dims(image, axis=0), 'c h w -> (repeat c) h w', repeat=3)\n",
        "        label = iio.imread(self.mask_path_all[index])\n",
        "        label = map_labels(label)\n",
        "        label = zoom(label, (512/label.shape[0], 512/label.shape[1]), order=0)\n",
        "        sample = {'image': image, 'label': label}\n",
        "        if self.low_res:\n",
        "            low_res_label = zoom(label, (self.low_res/label.shape[0], self.low_res/label.shape[1]), order=0)\n",
        "            sample = {'image': image, 'label': label, 'low_res_label': low_res_label}\n",
        "        # if self.transform:\n",
        "        #     sample = self.transform(sample)\n",
        "        return sample\n",
        "\n",
        "train_dataset = BratsDataset(root='Slices/Train', low_res=128)\n",
        "test_dataset = BratsDataset(root='Slices/Test', low_res=128)\n",
        "print('Train Sample:', len(train_dataset), 'Test Sample:', len(test_dataset))\n",
        "sample = train_dataset[7]\n",
        "input, label, low_res_label = sample['image'],sample['label'], sample['low_res_label']\n",
        "plt.subplot(1,4,1), plt.axis('OFF'), plt.title('in:{}'.format(input.shape)), plt.imshow(input.transpose(1,2,0))\n",
        "plt.subplot(1,4,2), plt.axis('OFF'), plt.title('in:{}'.format(input[0].shape)), plt.imshow(input[0], cmap='gray')\n",
        "plt.subplot(1,4,3), plt.axis('OFF'), plt.title('lab:{}'.format(label.shape)), plt.imshow(label, cmap='gray');\n",
        "plt.subplot(1,4,4), plt.axis('OFF'), plt.title('low:{}'.format(low_res_label.shape)), plt.imshow(low_res_label, cmap='gray');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "8w27C6DKCvOK",
        "outputId": "3e2475a3-2440-476a-a77e-b1b853abda1c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/samed_codes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Sample: 1395 Test Sample: 310\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAM Training"
      ],
      "metadata": {
        "id": "8j2gsPPfB45E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/samed_codes\n",
        "import os\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "from importlib import import_module\n",
        "from segment_anything import sam_model_registry\n",
        "from datasets.dataset_synapse import Synapse_dataset\n",
        "from icecream import ic\n",
        "from medpy import metric\n",
        "from scipy.ndimage import zoom\n",
        "import torch.nn as nn\n",
        "import SimpleITK as sitk\n",
        "import torch.nn.functional as F\n",
        "import imageio\n",
        "from einops import repeat\n",
        "\n",
        "from torch.nn.modules.loss import CrossEntropyLoss\n",
        "from utils import DiceLoss\n",
        "import torch.optim as optim\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    cudnn.benchmark = False\n",
        "    cudnn.deterministic = True\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "def calc_loss(outputs, low_res_label_batch, ce_loss, dice_loss, dice_weight:float=0.8):\n",
        "    low_res_logits = outputs['low_res_logits']\n",
        "    loss_ce = ce_loss(low_res_logits, low_res_label_batch[:].long())\n",
        "    loss_dice = dice_loss(low_res_logits, low_res_label_batch, softmax=True)\n",
        "    loss = (1 - dice_weight) * loss_ce + dice_weight * loss_dice\n",
        "    return loss, loss_ce, loss_dice\n",
        "\n",
        "def training_per_epoch(model, trainloader, optimizer, iter_num):\n",
        "    model.train()\n",
        "    loss_all = []\n",
        "    for i_batch, sampled_batch in enumerate(trainloader):\n",
        "        image_batch, label_batch, low_res_label_batch = sampled_batch['image'],sampled_batch['label'], sampled_batch['low_res_label']\n",
        "        image_batch, label_batch, low_res_label_batch = image_batch.to(device, dtype=torch.float32), label_batch.to(device, dtype=torch.long), low_res_label_batch.to(device, dtype=torch.long)\n",
        "        outputs = model(image_batch, multimask_output, args.img_size)\n",
        "        loss, loss_ce, loss_dice = calc_loss(outputs, low_res_label_batch, ce_loss, dice_loss)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_all.append(loss.item())\n",
        "        if args.warmup and iter_num < args.warmup_period:\n",
        "            lr_ = args.base_lr * ((iter_num + 1) / args.warmup_period)\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr_\n",
        "        else:\n",
        "            if args.warmup:\n",
        "                shift_iter = iter_num - args.warmup_period\n",
        "                assert shift_iter >= 0, f'Shift iter is {shift_iter}, smaller than zero'\n",
        "            else:\n",
        "                shift_iter = iter_num\n",
        "            lr_ = args.base_lr * (1.0 - shift_iter / args.max_iterations) ** 0.9  # learning rate adjustment depends on the max iterations\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr_\n",
        "\n",
        "        iter_num = iter_num + 1\n",
        "\n",
        "    return np.mean(loss_all)\n",
        "\n",
        "\n",
        "def test_per_epoch(model, testloader):\n",
        "    model.eval()\n",
        "    loss_per_epoch, dice_per_epoch = [], []\n",
        "    with torch.no_grad():\n",
        "        for i_batch, sampled_batch in enumerate(testloader):\n",
        "            image_batch, label_batch, low_res_label_batch = sampled_batch['image'],sampled_batch['label'], sampled_batch['low_res_label']\n",
        "            image_batch, label_batch, low_res_label_batch = image_batch.to(device, dtype=torch.float32), label_batch.to(device, dtype=torch.long), low_res_label_batch.to(device, dtype=torch.long)\n",
        "            outputs = model(image_batch, multimask_output, args.img_size)\n",
        "            loss, loss_ce, loss_dice = calc_loss(outputs, low_res_label_batch, ce_loss, dice_loss)\n",
        "            loss_per_epoch.append(loss.item())\n",
        "            dice_per_epoch.append(1-loss_dice)\n",
        "    return np.mean(loss_per_epoch), np.mean(dice_per_epoch)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--config', type=str, default=None, help='The config file provided by the trained model')\n",
        "    parser.add_argument('--volume_path', type=str, default='testset/test_vol_h5/')\n",
        "    parser.add_argument('--dataset', type=str, default='Synapse', help='Experiment name')\n",
        "    parser.add_argument('--num_classes', type=int, default=3)\n",
        "    parser.add_argument('--list_dir', type=str, default='./lists/lists_Synapse/', help='list_dir')\n",
        "    parser.add_argument('--output_dir', type=str, default='/output')\n",
        "    parser.add_argument('--img_size', type=int, default=512, help='Input image size of the network')\n",
        "    parser.add_argument('--input_size', type=int, default=224, help='The input size for training SAM model')\n",
        "    parser.add_argument('--seed', type=int,\n",
        "                        default=1234, help='random seed')\n",
        "    parser.add_argument('--is_savenii', action='store_true', help='Whether to save results during inference')\n",
        "    parser.add_argument('--deterministic', type=int, default=1, help='whether use deterministic training')\n",
        "    parser.add_argument('--ckpt', type=str, default='checkpoints/sam_vit_b_01ec64.pth',\n",
        "                        help='Pretrained checkpoint')\n",
        "    parser.add_argument('--lora_ckpt', type=str, default='checkpoints/epoch_159.pth', help='The checkpoint from LoRA')\n",
        "    parser.add_argument('--vit_name', type=str, default='vit_b', help='Select one vit model')\n",
        "    parser.add_argument('--rank', type=int, default=4, help='Rank for LoRA adaptation')\n",
        "    parser.add_argument('--module', type=str, default='sam_lora_image_encoder')\n",
        "\n",
        "    parser.add_argument('--base_lr', type=float, default=0.005, help='segmentation network learning rate')\n",
        "    parser.add_argument('--batch_size', type=int, default=12, help='batch_size per gpu')\n",
        "    parser.add_argument('--warmup', type=bool, default=True, help='If activated, warp up the learning from a lower lr to the base_lr')\n",
        "    parser.add_argument('--warmup_period', type=int, default=250, help='Warp up iterations, only valid whrn warmup is activated')\n",
        "    parser.add_argument('--AdamW', type=bool, default=True, help='If activated, use AdamW to finetune SAM model')\n",
        "    parser.add_argument('--max_epochs', type=int, default=5, help='maximum epoch number to train')\n",
        "    parser.add_argument('--max_iterations', type=int, default=30000, help='maximum epoch number to train')\n",
        "\n",
        "\n",
        "    args = parser.parse_args([])\n",
        "    args.output_dir = 'results'\n",
        "    args.ckpt = 'sam_vit_b_01ec64.pth'\n",
        "    args.lora_ckpt = 'epoch_159.pth'\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    seed_everything()\n",
        "    os.makedirs(args.output_dir, exist_ok = True)\n",
        "\n",
        "    sam, img_embedding_size = sam_model_registry[args.vit_name](image_size=args.img_size,\n",
        "                                                                    num_classes=args.num_classes,\n",
        "                                                                    checkpoint=args.ckpt, pixel_mean=[0, 0, 0],\n",
        "                                                                    pixel_std=[1, 1, 1])\n",
        "\n",
        "    pkg = import_module(args.module)\n",
        "    net = pkg.LoRA_Sam(sam, args.rank).cuda()\n",
        "    # net.load_lora_parameters(args.lora_ckpt)\n",
        "    multimask_output = True if args.num_classes > 1 else False\n",
        "    train_dataset = BratsDataset(root='Slices/Train', low_res=128)\n",
        "    test_dataset = BratsDataset(root='Slices/Test', low_res=128)\n",
        "    trainloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n",
        "    testloader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=2)\n",
        "    print('Training on:', device, 'train sample size:', len(train_dataset), 'test sample size:', len(test_dataset), 'batch:', args.batch_size)\n",
        "\n",
        "    ce_loss = CrossEntropyLoss()\n",
        "    dice_loss = DiceLoss(args.num_classes + 1)\n",
        "    b_lr = args.base_lr / args.warmup_period\n",
        "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, net.parameters()), lr=b_lr, betas=(0.9, 0.999), weight_decay=0.1)\n",
        "    iter_num = 0\n",
        "\n",
        "    best_epoch, best_loss = 0.0, np.inf\n",
        "    for epoch in range(args.max_epochs):\n",
        "        loss_training = training_per_epoch(net, trainloader, optimizer, iter_num)\n",
        "        loss_testing, dice = test_per_epoch(net, testloader)\n",
        "\n",
        "        if loss_testing < best_loss:\n",
        "            best_loss = loss_testing\n",
        "            best_epoch = epoch\n",
        "            net.save_lora_parameters(os.path.join(args.output_dir, 'model_best.pt'))\n",
        "\n",
        "        print('--- Epoch {}\\{}: Training loss = {:.4f}, Testing: [loss = {:.4f}, dice = {:.4f}], Best loss = {:.4f}, Best epoch = {} '.\\\n",
        "            format(epoch, args.max_epochs, loss_training, loss_testing, dice, best_loss, best_epoch))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXw9Wa1dDFET",
        "outputId": "038feb13-d99b-4075-a9c4-69b1e7cfed44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/samed_codes\n",
            "Training on: cuda train sample size: 1395 test sample size: 310\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Old data"
      ],
      "metadata": {
        "id": "tTfieHlKFOfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=1RczbNSB37OzPseKJZ1tDxa5OO1IIICzK\n",
        "!unzip test_vol_h5.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5fGggKuEyJk",
        "outputId": "a4623236-f1f4-4e5c-e3bf-b60351a45acb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1RczbNSB37OzPseKJZ1tDxa5OO1IIICzK\n",
            "To: /content/samed_codes/test_vol_h5.zip\n",
            "100% 267M/267M [00:03<00:00, 84.0MB/s]\n",
            "Archive:  test_vol_h5.zip\n",
            "   creating: test_vol_h5/\n",
            "  inflating: test_vol_h5/case0038.npy.h5  \n",
            "  inflating: test_vol_h5/case0036.npy.h5  \n",
            "  inflating: test_vol_h5/case0035.npy.h5  \n",
            "  inflating: test_vol_h5/case0032.npy.h5  \n",
            "  inflating: test_vol_h5/case0029.npy.h5  \n",
            "  inflating: test_vol_h5/case0025.npy.h5  \n",
            "  inflating: test_vol_h5/case0022.npy.h5  \n",
            "  inflating: test_vol_h5/case0008.npy.h5  \n",
            "  inflating: test_vol_h5/case0004.npy.h5  \n",
            "  inflating: test_vol_h5/case0003.npy.h5  \n",
            "  inflating: test_vol_h5/case0001.npy.h5  \n",
            "  inflating: test_vol_h5/case0002.npy.h5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/samed_codes\n",
        "import os\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "# from utils import test_single_volume\n",
        "from importlib import import_module\n",
        "from segment_anything import sam_model_registry\n",
        "from datasets.dataset_synapse import Synapse_dataset\n",
        "from icecream import ic\n",
        "from medpy import metric\n",
        "from scipy.ndimage import zoom\n",
        "import torch.nn as nn\n",
        "import SimpleITK as sitk\n",
        "import torch.nn.functional as F\n",
        "import imageio\n",
        "from einops import repeat\n",
        "\n",
        "from torchvision import transforms\n",
        "from datasets.dataset_synapse import Synapse_dataset, RandomGenerator\n",
        "\n",
        "\n",
        "volume_path = 'test_vol_h5'\n",
        "list_dir = './lists/lists_Synapse/'\n",
        "low_res = img_embedding_size * 4\n",
        "num_classes = 8\n",
        "\n",
        "dataset_config = {\n",
        "        'Synapse': {\n",
        "            'Dataset': Synapse_dataset,\n",
        "            'volume_path': volume_path,\n",
        "            'list_dir': list_dir,\n",
        "            'num_classes': num_classes,\n",
        "            'z_spacing': 1\n",
        "        }\n",
        "    }\n",
        "db_config = dataset_config['Synapse']\n",
        "db_test = db_config['Dataset'](base_dir=volume_path, list_dir=list_dir, split=\"test_vol\", transform=transforms.Compose(\n",
        "                                   [RandomGenerator(output_size=[args.img_size, args.img_size], low_res=[low_res, low_res])]))\n",
        "db_test[0]['image'].shape, db_test[0]['label'].shape, db_test[0]['low_res_label'].shape"
      ],
      "metadata": {
        "id": "fAGY05VuOa_0",
        "outputId": "7fee04b4-7b10-475e-d4c2-d4e99b7c8eb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/samed_codes\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 512, 512]), torch.Size([512, 512]), torch.Size([128, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "low_res"
      ],
      "metadata": {
        "id": "eZ04IX2VRvWN",
        "outputId": "ae2d071c-ac0f-4916-9969-87e4c20d38ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "filepath = '/content/samed_codes/test_vol_h5/case0001.npy.h5'\n",
        "data = h5py.File(filepath)\n",
        "image, label = data['image'][:], data['label'][:]\n",
        "image.shape, label.shape, np.unique(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P58G2pBFNYH",
        "outputId": "346d651a-814d-48b9-84d7-ca39cc284699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((147, 512, 512),\n",
              " (147, 512, 512),\n",
              " array([0., 1., 2., 3., 4., 5., 6., 7., 8.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference:"
      ],
      "metadata": {
        "id": "Kssy1bII-mhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/samed_codes\n",
        "import os\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "# from utils import test_single_volume\n",
        "from importlib import import_module\n",
        "from segment_anything import sam_model_registry\n",
        "from datasets.dataset_synapse import Synapse_dataset\n",
        "from icecream import ic\n",
        "from medpy import metric\n",
        "from scipy.ndimage import zoom\n",
        "import torch.nn as nn\n",
        "import SimpleITK as sitk\n",
        "import torch.nn.functional as F\n",
        "import imageio\n",
        "from einops import repeat\n",
        "\n",
        "\n",
        "\n",
        "class_to_name = {1: 'spleen', 2: 'right kidney', 3: 'left kidney', 4: 'gallbladder', 5: 'liver', 6: 'stomach', 7: 'aorta', 8: 'pancreas'}\n",
        "\n",
        "def calculate_metric_percase(pred, gt):\n",
        "    pred[pred > 0] = 1\n",
        "    gt[gt > 0] = 1\n",
        "    if pred.sum() > 0 and gt.sum() > 0:\n",
        "        dice = metric.binary.dc(pred, gt)\n",
        "        hd95 = metric.binary.hd95(pred, gt)\n",
        "        return dice, hd95\n",
        "    elif pred.sum() > 0 and gt.sum() == 0:\n",
        "        return 1, 0\n",
        "    else:\n",
        "        return 0, 0\n",
        "\n",
        "def test_single_volume(image, label, net, classes, multimask_output, image_size=[512, 512],\n",
        "                       test_save_path=None, case=None):\n",
        "    image, label = image.squeeze(0).cpu().detach().numpy(), label.squeeze(0).cpu().detach().numpy()\n",
        "    print('image, label:', image.shape, label.shape )\n",
        "\n",
        "    prediction = np.zeros_like(label)\n",
        "    for ind in range(image.shape[0]):\n",
        "        slice = image[ind, :, :]\n",
        "        x, y = slice.shape[0], slice.shape[1]\n",
        "        inputs = torch.from_numpy(slice).unsqueeze(0).unsqueeze(0).float().cuda()\n",
        "        inputs = repeat(inputs, 'b c h w -> b (repeat c) h w', repeat=3)\n",
        "        net.eval()\n",
        "        with torch.no_grad():\n",
        "            # print('model input:', inputs.shape)\n",
        "            outputs = net(inputs, multimask_output, image_size[0])\n",
        "            output_masks = outputs['masks']\n",
        "            out = torch.argmax(torch.softmax(output_masks, dim=1), dim=1).squeeze(0)\n",
        "            out = out.cpu().detach().numpy()\n",
        "            out_h, out_w = out.shape\n",
        "            if x != out_h or y != out_w:\n",
        "                pred = zoom(out, (x / out_h, y / out_w), order=0)\n",
        "            else:\n",
        "                pred = out\n",
        "            prediction[ind] = pred\n",
        "\n",
        "    metric_list = []\n",
        "    for i in range(1, classes + 1):\n",
        "        metric_list.append(calculate_metric_percase(prediction == i, label == i))\n",
        "\n",
        "    return metric_list\n",
        "\n",
        "def inference(args, multimask_output, db_config, model, test_save_path=None):\n",
        "    db_test = db_config['Dataset'](base_dir=args.volume_path, list_dir=args.list_dir, split='test_vol')\n",
        "    print('sample size:', len(db_test))\n",
        "    testloader = DataLoader(db_test, batch_size=1, shuffle=False, num_workers=1)\n",
        "    logging.info(f'{len(testloader)} test iterations per epoch')\n",
        "    model.eval()\n",
        "    metric_list = 0.0\n",
        "    for i_batch, sampled_batch in tqdm(enumerate(testloader)):\n",
        "        h, w = sampled_batch['image'].shape[2:]\n",
        "        image, label, case_name = sampled_batch['image'], sampled_batch['label'], sampled_batch['case_name'][0]\n",
        "        print(image.shape, label.shape)\n",
        "        metric_i = test_single_volume(image, label, model, classes=args.num_classes, multimask_output=multimask_output,\n",
        "                                      image_size=[args.img_size, args.img_size],\n",
        "                                      test_save_path=test_save_path, case=case_name)\n",
        "        metric_list += np.array(metric_i)\n",
        "        print('idx %d case %s mean_dice %f mean_hd95 %f' % (\n",
        "            i_batch, case_name, np.mean(metric_i, axis=0)[0], np.mean(metric_i, axis=0)[1]))\n",
        "        logging.info('idx %d case %s mean_dice %f mean_hd95 %f' % (\n",
        "            i_batch, case_name, np.mean(metric_i, axis=0)[0], np.mean(metric_i, axis=0)[1]))\n",
        "        if i_batch == 0:\n",
        "            break\n",
        "    metric_list = metric_list / len(db_test)\n",
        "    for i in range(1, args.num_classes + 1):\n",
        "        try:\n",
        "            logging.info('Mean class %d name %s mean_dice %f mean_hd95 %f' % (i, class_to_name[i], metric_list[i - 1][0], metric_list[i - 1][1]))\n",
        "        except:\n",
        "            logging.info('Mean class %d mean_dice %f mean_hd95 %f' % (i, metric_list[i - 1][0], metric_list[i - 1][1]))\n",
        "    performance = np.mean(metric_list, axis=0)[0]\n",
        "    mean_hd95 = np.mean(metric_list, axis=0)[1]\n",
        "    logging.info('Testing performance in best val model: mean_dice : %f mean_hd95 : %f' % (performance, mean_hd95))\n",
        "    logging.info(\"Testing Finished!\")\n",
        "    return 1\n",
        "\n",
        "\n",
        "def config_to_dict(config):\n",
        "    items_dict = {}\n",
        "    with open(config, 'r') as f:\n",
        "        items = f.readlines()\n",
        "    for i in range(len(items)):\n",
        "        key, value = items[i].strip().split(': ')\n",
        "        items_dict[key] = value\n",
        "    return items_dict\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--config', type=str, default=None, help='The config file provided by the trained model')\n",
        "    parser.add_argument('--volume_path', type=str, default='testset/test_vol_h5/')\n",
        "    parser.add_argument('--dataset', type=str, default='Synapse', help='Experiment name')\n",
        "    parser.add_argument('--num_classes', type=int, default=8)\n",
        "    parser.add_argument('--list_dir', type=str, default='./lists/lists_Synapse/', help='list_dir')\n",
        "    parser.add_argument('--output_dir', type=str, default='/output')\n",
        "    parser.add_argument('--img_size', type=int, default=512, help='Input image size of the network')\n",
        "    parser.add_argument('--input_size', type=int, default=224, help='The input size for training SAM model')\n",
        "    parser.add_argument('--seed', type=int,\n",
        "                        default=1234, help='random seed')\n",
        "    parser.add_argument('--is_savenii', action='store_true', help='Whether to save results during inference')\n",
        "    parser.add_argument('--deterministic', type=int, default=1, help='whether use deterministic training')\n",
        "    parser.add_argument('--ckpt', type=str, default='checkpoints/sam_vit_b_01ec64.pth',\n",
        "                        help='Pretrained checkpoint')\n",
        "    parser.add_argument('--lora_ckpt', type=str, default='checkpoints/epoch_159.pth', help='The checkpoint from LoRA')\n",
        "    parser.add_argument('--vit_name', type=str, default='vit_b', help='Select one vit model')\n",
        "    parser.add_argument('--rank', type=int, default=4, help='Rank for LoRA adaptation')\n",
        "    parser.add_argument('--module', type=str, default='sam_lora_image_encoder')\n",
        "\n",
        "    args = parser.parse_args([])\n",
        "    args.volume_path = 'test_vol_h5'\n",
        "    args.output_dir = 'results'\n",
        "    args.ckpt = 'sam_vit_b_01ec64.pth'\n",
        "    args.lora_ckpt = 'epoch_159.pth'\n",
        "\n",
        "    if args.config is not None:\n",
        "        # overwtite default configurations with config file\\\n",
        "        config_dict = config_to_dict(args.config)\n",
        "        for key in config_dict:\n",
        "            setattr(args, key, config_dict[key])\n",
        "\n",
        "    if not args.deterministic:\n",
        "        cudnn.benchmark = True\n",
        "        cudnn.deterministic = False\n",
        "    else:\n",
        "        cudnn.benchmark = False\n",
        "        cudnn.deterministic = True\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "    dataset_name = args.dataset\n",
        "    dataset_config = {\n",
        "        'Synapse': {\n",
        "            'Dataset': Synapse_dataset,\n",
        "            'volume_path': args.volume_path,\n",
        "            'list_dir': args.list_dir,\n",
        "            'num_classes': args.num_classes,\n",
        "            'z_spacing': 1\n",
        "        }\n",
        "    }\n",
        "    if not os.path.exists(args.output_dir):\n",
        "        os.makedirs(args.output_dir)\n",
        "\n",
        "    # register model\n",
        "    sam, img_embedding_size = sam_model_registry[args.vit_name](image_size=args.img_size,\n",
        "                                                                    num_classes=args.num_classes,\n",
        "                                                                    checkpoint=args.ckpt, pixel_mean=[0, 0, 0],\n",
        "                                                                    pixel_std=[1, 1, 1])\n",
        "\n",
        "    pkg = import_module(args.module)\n",
        "    net = pkg.LoRA_Sam(sam, args.rank).cuda()\n",
        "\n",
        "    assert args.lora_ckpt is not None\n",
        "    net.load_lora_parameters(args.lora_ckpt)\n",
        "\n",
        "    if args.num_classes > 1:\n",
        "        multimask_output = True\n",
        "    else:\n",
        "        multimask_output = False\n",
        "\n",
        "    # initialize log\n",
        "    log_folder = os.path.join(args.output_dir, 'test_log')\n",
        "    os.makedirs(log_folder, exist_ok=True)\n",
        "    logging.basicConfig(filename=log_folder + '/' + 'log.txt', level=logging.INFO,\n",
        "                        format='[%(asctime)s.%(msecs)03d] %(message)s', datefmt='%H:%M:%S')\n",
        "    logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))\n",
        "    logging.info(str(args))\n",
        "\n",
        "    if args.is_savenii:\n",
        "        test_save_path = os.path.join(args.output_dir, 'predictions')\n",
        "        os.makedirs(test_save_path, exist_ok=True)\n",
        "    else:\n",
        "        test_save_path = None\n",
        "    inference(args, multimask_output, dataset_config[dataset_name], net, test_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y2mu4ndPfOZ",
        "outputId": "9c241052-d2ff-4169-b8f2-2eb2d82a6587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/samed_codes\n",
            "sample size: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 148, 512, 512]) torch.Size([1, 148, 512, 512])\n",
            "image, label: (148, 512, 512) (148, 512, 512)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [02:27, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx 0 case case0008 mean_dice 0.681535 mean_hd95 16.097952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing with command:"
      ],
      "metadata": {
        "id": "dPc3iQTZ-pTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "python test.py --volume_path test_vol_h5 --output_dir results --ckpt sam_vit_b_01ec64.pth --lora_ckpt epoch_159.pth"
      ],
      "metadata": {
        "id": "TsKn0gVsSUYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tEWvz8iy2N-3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}