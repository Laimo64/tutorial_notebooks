{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/VQA_BioGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BioGPT\n",
        "\n",
        "SRC: https://github.com/microsoft/BioGPT.git"
      ],
      "metadata": {
        "id": "BEYoysgQrL5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install fairseq moses fastBPE sacremoses"
      ],
      "metadata": {
        "id": "U3CtLsoOFbzC",
        "outputId": "9eadb2ae-c57a-41dc-d486-89c5a54f7efd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.4/240.4 KB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for moses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints\n",
        "%cd checkpoints\n",
        "!wget https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/Pre-trained-BioGPT.tgz\n",
        "!tar -zxvf Pre-trained-BioGPT.tgz\n",
        "%cd .."
      ],
      "metadata": {
        "id": "6e-sA-MPo8gw",
        "outputId": "95f4a457-39ff-4602-9284-1c68e8ee0d42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/checkpoints\n",
            "--2023-02-04 13:38:35--  https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/Pre-trained-BioGPT.tgz\n",
            "Resolving msramllasc.blob.core.windows.net (msramllasc.blob.core.windows.net)... 20.209.34.164\n",
            "Connecting to msramllasc.blob.core.windows.net (msramllasc.blob.core.windows.net)|20.209.34.164|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3414384105 (3.2G) [application/octet-stream]\n",
            "Saving to: ‘Pre-trained-BioGPT.tgz’\n",
            "\n",
            "Pre-trained-BioGPT. 100%[===================>]   3.18G  23.5MB/s    in 1m 54s  \n",
            "\n",
            "2023-02-04 13:40:30 (28.5 MB/s) - ‘Pre-trained-BioGPT.tgz’ saved [3414384105/3414384105]\n",
            "\n",
            "Pre-trained-BioGPT/\n",
            "Pre-trained-BioGPT/checkpoint.pt\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/1-kEJF9LS5_Fb-D-09lWMfzpx8169an8k/view?usp=sharing\n",
        "!curl -L -s -o data.zip 'https://drive.google.com/uc?id=1-kEJF9LS5_Fb-D-09lWMfzpx8169an8k'\n",
        "!unzip -q data.zip"
      ],
      "metadata": {
        "id": "lF7ajewUp3TC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from fairseq.models.transformer_lm import TransformerLanguageModel\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "m = TransformerLanguageModel.from_pretrained(\n",
        "        \"checkpoints/Pre-trained-BioGPT\", \n",
        "        \"checkpoint.pt\", \n",
        "        \"data\",\n",
        "        tokenizer='moses', \n",
        "        bpe='fastbpe', \n",
        "        bpe_codes=\"data/bpecodes\",\n",
        "        min_len=100,\n",
        "        max_len_b=1024)\n",
        "m.to(device)\n",
        "src_tokens = m.encode(\"COVID-19 is a disease\")\n",
        "generate = m.generate([src_tokens], beam=5)[0]\n",
        "output = m.decode(generate[0][\"tokens\"])\n",
        "print(output)"
      ],
      "metadata": {
        "id": "rQBfi4Xao9I2",
        "outputId": "998ad9f5-5823-4b72-bf02-869127747f88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COVID-19 is a disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), which was first identified in Wuhan, China, in December 2019 and has since spread to more than 200 countries and territories, including the United States, Canada, the United Kingdom, the United States of America, the United States of America, Australia, New Zealand, Canada, and the United States of America, as well as the rest of the world, including Europe, Asia, Africa, and South America.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample prediction-1:"
      ],
      "metadata": {
        "id": "81PlcHSUtFRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_tokens = m.encode(\"HIV is a\")\n",
        "generate = m.generate([src_tokens], beam=2)[0]\n",
        "output = m.decode(generate[0][\"tokens\"])\n",
        "print(generate[0]['positional_scores'].shape)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "yonH3SJvrd-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample prediction-2:"
      ],
      "metadata": {
        "id": "Qw_uls-RtJtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_tokens = m.encode(\"HIV is a virus from\")\n",
        "generate = m.generate([src_tokens], beam=2)[0]\n",
        "output = m.decode(generate[0][\"tokens\"])\n",
        "print(generate[0]['positional_scores'].shape)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "ZBAEwePfsYK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BioGPT for PubMedQA:\n",
        "Dataset Src: https://pubmedqa.github.io/\n",
        "\n",
        "Download pretrained weights:"
      ],
      "metadata": {
        "id": "GaiqK7f1u_sE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L -s -o QA-PubMedQA-BioGPT.tgz 'https://msramllasc.blob.core.windows.net/modelrelease/BioGPT/checkpoints/QA-PubMedQA-BioGPT.tgz'"
      ],
      "metadata": {
        "id": "q_yobLZiso6Z",
        "outputId": "52d6782d-74fd-4b05-869e-cada0adec277",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rzAyRbsju3kG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}