{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONlk/nstZMLTDQMQTqly6D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/triangulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Triangulate image points to world points comparing openCV to pure python"
      ],
      "metadata": {
        "id": "b-6Mli1Cm_hy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
        "\n",
        "\n",
        "def triangulate_nviews(P, ip):\n",
        "    \"\"\"\n",
        "    Triangulate a point visible in n camera views.\n",
        "    P is a list of camera projection matrices.\n",
        "    ip is a list of homogenised image points. eg [ [x, y, 1], [x, y, 1] ], OR,\n",
        "    ip is a 2d array - shape nx3 - [ [x, y, 1], [x, y, 1] ]\n",
        "    len of ip must be the same as len of P\n",
        "    \"\"\"\n",
        "    if not len(ip) == len(P):\n",
        "        raise ValueError('Number of points and number of cameras not equal.')\n",
        "    n = len(P)\n",
        "    M = np.zeros([3*n, 4+n])\n",
        "    for i, (x, p) in enumerate(zip(ip, P)):\n",
        "        M[3*i:3*i+3, :4] = p\n",
        "        M[3*i:3*i+3, 4+i] = -x\n",
        "    V = np.linalg.svd(M)[-1]\n",
        "    X = V[-1, :4]\n",
        "    return X / X[3]\n",
        "\n",
        "\n",
        "def triangulate_points(P1, P2, x1, x2):\n",
        "    \"\"\"\n",
        "    Two-view triangulation of points in\n",
        "    x1,x2 (nx3 homog. coordinates).\n",
        "    Similar to openCV triangulatePoints.\n",
        "    \"\"\"\n",
        "    if not len(x2) == len(x1):\n",
        "        raise ValueError(\"Number of points don't match.\")\n",
        "    X = [triangulate_nviews([P1, P2], [x[0], x[1]]) for x in zip(x1, x2)]\n",
        "    return np.array(X)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Data\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# 3 camera projection matrices\n",
        "P1 = np.array([[5.010e+03, 0.000e+00, 3.600e+02, 0.000e+00],\n",
        "               [0.000e+00, 5.010e+03, 6.400e+02, 0.000e+00],\n",
        "               [0.000e+00, 0.000e+00, 1.000e+00, 0.000e+00]])\n",
        "\n",
        "P2 = np.array([[5.037e+03, -9.611e+01, -1.756e+03, 4.284e+03],\n",
        "               [2.148e+02,  5.354e+03,  1.918e+02, 8.945e+02],\n",
        "               [3.925e-01,  7.092e-02,  9.169e-01, 4.930e-01]])\n",
        "\n",
        "P3 = np.array([[5.217e+03,  2.246e+02,  2.366e+03, -3.799e+03],\n",
        "               [-5.734e+02,  5.669e+03,  8.233e+02, -2.567e+02],\n",
        "               [-3.522e-01, -5.839e-02,  9.340e-01,  6.459e-01]])\n",
        "\n",
        "# 3 corresponding image points - nx2 arrays, n=1\n",
        "x1 = np.array([[274.128, 624.409]])\n",
        "x2 = np.array([[239.571, 533.568]])\n",
        "x3 = np.array([[297.574, 549.260]])\n",
        "\n",
        "# 3 corresponding homogeneous image points - nx3 arrays, n=1\n",
        "x1h = np.array([[274.128, 624.409, 1.0]])\n",
        "x2h = np.array([[239.571, 533.568, 1.0]])\n",
        "x3h = np.array([[297.574, 549.260, 1.0]])\n",
        "\n",
        "# 3 corresponding homogeneous image points - nx3 arrays, n=2\n",
        "x1h2 = np.array([[274.129, 624.409, 1.0], [322.527, 624.869, 1.0]])\n",
        "x2h2 = np.array([[239.572, 533.568, 1.0], [284.507, 534.572, 1.0]])\n",
        "x3h2 = np.array([[297.575, 549.260, 1.0], [338.942, 546.567, 1.0]])\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Test\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "print('Triangulate 3d points - units in meters')\n",
        "# triangulatePoints requires 2xn arrays, so transpose the points\n",
        "p = cv2.triangulatePoints(P1, P2, x1.T, x2.T)\n",
        "# however, homgeneous point is returned\n",
        "p /= p[3]\n",
        "print('Projected point from openCV:',  p.T)\n",
        "\n",
        "p = triangulate_nviews([P1, P2], [x1h, x2h])\n",
        "print('Projected point from 2 camera views:',  p)\n",
        "\n",
        "p = triangulate_nviews([P1, P2, P3], [x1h, x2h, x3h])\n",
        "print('Projected point from 3 camera views:',  p)\n",
        "\n",
        "# cv2 two image points - not homgeneous on input\n",
        "p = cv2.triangulatePoints(P1, P2, x1h2[:, :2].T, x2h2[:, :2].T)\n",
        "p /= p[3]\n",
        "print('Projected points from openCV:\\n', p.T)\n",
        "\n",
        "p = triangulate_points(P1, P2, x1h2, x2h2)\n",
        "print('Projected point from code:\\n',  p)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Timing\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "t1 = time.time()\n",
        "for i in range(10000):\n",
        "    p = cv2.triangulatePoints(P1, P2, x1.T, x2.T)\n",
        "    p /= p[3]\n",
        "t2 = time.time()\n",
        "print('Elapsed time cv2:', t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "for i in range(10000):\n",
        "    p = triangulate_nviews([P1, P2], [x1h, x2h])\n",
        "t2 = time.time()\n",
        "print('Elapsed time sfm:', t2-t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPD3CpvokEu5",
        "outputId": "97224dac-c28f-47b5-e1bf-c767fca7053d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Triangulate 3d points - units in meters\n",
            "Projected point from openCV: [[-0.035 -0.006  2.022  1.000]]\n",
            "Projected point from 2 camera views: [-0.034 -0.006  2.023  1.000]\n",
            "Projected point from 3 camera views: [-0.004  0.062  2.011  1.000]\n",
            "Projected points from openCV:\n",
            " [[-0.035 -0.006  2.022  1.000]\n",
            " [-0.015 -0.006  2.018  1.000]]\n",
            "Projected point from code:\n",
            " [[-0.034 -0.006  2.023  1.000]\n",
            " [-0.015 -0.006  2.019  1.000]]\n",
            "Elapsed time cv2: 0.11631059646606445\n",
            "Elapsed time sfm: 0.6416676044464111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 2:<br>\n",
        "https://www.programcreek.com/python/?code=Huangying-Zhan%2FDF-VO%2FDF-VO-master%2Flibs%2Fgeometry%2Fops_3d.py\n"
      ],
      "metadata": {
        "id": "AEsIxK3InB-E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFzDBAHHivv1"
      },
      "outputs": [],
      "source": [
        "def triangulation(kp1, kp2, T_1w, T_2w):\n",
        "    \"\"\"Triangulation to get 3D points\n",
        "    Args:\n",
        "        kp1 (Nx2): keypoint in view 1 (normalized)\n",
        "        kp2 (Nx2): keypoints in view 2 (normalized)\n",
        "        T_1w (4x4): pose of view 1 w.r.t  i.e. T_1w (from w to 1)\n",
        "        T_2w (4x4): pose of view 2 w.r.t world, i.e. T_2w (from w to 2)\n",
        "    Returns:\n",
        "        X (3xN): 3D coordinates of the keypoints w.r.t world coordinate\n",
        "        X1 (3xN): 3D coordinates of the keypoints w.r.t view1 coordinate\n",
        "        X2 (3xN): 3D coordinates of the keypoints w.r.t view2 coordinate\n",
        "    \"\"\"\n",
        "    kp1_3D = np.ones((3, kp1.shape[0]))\n",
        "    kp2_3D = np.ones((3, kp2.shape[0]))\n",
        "    kp1_3D[0], kp1_3D[1] = kp1[:, 0].copy(), kp1[:, 1].copy()\n",
        "    kp2_3D[0], kp2_3D[1] = kp2[:, 0].copy(), kp2[:, 1].copy()\n",
        "    X = cv2.triangulatePoints(T_1w[:3], T_2w[:3], kp1_3D[:2], kp2_3D[:2])\n",
        "    X /= X[3]\n",
        "    X1 = T_1w[:3] @ X\n",
        "    X2 = T_2w[:3] @ X\n",
        "    return X[:3], X1, X2 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example-x <br>\n",
        "So the setting is given a coordinate system shown below where the z-axis is pointing out of the screen (towards you), the camera focal length is 270 pixels and image resolution is 640x480, then we have an object somewhere in 3D space, and two drones d1 and d2 taking two observations at two different viewpoints, where is d1 is at (6, 3, 2) and the corresponding image coordinate of the object is (320, 280), and that of d2 is (9.5, 4.5, 3) and (160, 408), also the heading of d1 is -20 degrees from the y-axis and that of d2 is +30 degrees from y-axis, the goal is to determine (x, y, z) where the object is at, the drones are hovering over the xy plane\n",
        "<img src=\"https://i.stack.imgur.com/vHI9a.png\" width=\"400\"/>\n",
        "\n",
        "Given the information, by letting d1 be the reference frame, we can have the camera intrinsics K = [[270, 0, 320], [0, 270, 240], [0, 0, 1]], the transformation is rotate +50 degrees with z-axis as the rotation axis, and translation t = [3.5, 1.5, 1]\n"
      ],
      "metadata": {
        "id": "ejzRFRAVo1lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pixel2cam(pt, K):\n",
        "    u = (pt[0] - K[0][2]) / K[0][0]\n",
        "    v = (pt[1] - K[1][2]) / K[1][1]\n",
        "    return np.array([u, v], dtype=np.float32)\n",
        "\n",
        "def triangulate(points_1, points_2, K, R, t):\n",
        "    T1 = np.array([[1, 0, 0, 0], \n",
        "                   [0, 1, 0, 0], \n",
        "                   [0, 0, 1, 0]], dtype=np.float32)\n",
        "    T2 = np.hstack((R, t))\n",
        "    proj1 = np.matmul(K, T1)\n",
        "    proj2 = np.matmul(K, T2)\n",
        "    X = cv2.triangulatePoints(proj1, proj2, points_1, points_2)\n",
        "    X /= X[3]\n",
        "    return X\n",
        "\n",
        "K = np.array([[270, 0, 320], [0, 270, 240], [0, 0, 1]], dtype=np.float32)\n",
        "# rotate +50 degrees along z axis\n",
        "rotation_vector = np.array([0, -50 / 180 * np.pi, 0])\n",
        "R, _ = cv2.Rodrigues(rotation_vector)\n",
        "t = np.array([[3.5], [1.5], [1]], dtype=np.float)\n",
        "\n",
        "pt_1 = (320, 280)\n",
        "pt_2 = (160, 408)\n",
        "\n",
        "X = triangulate(pt_1, pt_2, K, R, t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY33iG1zo12N",
        "outputId": "f00bea01-9527-4035-cdef-120a2559e86c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-9ceae85dd3e3>:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  t = np.array([[3.5], [1.5], [1]], dtype=np.float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example-x:"
      ],
      "metadata": {
        "id": "2avbmwyRraDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Camera projection matrices\n",
        "P1 = np.eye(4)\n",
        "P2 = np.array([[ 0.878, -0.01 ,  0.479, -1.995],\n",
        "            [ 0.01 ,  1.   ,  0.002, -0.226],\n",
        "            [-0.479,  0.002,  0.878,  0.615],\n",
        "            [ 0.   ,  0.   ,  0.   ,  1.   ]])\n",
        "# Homogeneous arrays\n",
        "a3xN = np.array([[ 0.091,  0.167,  0.231,  0.083,  0.154],\n",
        "              [ 0.364,  0.333,  0.308,  0.333,  0.308],\n",
        "              [ 1.   ,  1.   ,  1.   ,  1.   ,  1.   ]])\n",
        "b3xN = np.array([[ 0.42 ,  0.537,  0.645,  0.431,  0.538],\n",
        "              [ 0.389,  0.375,  0.362,  0.357,  0.345],\n",
        "              [ 1.   ,  1.   ,  1.   ,  1.   ,  1.   ]])\n",
        "# The cv2 method\n",
        "X = cv2.triangulatePoints( P1[:3], P2[:3], a3xN[:2], b3xN[:2] )\n",
        "# Remember to divide out the 4th row. Make it homogeneous\n",
        "X /= X[3]\n",
        "# Recover the origin arrays from PX\n",
        "x1 = np.dot(P1[:3],X)\n",
        "x2 = np.dot(P2[:3],X)\n",
        "# Again, put in homogeneous form before using them\n",
        "x1 /= x1[2]\n",
        "x2 /= x2[2]\n",
        " \n",
        "print ('X\\n', X)\n",
        "print ('x1\\n', x1)\n",
        "print ('x2\\n', x2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3qIIbHXrb_6",
        "outputId": "e2c643d5-43a3-42c2-e249-8e9b78757af9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X\n",
            " [[ 1.003  2.009  3.013  1.004  2.011]\n",
            " [ 4.012  4.010  4.017  4.030  4.019]\n",
            " [ 11.020  12.029  13.042  12.092  13.055]\n",
            " [ 1.000  1.000  1.000  1.000  1.000]]\n",
            "x1\n",
            " [[ 0.091  0.167  0.231  0.083  0.154]\n",
            " [ 0.364  0.333  0.308  0.333  0.308]\n",
            " [ 1.000  1.000  1.000  1.000  1.000]]\n",
            "x2\n",
            " [[ 0.420  0.537  0.645  0.431  0.538]\n",
            " [ 0.389  0.375  0.362  0.357  0.345]\n",
            " [ 1.000  1.000  1.000  1.000  1.000]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example-3"
      ],
      "metadata": {
        "id": "0HUwq9VGncV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def triangulatePoints( P1, P2, x1, x2 ):\n",
        "    X = cv2.triangulatePoints( P1[:3], P2[:3], x1[:2], x2[:2] )\n",
        "    return X/X[3]\n",
        "\n",
        "X = triangulatePoints( P1, P2, a3xN, b3xN )\n",
        "# Remember to divide out the 4th row. Make it homogeneous\n",
        "X /= X[3]\n",
        "# Recover the origin arrays from PX\n",
        "x1 = np.dot(P1[:3],X)\n",
        "x2 = np.dot(P2[:3],X)\n",
        "# Again, put in homogeneous form before using them\n",
        "x1 /= x1[2]\n",
        "x2 /= x2[2]\n",
        " \n",
        "print ('X\\n', X)\n",
        "print ('x1\\n', x1)\n",
        "print ('x2\\n', x2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygnhmaWWr2oQ",
        "outputId": "fb0b53aa-bdf8-4ee3-9366-cc30beddbf80"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X\n",
            " [[ 1.003  2.009  3.013  1.004  2.011]\n",
            " [ 4.012  4.010  4.017  4.030  4.019]\n",
            " [ 11.020  12.029  13.042  12.092  13.055]\n",
            " [ 1.000  1.000  1.000  1.000  1.000]]\n",
            "x1\n",
            " [[ 0.091  0.167  0.231  0.083  0.154]\n",
            " [ 0.364  0.333  0.308  0.333  0.308]\n",
            " [ 1.000  1.000  1.000  1.000  1.000]]\n",
            "x2\n",
            " [[ 0.420  0.537  0.645  0.431  0.538]\n",
            " [ 0.389  0.375  0.362  0.357  0.345]\n",
            " [ 1.000  1.000  1.000  1.000  1.000]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Old_version"
      ],
      "metadata": {
        "id": "Iq0296s-sEmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "# from gi.repository import GExiv2\n",
        "from gi.repository import GObject\n",
        "import pcl\n",
        "# import display_vtk\n",
        "import cam_db\n",
        "\n",
        "def sort_images(directory):\n",
        "    return sorted([ str(directory + \"/\" + img) for img in os.listdir(directory) if img.rpartition('.')[2].lower() in ('jpg', 'jpeg', 'png', 'pgm', 'ppm') ])\n",
        "\n",
        "def load_images(filename1, filename2):\n",
        "    '''Loads 2 images.'''\n",
        "    # img1 and img2 are HxWx3 arrays (rows, columns, 3-colour channels)\n",
        "    img1 = cv2.imread(filename1)\n",
        "    img2 = cv2.imread(filename2)\n",
        "    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
        "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    return img1, img2\n",
        "\n",
        "def build_calibration_matrices(i, prev_sensor, K_matrices, filename1, filename2):\n",
        "    '''Extract exif metadata from image files, and use them to build the 2 calibration matrices.'''\n",
        "\n",
        "    def get_sensor_sizes(i, prev_sensor, metadata1, metadata2):\n",
        "        '''Looks up sensor width from the database based on the camera model.'''\n",
        "        # focal length in pixels = (image width in pixels) * (focal length in mm) / (CCD width in mm)\n",
        "        if i == 0:\n",
        "            sensor_1 = cam_db.get_sensor_size(metadata1['Exif.Image.Model'].strip().upper())\n",
        "            sensor_2 = cam_db.get_sensor_size(metadata2['Exif.Image.Model'].strip().upper())\n",
        "        elif i >= 1:\n",
        "            sensor_1 = prev_sensor\n",
        "            sensor_2 = cam_db.get_sensor_size(metadata2['Exif.Image.Model'])\n",
        "\n",
        "        return sensor_1, sensor_2\n",
        "\n",
        "    metadata1 = GObject.Metadata(filename1)\n",
        "    metadata2 = GObject.Metadata(filename2)\n",
        "\n",
        "    if metadata1.get_supports_exif() and metadata2.get_supports_exif():\n",
        "            sensor_1, sensor_2 = get_sensor_sizes(i, prev_sensor, metadata1, metadata2)\n",
        "    else:\n",
        "        if metadata1.get_supports_exif() == False:\n",
        "                print (\"Exif data not available for \", filename1)\n",
        "        if metadata2.get_supports_exif() == False:\n",
        "                print (\"Exif data not available for \", filename2)\n",
        "        sys.exit(\"Please try again.\")\n",
        "\n",
        "    # Calibration matrix for camera 1 (K1)\n",
        "    f1_mm = metadata1.get_focal_length()\n",
        "    w1 = metadata1.get_pixel_width()\n",
        "    h1 = metadata1.get_pixel_height()\n",
        "    f1_px = (w1 * f1_mm) / sensor_1\n",
        "    K1 = np.array([[f1_px, 0, w1/2], [0, f1_px, h1/2], [0,0,1]])\n",
        "\n",
        "    # Calibration matrix for camera 2 (K2)\n",
        "    f2_mm = metadata2.get_focal_length()\n",
        "    w2 = metadata2.get_pixel_width()\n",
        "    h2 = metadata2.get_pixel_height()\n",
        "    f2_px = (w2 * f2_mm) / sensor_2\n",
        "    K2 = np.array([[f2_px, 0, w2/2], [0, f2_px, h2/2], [0,0,1]])\n",
        "\n",
        "    if i == 0:\n",
        "        K_matrices.append(K1)\n",
        "        K_matrices.append(K2)\n",
        "    elif i >= 1:\n",
        "        K_matrices.append(K2)\n",
        "\n",
        "    return sensor_2, K_matrices\n",
        "\n",
        "def gray_images(img1, img2):\n",
        "    '''Convert images to grayscale if the images are found.'''\n",
        "    try:\n",
        "        img1_gray = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
        "        img2_gray = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
        "    except:\n",
        "        print (\"Image not found!\")\n",
        "\n",
        "    return img1_gray, img2_gray\n",
        "\n",
        "def normalize_points(K_matrices, src_pts, dst_pts):\n",
        "    '''Normalize points by multiplying them with the inverse of the K matrix.'''\n",
        "    # convert to 3xN arrays by making the points homogeneous\n",
        "    src_pts = np.vstack((np.array([ pt[0] for pt in src_pts ]).T, np.ones(src_pts.shape[0])))\n",
        "    dst_pts = np.vstack((np.array([ pt[0] for pt in dst_pts ]).T, np.ones(dst_pts.shape[0])))\n",
        "\n",
        "    # normalize with the calibration matrices\n",
        "    # norm_pts1 and norm_pts2 are 3xN arrays\n",
        "    K1 = K_matrices[-2]\n",
        "    K2 = K_matrices[-1]\n",
        "    norm_pts1 = np.dot(np.linalg.inv(K1), src_pts)\n",
        "    norm_pts2 = np.dot(np.linalg.inv(K2), dst_pts)\n",
        "\n",
        "    # convert back to Nx1x2 arrays\n",
        "    norm_pts1 = np.array([ [pt] for pt in norm_pts1[:2].T ])\n",
        "    norm_pts2 = np.array([ [pt] for pt in norm_pts2[:2].T ])\n",
        "\n",
        "    return norm_pts1, norm_pts2\n",
        "\n",
        "def find_essential_matrix(K_matrices, norm_pts1, norm_pts2):\n",
        "    '''Estimate an essential matrix that satisfies the epipolar constraint for all the corresponding points.'''\n",
        "    # K = K1, the calibration matrix of the first camera of the current image pair \n",
        "    K = K_matrices[-2]\n",
        "    # convert to Nx2 arrays for findFundamentalMat\n",
        "    norm_pts1 = np.array([ pt[0] for pt in norm_pts1 ])\n",
        "    norm_pts2 = np.array([ pt[0] for pt in norm_pts2 ])\n",
        "    # inliers (1 in mask) are features that satisfy the epipolar constraint\n",
        "    F, mask = cv2.findFundamentalMat(norm_pts1, norm_pts2, cv2.RANSAC)\n",
        "    E = np.dot(K.T, np.dot(F, K))\n",
        "\n",
        "    return E, mask\n",
        "\n",
        "def find_projection_matrices(E, poses):\n",
        "    '''Compute the second camera matrix (assuming the first camera matrix = [I 0]).\n",
        "    Output is a list of 4 possible camera matrices for P2.'''\n",
        "    # the first camera matrix is assumed to be the identity matrix for the first image,\n",
        "    # or the pose of the camera for the second and subsequent images\n",
        "    P1 = poses[-1]\n",
        "        \n",
        "    # make sure E is rank 2\n",
        "    U, S, V = np.linalg.svd(E)\n",
        "    if np.linalg.det(np.dot(U, V)) < 0:\n",
        "        V = -V\n",
        "    E = np.dot(U, np.dot(np.diag([1,1,0]), V))\n",
        "\n",
        "    # create matrices\n",
        "    W = np.array([[0,-1,0], [1,0,0], [0,0,1]])\n",
        "\n",
        "    # return all four solutions\n",
        "    P2 = [np.vstack( (np.dot(U,np.dot(W,V)).T, U[:,2]) ).T, \n",
        "          np.vstack( (np.dot(U,np.dot(W,V)).T, -U[:,2]) ).T,\n",
        "          np.vstack( (np.dot(U,np.dot(W.T,V)).T, U[:,2]) ).T, \n",
        "          np.vstack( (np.dot(U,np.dot(W.T,V)).T, -U[:,2]) ).T]\n",
        "\n",
        "    return P1, P2\n",
        "\n",
        "def apply_mask(mask, norm_pts1, norm_pts2):\n",
        "    '''Keep only those points that satisfy the epipolar constraint.'''\n",
        "    norm_pts1 = norm_pts1[mask.ravel()==1]\n",
        "    norm_pts2 = norm_pts2[mask.ravel()==1]\n",
        "    return norm_pts1, norm_pts2\n",
        "\n",
        "def refine_points(norm_pts1, norm_pts2, E):\n",
        "    '''Refine the coordinates of the corresponding points using the Optimal Triangulation Method.'''\n",
        "    # convert to 1xNx2 arrays for cv2.correctMatches\n",
        "    refined_pts1 = np.array([ [pt[0] for pt in norm_pts1 ] ])\n",
        "    refined_pts2 = np.array([ [pt[0] for pt in norm_pts2 ] ])\n",
        "    refined_pts1, refined_pts2 = cv2.correctMatches(E, refined_pts1, refined_pts2)\n",
        "\n",
        "    # refined_pts are 1xNx2 arrays\n",
        "    return refined_pts1, refined_pts2\n",
        "\n",
        "def triangulate_points(P1, P2, refined_pts1, refined_pts2):\n",
        "    '''Reconstructs 3D points by triangulation using Direct Linear Transformation.'''\n",
        "    # convert to 2xN arrays\n",
        "    refined_pts1 = refined_pts1[0].T\n",
        "    refined_pts2 = refined_pts2[0].T\n",
        "\n",
        "    # pick the P2 matrix with the most scene points in front of the cameras after triangulation\n",
        "    ind = 0\n",
        "    maxres = 0\n",
        "\n",
        "    for i in range(4):\n",
        "        # triangulate inliers and compute depth for each camera\n",
        "        homog_3D = cv2.triangulatePoints(P1, P2[i], refined_pts1, refined_pts2)\n",
        "        # the sign of the depth is the 3rd value of the image point after projecting back to the image\n",
        "        d1 = np.dot(P1, homog_3D)[2]\n",
        "        d2 = np.dot(P2[i], homog_3D)[2]\n",
        "        \n",
        "        if sum(d1 > 0) + sum(d2 < 0) > maxres:\n",
        "            maxres = sum(d1 > 0) + sum(d2 < 0)\n",
        "            ind = i\n",
        "            infront = (d1 > 0) & (d2 < 0)\n",
        "\n",
        "    # triangulate inliers and keep only points that are in front of both cameras\n",
        "    # homog_3D is a 4xN array of reconstructed points in homogeneous coordinates, pts_3D is a Nx3 array\n",
        "    homog_3D = cv2.triangulatePoints(P1, P2[ind], refined_pts1, refined_pts2)\n",
        "    homog_3D = homog_3D[:, infront]\n",
        "    homog_3D = homog_3D / homog_3D[3]\n",
        "    pts_3D = np.array(homog_3D[:3]).T\n",
        "\n",
        "    return homog_3D, pts_3D, infront\n",
        "\n",
        "def apply_infront_filter(infront, norm_pts1, norm_pts2):\n",
        "    '''Keep only those points that are in front of the cameras.'''\n",
        "    norm_pts1 = norm_pts1[infront.ravel()==1]\n",
        "    norm_pts2 = norm_pts2[infront.ravel()==1]\n",
        "    return norm_pts1, norm_pts2\n",
        "\n",
        "def filter_outliers(pts_3D, norm_pts1, norm_pts2):\n",
        "    '''Remove points that are too far away from the median.'''\n",
        "    x, y, z = pts_3D.T[0], pts_3D.T[1], pts_3D.T[2]\n",
        "    x_med, y_med, z_med = np.median(x), np.median(y), np.median(z)\n",
        "    x_std, y_std, z_std = np.std(x), np.std(y), np.std(z)\n",
        "\n",
        "    N = 2 # number of std devs\n",
        "    x_mask = [ True if ( x_med - N*x_std < coord < x_med + N*x_std) else False for coord in x ]\n",
        "    y_mask = [ True if ( y_med - N*y_std < coord < y_med + N*y_std) else False for coord in y ]\n",
        "    z_mask = [ True if ( z_med - N*z_std < coord < z_med + N*z_std) else False for coord in z ]\n",
        "    mask = [ all(tup) for tup in zip(x_mask, y_mask, z_mask) ]\n",
        "\n",
        "    pts_3D = [ pt[0] for pt in zip(pts_3D, mask) if pt[1] ]\n",
        "    norm_pts1 = [ pt[0] for pt in zip(norm_pts1, mask) if pt[1] ]\n",
        "    norm_pts2 = [ pt[0] for pt in zip(norm_pts2, mask) if pt[1] ]\n",
        "\n",
        "    return pts_3D, norm_pts1, norm_pts2\n",
        "\n",
        "def get_colours(img1, K_matrices, norm_pts1, norm_pts2):\n",
        "    '''Extract RGB data from the original images and store them in new arrays.'''\n",
        "    K1 = K_matrices[-2]\n",
        "    K2 = K_matrices[-1]\n",
        "    # get the original x and y image coords\n",
        "    norm_pts1 = np.array([ pt[0] for pt in norm_pts1 ])\n",
        "    norm_pts1 = np.vstack((norm_pts1.T, np.ones(norm_pts1.shape[0])))\n",
        "    img1_pts = np.dot(K1, norm_pts1).T\n",
        "    norm_pts2 = np.array([ pt[0] for pt in norm_pts2 ])\n",
        "    norm_pts2 = np.vstack((norm_pts2.T, np.ones(norm_pts2.shape[0])))\n",
        "    img2_pts = np.dot(K2, norm_pts2).T\n",
        "\n",
        "    # extract RGB information from first image and store in new arrays with the coordinates\n",
        "    img_colours = np.array([ img1[ pt[1] ][ pt[0] ] for pt in img1_pts ])\n",
        "\n",
        "    return img1_pts, img2_pts, img_colours\n",
        "\n",
        "def compute_cam_pose(K_matrices, matched_pts_2D, matched_pts_3D, poses):\n",
        "    '''Compute the camera pose from a set of 3D and 2D correspondences.'''\n",
        "    K1 = K_matrices[-2]\n",
        "    rvec, tvec = cv2.solvePnPRansac(matched_pts_3D, matched_pts_2D, K1, None)[0:2]\n",
        "    rmat = cv2.Rodrigues(rvec)[0]\n",
        "    pose = np.hstack((rmat, tvec))\n",
        "    poses.append(pose)\n",
        "    return poses\n",
        "\n",
        "def load_points(filename):\n",
        "    '''Loads .txt and .pcd files.'''\n",
        "    format = filename.rpartition('.')[2]\n",
        "    if format == 'txt':\n",
        "        data = np.loadtxt(filename)\n",
        "        pt_cloud = data[:,:3]\n",
        "        colours = data[:,3:]\n",
        "\n",
        "    elif format == 'pcd':\n",
        "        data = np.loadtxt(filename)[11:]\n",
        "        pt_cloud = data[:,:3]\n",
        "        colours = data[:,3:]\n",
        "\n",
        "    # display_vtk.vtk_show_points(pt_cloud, list(colours))\n",
        "\n",
        "def rgb_to_int(colours):\n",
        "    return np.array([ c[0]*256*256 + c[1]*256 + c[2] for c in colours ])\n",
        "\n",
        "def save_points(choice, images, pt_cloud, colours, file_path=None, save_format='txt'):\n",
        "    '''Saves point cloud data in .txt or .pcd formats.'''\n",
        "    if file_path is None:\n",
        "        file_path = 'points/' + images[0].split('/')[1].lower() + '_' + choice\n",
        "\n",
        "    if save_format == 'txt':\n",
        "        data = np.hstack((pt_cloud, colours))\n",
        "        np.savetxt('%s.%s' % (file_path, save_format), data, delimiter=\" \")\n",
        "\n",
        "    elif save_format == 'pcd':\n",
        "        header = ['# .PCD v.7 - Point Cloud Data file format', \n",
        "                      'VERSION.7', 'FIELDS x y z rgb', 'SIZE 4 4 4 4', \n",
        "                      'TYPE F F F F', 'COUNT 1 1 1 1', 'WIDTH %s' % pt_cloud.shape[0], \n",
        "                      'HEIGHT 1', 'VIEWPOINT = 0 0 0 1 0 0 0', \n",
        "                      'POINTS %s' % pt_cloud.shape[0], 'DATA ascii']\n",
        "\n",
        "        colours = rgb_to_int(colours)\n",
        "        data = np.vstack((pt_cloud.T, colours)).T\n",
        "\n",
        "        with open('%s.%s' % (file_path, save_format), 'w') as f:\n",
        "            for item in header:\n",
        "                f.write(item + '\\n')\n",
        "            for pt in data:\n",
        "                f.write(np.array_str(pt).strip('[]') + '\\n')\n",
        "    # print \"    Saved file as %s.%s\" % (file_path.rpartition('/')[2], save_format)\n",
        "\n",
        "def remove_outliers(file_path):\n",
        "    points = pcl.PointCloud()\n",
        "    points.from_file(file_path)\n",
        "\n",
        "    fil = points.make_statistical_outlier_filter()\n",
        "    fil.set_mean_k(50)\n",
        "    fil.set_std_dev_mul_thresh(1.0)\n",
        "    fil.filter().to_file(file_path.rpartition('.')[0] + '_inliers' + '.pcd')\n",
        "\n",
        "def check_line(orig_file, line):\n",
        "    line = [ round(float(i), 5) for i in line.split() ]\n",
        "\n",
        "    with open(orig_file, 'r') as file_o:\n",
        "        for j, line_o in enumerate(file_o):\n",
        "            line_o = [ round(float(k), 5) for k in line_o.split() ]\n",
        "\n",
        "            if line == line_o[:3]:\n",
        "                return True, ' '.join( [ str(val) for val in line_o ] )\n",
        "    return False, None\n",
        "\n",
        "def pcd_to_txt(orig_file, file_read):\n",
        "    file_write = file_read.rpartition('.')[0] + '.txt'\n",
        "\n",
        "    try:\n",
        "        with open(file_read, 'r') as file_r:\n",
        "            with open(file_write, 'w') as file_w:\n",
        "                for i, line in enumerate(file_r):\n",
        "                    if i > 10:\n",
        "                        found, line_o = check_line(orig_file, line)\n",
        "                        if found:\n",
        "                            file_w.write(line_o + '\\n')\n",
        "    except IOError as e:\n",
        "        print ('Operation failed: %s' % e.strerror)\n",
        "\n",
        "def extract_points(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return f.read()\n",
        "\n",
        "def write_points_ba(pt_cloud_indexed, num_views, K_matrices, poses):\n",
        "    with open('ba.txt', 'w') as f:\n",
        "        # no. of 3D points, views and 2D measurements\n",
        "        M = len(pt_cloud_indexed)   # number of 3D points\n",
        "        N = num_views               # number of views: len(images)\n",
        "        K = reduce(lambda x, y: x+y, [ len(pt.origin) for pt in pt_cloud_indexed ]) # number of 2D points\n",
        "        f.write(' '.join([ str(i) for i in [M, N, K] ]) + '\\n')\n",
        "\n",
        "        # K matrices\n",
        "        K_matrices = [ matrix.ravel().tolist() for matrix in K_matrices ]\n",
        "        K_matrices = [ [ matrix[0], matrix[1], matrix[2], matrix[4], matrix[5], 0, 0, 0, 0 ] for matrix in K_matrices ]\n",
        "        for idx, matrix in enumerate(K_matrices):\n",
        "            f.write(' '.join([str(idx)] + [ str(i) for i in matrix ]) + '\\n')\n",
        "\n",
        "        # 3D point positions\n",
        "        for idx, pt in enumerate(pt_cloud_indexed):\n",
        "            coords = pt.coords.tolist()\n",
        "            f.write(' '.join([ str(idx), str(coords[0]), str(coords[1]), str(coords[2]) ]) + '\\n')\n",
        "\n",
        "        # camera poses\n",
        "        poses = [ pose.ravel().tolist() for pose in poses ]\n",
        "        for idx, pose in enumerate(poses):\n",
        "            f.write(' '.join([ str(i) for i in pose ]) + '\\n')\n",
        "\n",
        "        # 2D image measurements\n",
        "        for idx, pt in enumerate(pt_cloud_indexed):\n",
        "            for key in pt.origin:\n",
        "                f.write(' '.join([ str(key), str(idx), str(pt.origin[key][0][0]), str(pt.origin[key][0][1]), '1' ]) + '\\n')\n",
        "\n",
        "def load_refined(filename):\n",
        "    with open(filename, 'w') as f:\n",
        "        pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "fkeCaXX1kGmZ",
        "outputId": "87e018c8-6836-4fe7-d14f-c775b03b5b96"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-6f6e1589d8c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpcl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# import display_vtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcam_db\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msort_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cam_db'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pcl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o2SonwFnvgV",
        "outputId": "64b1588d-db13-4de7-f430-1c0e7d0296c9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pcl\n",
            "  Downloading pcl-0.0.0.post1.tar.gz (1.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pcl\n",
            "  Building wheel for pcl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pcl: filename=pcl-0.0.0.post1-py3-none-any.whl size=1711 sha256=5381d621309e6f0da634e7946fb4c2b2527a0319750fae5ee36a29f267eb6647\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/fa/4e/14d373f7981c93b70b5096f04f46b9484b6b9374361a17acdb\n",
            "Successfully built pcl\n",
            "Installing collected packages: pcl\n",
            "Successfully installed pcl-0.0.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "grnqXiNcoIXy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}