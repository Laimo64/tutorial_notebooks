{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/BraTS_SAMed_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-tSMFkgPhyc"
      },
      "source": [
        "# Download codes, pretrained weights and test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id3D1PuuLQMm"
      },
      "source": [
        "# Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmmYvx7FLUif",
        "outputId": "d2b0acca-b2a2-49fb-fdd5-730f34c3271b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/151.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/151.8 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m112.6/151.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for MedPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q einops==0.6.1 icecream==2.1.3 MedPy==0.4.0 monai==1.1.0 opencv_python==4.5.4.58 SimpleITK==2.2.1 tensorboardX==2.6 ml-collections==0.1.1 onnx==1.13.1 onnxruntime==1.14.1 tensorboardX torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF-Hl0fZGTRq"
      },
      "source": [
        "# Download codes, pretrained weights and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyB2eYACPtEX",
        "outputId": "c2d971d2-c7ca-4198-f475-05227eff9862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'samed_codes'...\n",
            "remote: Enumerating objects: 536, done.\u001b[K\n",
            "remote: Counting objects: 100% (369/369), done.\u001b[K\n",
            "remote: Compressing objects: 100% (219/219), done.\u001b[K\n",
            "remote: Total 536 (delta 236), reused 229 (delta 147), pack-reused 167\u001b[K\n",
            "Receiving objects: 100% (536/536), 804.38 KiB | 5.40 MiB/s, done.\n",
            "Resolving deltas: 100% (297/297), done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['subsample_datasets.py',\n",
              " 'BraTS_SAMed_train.ipynb',\n",
              " 'requirements.txt',\n",
              " '.gitignore',\n",
              " 'eval_BraTS.py',\n",
              " 'BraTS_SAMed_train_command_line.ipynb',\n",
              " 'segment_anything',\n",
              " '.git',\n",
              " 'trainer.py',\n",
              " 'utils.py',\n",
              " 'datasets',\n",
              " 'lists',\n",
              " 'materials',\n",
              " 'dataset_BraTS.py',\n",
              " 'train.py',\n",
              " 'preprocess',\n",
              " 'README.md',\n",
              " 'test.py',\n",
              " 'sam_lora_image_encoder_mask_decoder.py',\n",
              " 'sam_lora_image_encoder.py',\n",
              " 'train_BraTS.py',\n",
              " 'trainer_BraTS.py']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "CODE_DIR = 'samed_codes'\n",
        "\n",
        "# Create the parent directory\n",
        "os.makedirs(f'./{CODE_DIR}', exist_ok=True)\n",
        "\n",
        "# Clone the SAMed repository into its subfolder\n",
        "!git clone https://github.com/dudeurv/SAMed.git $CODE_DIR\n",
        "\n",
        "os.chdir(f'./{CODE_DIR}')\n",
        "\n",
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Qo3WFc4NsXGy",
        "outputId": "386e6793-4f87-4131-bad5-ed2453595de4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-baaaea10e478>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msam_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msam_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'1nHZWlCBpudbT4zzPyqyu2Vi5uILcxSrv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Slices.zip'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-baaaea10e478>\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(self, file_id, file_name)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mdownloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdownloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdownloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mdownloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDownloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_with_pydrive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydrive2/auth.py\u001b[0m in \u001b[0;36m_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoratee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydrive2/files.py\u001b[0m in \u001b[0;36mGetContentFile\u001b[0;34m(self, filename, mimetype, remove_bom, callback, chunksize)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;31m# We prefer to try-except for speed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                 \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_media\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileId\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mApiRequestError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydrive2/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(fd, request)\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m                 \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                     \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresumable_progress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mpositional_parameters_enforcement\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPOSITIONAL_WARNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpositional_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mnext_chunk\u001b[0;34m(self, num_retries)\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0mhttp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m         resp, content = _retry_request(\n\u001b[0m\u001b[1;32m    742\u001b[0m             \u001b[0mhttp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0mnum_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Retry on SSL errors and socket timeout errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_ssl_SSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mssl_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/oauth2client/transport.py\u001b[0m in \u001b[0;36mnew_request\u001b[0;34m(uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mbody_stream_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         resp, content = request(orig_request_method, uri, method, body,\n\u001b[0m\u001b[1;32m    174\u001b[0m                                 \u001b[0mclean_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                                 redirections, connection_type)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/oauth2client/transport.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(http, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;31m# NOTE: Allowing http or http.request is temporary (See Issue 601).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0mhttp_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     return http_callable(uri, method=method, body=body, headers=headers,\n\u001b[0m\u001b[1;32m    281\u001b[0m                          \u001b[0mredirections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mredirections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                          connection_type=connection_type)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, uri, method, body, headers, redirections, connection_type)\u001b[0m\n\u001b[1;32m   1722\u001b[0m                     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m                     (response, content) = self._request(\n\u001b[0m\u001b[1;32m   1725\u001b[0m                         \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthority\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredirections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcachekey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, conn, host, absolute_uri, request_uri, method, body, headers, redirections, cachekey)\u001b[0m\n\u001b[1;32m   1442\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httplib2/__init__.py\u001b[0m in \u001b[0;36m_conn_request\u001b[0;34m(self, conn, request_uri, method, body, headers)\u001b[0m\n\u001b[1;32m   1394\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBadStatusLine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponseNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m                 \u001b[0;31m# If we get a BadStatusLine on the first try then that means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "\n",
        "download_with_pydrive = True\n",
        "\n",
        "class Downloader(object):\n",
        "  def __init__(self, use_pydrive):\n",
        "    self.use_pydrive = use_pydrive\n",
        "    current_directory = os.getcwd()\n",
        "    self.save_dir = '.'\n",
        "    if self.use_pydrive:\n",
        "      self.authenticate()\n",
        "\n",
        "  def authenticate(self):\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    self.drive = GoogleDrive(gauth)\n",
        "\n",
        "  def download_file(self, file_id, file_name):\n",
        "    file_dst = f'{self.save_dir}/{file_name}'\n",
        "    if os.path.exists(file_dst):\n",
        "      print(f'{file_name} already exists')\n",
        "      return\n",
        "    downloaded = self.drive.CreateFile({'id': file_id})\n",
        "    downloaded.FetchMetadata(fetch_all=True)\n",
        "    downloaded.GetContentFile(file_dst)\n",
        "\n",
        "downloader = Downloader(download_with_pydrive)\n",
        "\n",
        "sam_model = {'id': '1_oCdoEEu3mNhRfFxeWyRerOKt8OEUvcg', 'name': 'sam_vit_b_01ec64.pth'}\n",
        "downloader.download_file(file_id=sam_model['id'], file_name=sam_model['name'])\n",
        "data = {'id': '1nHZWlCBpudbT4zzPyqyu2Vi5uILcxSrv', 'name': 'Slices.zip'}\n",
        "downloader.download_file(file_id=data['id'], file_name=data['name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sxSFzwwvNyB"
      },
      "outputs": [],
      "source": [
        "!unzip -n Slices.zip -d /content/samed_codes/ > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ModmC4zTSSQj"
      },
      "source": [
        "# Execute SAMed"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***From trainer.py***"
      ],
      "metadata": {
        "id": "uqqgeTAZErnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLjKoVzbFvlC",
        "outputId": "2e1f7866-9388-4b84-f98a-e99ca097dde5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tensorboardX import SummaryWriter\n",
        "from torch.nn.modules.loss import CrossEntropyLoss\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from utils import DiceLoss, Focal_loss\n",
        "from torchvision import transforms\n",
        "from icecream import ic\n",
        "\n",
        "from eval_BraTS import test_per_epoch, vis_per_epoch, calc_loss\n",
        "\n",
        "def trainer_BraTS(args, model, snapshot_path, multimask_output, low_res):\n",
        "    from dataset_BraTS import BraTS_dataset\n",
        "    base_lr = args.base_lr\n",
        "    num_classes = args.num_classes\n",
        "    batch_size = args.batch_size * args.n_gpu\n",
        "    # max_iterations = args.max_iterations\n",
        "    db_train = BraTS_dataset(base_dir=args.root_path)\n",
        "    db_test = BraTS_dataset(base_dir='/content/samed_codes/Slices/Test')\n",
        "    print(\"The length of train set is: {}\".format(len(db_train)))\n",
        "\n",
        "    def worker_init_fn(worker_id):\n",
        "        random.seed(args.seed + worker_id)\n",
        "\n",
        "    trainloader = DataLoader(db_train, batch_size=5, shuffle=True, num_workers=8, pin_memory=True,\n",
        "                             worker_init_fn=worker_init_fn)\n",
        "    testloader = DataLoader(db_test, batch_size=10, shuffle=True, num_workers=8, pin_memory=True,\n",
        "                             worker_init_fn=worker_init_fn)\n",
        "    if args.n_gpu > 1:\n",
        "        model = nn.DataParallel(model)\n",
        "    model.train()\n",
        "\n",
        "    if args.warmup:\n",
        "        b_lr = base_lr / args.warmup_period\n",
        "    else:\n",
        "        b_lr = base_lr\n",
        "    if args.AdamW:\n",
        "        optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=b_lr, betas=(0.9, 0.999), weight_decay=0.1)\n",
        "    else:\n",
        "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=b_lr, momentum=0.9, weight_decay=0.0001)  # Even pass the model.parameters(), the `requires_grad=False` layers will not update\n",
        "    writer = SummaryWriter(snapshot_path + '/log')\n",
        "    iter_num = 0\n",
        "    max_epoch = args.max_epochs\n",
        "    stop_epoch = args.stop_epoch\n",
        "    best_epoch, best_loss = 0.0, np.inf\n",
        "    max_iterations = args.max_epochs * len(trainloader)  # max_epoch = max_iterations // len(trainloader) + 1\n",
        "    print(\"{} iterations per epoch. {} max iterations \".format(len(trainloader), max_iterations))\n",
        "    best_performance = 0.0\n",
        "    iterator = tqdm(range(max_epoch), ncols=70)\n",
        "    for epoch_num in iterator:\n",
        "        for i_batch, (image_batch, label_batch) in enumerate(trainloader):\n",
        "            # Original shape of image and label batch\n",
        "\n",
        "            image_batch, label_batch = image_batch.unsqueeze(1).float().cuda(), label_batch.unsqueeze(1).cuda()\n",
        "            image_batch = image_batch.repeat(1, 3, 1, 1)\n",
        "            # Resize the target\n",
        "            label_batch = F.interpolate(label_batch, size=(128, 128), mode='nearest')\n",
        "            label_batch = label_batch.squeeze(1)\n",
        "\n",
        "            label_batch = torch.clamp(label_batch, 0, num_classes-1)\n",
        "\n",
        "            assert image_batch.max() <= 3, f'image_batch max: {image_batch.max()}'\n",
        "            outputs = model(image_batch, multimask_output, args.img_size)\n",
        "            # Check the shape and content of the model output\n",
        "\n",
        "            loss, loss_ce, loss_dice = calc_loss(outputs, label_batch, args.dice_param, num_classes)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if args.warmup and iter_num < args.warmup_period:\n",
        "                lr_ = base_lr * ((iter_num + 1) / args.warmup_period)\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = lr_\n",
        "            else:\n",
        "                if args.warmup:\n",
        "                    shift_iter = iter_num - args.warmup_period\n",
        "                    assert shift_iter >= 0, f'Shift iter is {shift_iter}, smaller than zero'\n",
        "                else:\n",
        "                    shift_iter = iter_num\n",
        "                lr_ = base_lr * (1.0 - shift_iter / max_iterations) ** 0.9  # learning rate adjustment depends on the max iterations\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = lr_\n",
        "\n",
        "        # Testing at the end of each epoch\n",
        "        test_loss, test_loss_ce, test_loss_dice = test_per_epoch(model, testloader, multimask_output, args.img_size)\n",
        "\n",
        "        # Update best model if current epoch's loss is lower\n",
        "        if test_loss < best_loss:\n",
        "            best_loss = test_loss\n",
        "            best_epoch = epoch_num\n",
        "            torch.save(model.state_dict(), os.path.join(snapshot_path, 'model_best_epoch_{:03d}.pth'.format(best_epoch)))\n",
        "            print(\"New best model saved with loss {:.4f}\".format(best_loss))\n",
        "\n",
        "        # Log at the end of each epoch\n",
        "        print(f'--- Epoch {epoch_num}/{args.max_epochs}: Training loss = {loss:.4f}, Testing loss = {test_loss:.4f}, Best loss = {best_loss:.4f}, Best epoch = {best_epoch}')\n",
        "\n",
        "        if (epoch_num + 1) % 2 == 0 or epoch_num >= args.max_epochs or epoch_num >= args.stop_epoch :\n",
        "            save_mode_path = os.path.join(snapshot_path, 'epoch_{:03d}.pth'.format(epoch_num))\n",
        "            torch.save(model.state_dict(), save_mode_path)\n",
        "            print(\"Model saved to {}\".format(save_mode_path))\n",
        "            if epoch_num >= args.max_epochs - 1 or epoch_num >= args.stop_epoch - 1:\n",
        "                iterator.close()\n",
        "                break\n",
        "\n",
        "    writer.close()\n",
        "    return \"Training Finished!\""
      ],
      "metadata": {
        "id": "pfZK9Fl1Ewl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***From train.py***"
      ],
      "metadata": {
        "id": "hsbI7rA0EdEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "from importlib import import_module\n",
        "\n",
        "from sam_lora_image_encoder import LoRA_Sam\n",
        "from segment_anything import sam_model_registry\n",
        "\n",
        "from icecream import ic\n",
        "\n",
        "# Manually set the arguments\n",
        "args = argparse.Namespace(\n",
        "    root_path='/content/samed_codes/Slices/Train',\n",
        "    output='/content/samed_codes/training_output',\n",
        "    dataset='BraTS',\n",
        "    num_classes=8,\n",
        "    max_iterations=100,\n",
        "    max_epochs=10,\n",
        "    stop_epoch=11,\n",
        "    batch_size=10,\n",
        "    n_gpu=2,\n",
        "    deterministic=1,\n",
        "    base_lr=0.005,\n",
        "    img_size=512,\n",
        "    seed=1234,\n",
        "    vit_name='vit_b',\n",
        "    ckpt='/content/samed_codes/sam_vit_b_01ec64.pth',\n",
        "    lora_ckpt=None,\n",
        "    rank=4,\n",
        "    warmup=True,  # True if you want to use warmup\n",
        "    warmup_period=250,\n",
        "    AdamW=True,  # True if you want to use AdamW\n",
        "    module='sam_lora_image_encoder',\n",
        "    dice_param=0.8\n",
        ")\n",
        "\n",
        "\n",
        "if not args.deterministic:\n",
        "    cudnn.benchmark = True\n",
        "    cudnn.deterministic = False\n",
        "else:\n",
        "    cudnn.benchmark = False\n",
        "    cudnn.deterministic = True\n",
        "\n",
        "random.seed(args.seed)\n",
        "np.random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "torch.cuda.manual_seed(args.seed)\n",
        "dataset_name = args.dataset\n",
        "dataset_config = {\n",
        "    'BraTS': {\n",
        "        'root_path': args.root_path,\n",
        "        'num_classes': args.num_classes,\n",
        "    }\n",
        "}\n",
        "args.is_pretrain = True\n",
        "args.exp = dataset_name + '_' + str(args.img_size)\n",
        "snapshot_path = os.path.join(args.output, \"{}\".format(args.exp))\n",
        "snapshot_path = snapshot_path + '_pretrain' if args.is_pretrain else snapshot_path\n",
        "snapshot_path += '_' + args.vit_name\n",
        "snapshot_path = snapshot_path + '_' + str(args.max_iterations)[\n",
        "                                      0:2] + 'k' if args.max_iterations != 30000 else snapshot_path\n",
        "snapshot_path = snapshot_path + '_epo' + str(args.max_epochs) if args.max_epochs != 30 else snapshot_path\n",
        "snapshot_path = snapshot_path + '_bs' + str(args.batch_size)\n",
        "snapshot_path = snapshot_path + '_lr' + str(args.base_lr) if args.base_lr != 0.01 else snapshot_path\n",
        "snapshot_path = snapshot_path + '_s' + str(args.seed) if args.seed != 1234 else snapshot_path\n",
        "\n",
        "if not os.path.exists(snapshot_path):\n",
        "    os.makedirs(snapshot_path)\n",
        "\n",
        "# register model\n",
        "sam, img_embedding_size = sam_model_registry[args.vit_name](image_size=args.img_size,\n",
        "                                                            num_classes=args.num_classes,\n",
        "                                                            checkpoint=args.ckpt, pixel_mean=[0, 0, 0],\n",
        "                                                            pixel_std=[1, 1, 1])\n",
        "\n",
        "pkg = import_module(args.module)\n",
        "net = pkg.LoRA_Sam(sam, args.rank).cuda()\n",
        "\n",
        "# net = LoRA_Sam(sam, args.rank).cuda()\n",
        "if args.lora_ckpt is not None:\n",
        "    net.load_lora_parameters(args.lora_ckpt)\n",
        "\n",
        "if args.num_classes > 1:\n",
        "    multimask_output = True\n",
        "else:\n",
        "    multimask_output = False\n",
        "\n",
        "low_res = img_embedding_size * 4\n",
        "\n",
        "config_file = os.path.join(snapshot_path, 'config.txt')\n",
        "config_items = []\n",
        "for key, value in args.__dict__.items():\n",
        "    config_items.append(f'{key}: {value}\\n')\n",
        "\n",
        "with open(config_file, 'w') as f:\n",
        "    f.writelines(config_items)\n",
        "\n",
        "trainer = {'BraTS': trainer_BraTS}\n",
        "trainer[dataset_name](args, net, snapshot_path, multimask_output, low_res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "01ORU0VADVCd",
        "outputId": "e6cb7e00-569d-4e76-859a-89e0de4987d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1, 1])\n",
            "The length of train set is: 1395\n",
            "279 iterations per epoch. 2790 max iterations \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|███▎                             | 1/10 [05:13<46:58, 313.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved with loss 0.6990\n",
            "--- Epoch 0/10: Training loss = 0.7132, Testing loss = 0.6990, Best loss = 0.6990, Best epoch = 0\n",
            "New best model saved with loss 0.2946\n",
            "--- Epoch 1/10: Training loss = 0.3918, Testing loss = 0.2946, Best loss = 0.2946, Best epoch = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██████▌                          | 2/10 [10:29<42:02, 315.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/samed_codes/training_output/BraTS_512_pretrain_vit_b_10k_epo10_bs10_lr0.005/epoch_001.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|█████████▉                       | 3/10 [15:46<36:50, 315.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved with loss 0.2888\n",
            "--- Epoch 2/10: Training loss = 0.1009, Testing loss = 0.2888, Best loss = 0.2888, Best epoch = 2\n",
            "New best model saved with loss 0.2861\n",
            "--- Epoch 3/10: Training loss = 0.2718, Testing loss = 0.2861, Best loss = 0.2861, Best epoch = 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|█████████████▏                   | 4/10 [21:03<31:37, 316.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/samed_codes/training_output/BraTS_512_pretrain_vit_b_10k_epo10_bs10_lr0.005/epoch_003.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|████████████████▌                | 5/10 [26:19<26:21, 316.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved with loss 0.2803\n",
            "--- Epoch 4/10: Training loss = 0.2755, Testing loss = 0.2803, Best loss = 0.2803, Best epoch = 4\n",
            "--- Epoch 5/10: Training loss = 0.3133, Testing loss = 0.2864, Best loss = 0.2803, Best epoch = 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|███████████████████▊             | 6/10 [31:35<21:04, 316.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/samed_codes/training_output/BraTS_512_pretrain_vit_b_10k_epo10_bs10_lr0.005/epoch_005.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████████████████████          | 7/10 [36:51<15:48, 316.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Epoch 6/10: Training loss = 0.3089, Testing loss = 0.2933, Best loss = 0.2803, Best epoch = 4\n",
            "--- Epoch 7/10: Training loss = 0.1938, Testing loss = 0.2931, Best loss = 0.2803, Best epoch = 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|██████████████████████████▍      | 8/10 [42:07<10:32, 316.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/samed_codes/training_output/BraTS_512_pretrain_vit_b_10k_epo10_bs10_lr0.005/epoch_007.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████████████████████████▋   | 9/10 [47:23<05:16, 316.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Epoch 8/10: Training loss = 0.3954, Testing loss = 0.3034, Best loss = 0.2803, Best epoch = 4\n",
            "--- Epoch 9/10: Training loss = 0.2982, Testing loss = 0.2948, Best loss = 0.2803, Best epoch = 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████████████████████████▋   | 9/10 [52:39<05:51, 351.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/samed_codes/training_output/BraTS_512_pretrain_vit_b_10k_epo10_bs10_lr0.005/epoch_009.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Training Finished!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from dataset_BraTS import BraTS_dataset\n",
        "import matplotlib as plt\n",
        "\n",
        "# Define a function to calculate the confusion matrix from predictions and ground truths\n",
        "def calculate_confusion_matrix_from_arrays(prediction, ground_truth, nr_labels):\n",
        "    # Stack the ground truth and prediction arrays and transpose\n",
        "    replace_indices = np.vstack((\n",
        "        ground_truth.flatten(),\n",
        "        prediction.flatten())\n",
        "    ).T\n",
        "    # Compute the confusion matrix using histogram\n",
        "    confusion_matrix, _ = np.histogramdd(\n",
        "        replace_indices,\n",
        "        bins=(nr_labels, nr_labels),  # Number of bins for each dimension (nr_labels)\n",
        "        range=[(0, nr_labels), (0, nr_labels)]  # Range of labels\n",
        "    )\n",
        "    # Convert the confusion matrix to uint32 for consistency\n",
        "    confusion_matrix = confusion_matrix.astype(np.uint32)\n",
        "    return confusion_matrix\n",
        "\n",
        "# Define a function to calculate the Dice coefficient from the confusion matrix\n",
        "def calculate_dice(confusion_matrix):\n",
        "    dices = []  # Initialize a list to store Dice scores for each class\n",
        "    # Iterate over each class to calculate Dice score\n",
        "    for index in range(confusion_matrix.shape[0]):\n",
        "        true_positives = confusion_matrix[index, index]  # Diagonal elements are true positives\n",
        "        # Sum of the column for the class minus true positives gives false positives\n",
        "        false_positives = confusion_matrix[:, index].sum() - true_positives\n",
        "        # Sum of the row for the class minus true positives gives false negatives\n",
        "        false_negatives = confusion_matrix[index, :].sum() - true_positives\n",
        "        # The denominator in the Dice score formula\n",
        "        denom = 2 * true_positives + false_positives + false_negatives\n",
        "        # Handle the case where denominator is zero (to avoid division by zero)\n",
        "        if denom == 0:\n",
        "            dice = 0\n",
        "        else:\n",
        "            # Dice score calculation: 2 times the number of true positives divided by the denominator\n",
        "            dice = 2 * float(true_positives) / denom\n",
        "        dices.append(dice)  # Append the Dice score for the current class to the list\n",
        "    return dices\n",
        "\n",
        "\n",
        "# Define a function to test the model for an epoch and visualize the results\n",
        "def vis_per_epoch(model, testloader, multimask_output, img_size):\n",
        "    model.eval()\n",
        "    num_classes = 8\n",
        "    fig, axs = plt.subplots(len(testloader), 3, figsize=(1*3, len(testloader)*1), subplot_kw=dict(xticks=[],yticks=[]))\n",
        "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=np.uint32)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i_batch, (image_batch, label_batch) in enumerate(testloader):\n",
        "\n",
        "            image_batch, label_batch = image_batch.unsqueeze(1).float().cuda(), label_batch.unsqueeze(1).cuda()\n",
        "            image_batch = image_batch.repeat(1, 3, 1, 1)\n",
        "\n",
        "            label_batch = F.interpolate(label_batch, size=(128, 128), mode='nearest')\n",
        "            label_batch = label_batch.squeeze(1)\n",
        "\n",
        "            label_batch = torch.clamp(label_batch, 0, num_classes-1)\n",
        "\n",
        "            output = model(image_batch, multimask_output, img_size)\n",
        "            logits = outputs['low_res_logits']\n",
        "\n",
        "            prob = F.softmax(logits, dim=1)\n",
        "            pred_seg = torch.argmax(prob, dim=1)\n",
        "\n",
        "            confusion_matrix += calculate_confusion_matrix_from_arrays(pred_seg.cpu(), labels.cpu(), num_classes)\n",
        "\n",
        "            img_num = 0\n",
        "            axs[batch_idx, 0].imshow(images[img_num, 0].cpu().numpy(), cmap='gray')\n",
        "            axs[batch_idx, 1].imshow(labels[img_num].cpu().numpy(), cmap='gray')\n",
        "            axs[batch_idx, 2].imshow(pred_seg[img_num].cpu().numpy(), cmap='gray')\n",
        "\n",
        "    confusion_matrix = confusion_matrix[1:, 1:]\n",
        "\n",
        "    dices_per_class = {'dice_cls:{}'.format(cls + 1): dice\n",
        "                for cls, dice in enumerate(calculate_dice(confusion_matrix))}\n",
        "\n",
        "    plt.axis('OFF')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return dices_per_class\n",
        "\n",
        "import torch\n",
        "from importlib import import_module\n",
        "\n",
        "# Assuming your model's setup is like this\n",
        "sam, img_embedding_size = sam_model_registry[args.vit_name](image_size=args.img_size,\n",
        "                                                            num_classes=args.num_classes,\n",
        "                                                            checkpoint=args.ckpt, pixel_mean=[0, 0, 0],\n",
        "                                                            pixel_std=[1, 1, 1])\n",
        "pkg = import_module(args.module)\n",
        "net = pkg.LoRA_Sam(sam, args.rank).cuda()\n",
        "\n",
        "# Load the saved model\n",
        "saved_model_path = '/content/samed_codes/training_output/BraTS_512_pretrain_vit_b_10k_epo10_bs10_lr0.005/epoch_009.pth'\n",
        "net.load_state_dict(torch.load(saved_model_path))\n",
        "\n",
        "from dataset_BraTS import BraTS_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load the test dataset\n",
        "db_test = BraTS_dataset(base_dir='/content/samed_codes/Slices/Test')\n",
        "test_loader = DataLoader(db_test, batch_size=10, shuffle=False, num_workers=2)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Switch to evaluation mode\n",
        "net.eval()\n",
        "\n",
        "# Run visualization and evaluation\n",
        "dices_per_class = vis_per_epoch(net, test_loader, multimask_output, img_size=128)  # img_size should match the expected input size of your model\n",
        "\n",
        "# Output the results\n",
        "print(\"Dices per class:\", dices_per_class)\n",
        "print(\"Overall Dice:\", np.mean(list(dices_per_class.values())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "8rBj62mOPsge",
        "outputId": "b89b1aaf-eaa8-4ca8-f39b-cee8bc8cb848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1, 1])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-ccfd63694511>\u001b[0m in \u001b[0;36m<cell line: 98>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m# Load the saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0msaved_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/samed_codes/training_output/BraTS_512_pretrain_vit_b_10k_epo10_bs10_lr0.005/epoch_009.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset_BraTS\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBraTS_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2152\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2153\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LoRA_Sam:\n\tMissing key(s) in state_dict: \"sam.image_encoder.pos_embed\", \"sam.image_encoder.patch_embed.proj.weight\", \"sam.image_encoder.patch_embed.proj.bias\", \"sam.image_encoder.blocks.0.norm1.weight\", \"sam.image_encoder.blocks.0.norm1.bias\", \"sam.image_encoder.blocks.0.attn.rel_pos_h\", \"sam.image_encoder.blocks.0.attn.rel_pos_w\", \"sam.image_encoder.blocks.0.attn.qkv.qkv.weight\", \"sam.image_encoder.blocks.0.attn.qkv.qkv.bias\", \"sam.image_encoder.blocks.0.attn.qkv.linear_a_q.weight\", \"sam.image_encoder.blocks.0.attn.qkv.linear_b_q.weight\", \"sam.image_encoder.blocks.0.attn.qkv.linear_a_v.weight\", \"sam.image_encoder.blocks.0.attn.qkv.linear_b_v.weight\", \"sam.image_encoder.blocks.0.attn.proj.weight\", \"sam.image_encoder.blocks.0.attn.proj.bias\", \"sam.image_encoder.blocks.0.norm2.weight\", \"sam.image_encoder.blocks.0.norm2.bias\", \"sam.image_encoder.blocks.0.mlp.lin1.weight\", \"sam.image_encoder.blocks.0.mlp.lin1.bias\", \"sam.image_encoder.blocks.0.mlp.lin2.weight\", \"sam.image_encoder.blocks.0.mlp.lin2.bias\", \"sam.image_encoder.blocks.1.norm1.weight\", \"sam.image_encoder.blocks.1.norm1.bias\", \"sam.image_encoder.blocks.1.attn.rel_pos_h\", \"sam.image_encoder.blocks.1.attn.rel_pos_w\", \"sam.image_encoder.blocks.1.attn.qkv.qkv.weight\", \"sam.image_encoder.blocks.1.attn.qkv.qkv.bias\", \"sam.image_encoder.blocks.1.attn.qkv.linear_a_q.weight\", \"sam.image_encoder.blocks.1.attn.qkv.linear_b_q.weight\", \"sam.image_encoder.blocks.1.attn.qkv.linear_a_v.weight\", \"sam.image_encoder.blocks.1.attn.qkv.linear_b_v....\n\tUnexpected key(s) in state_dict: \"module.sam.image_encoder.pos_embed\", \"module.sam.image_encoder.patch_embed.proj.weight\", \"module.sam.image_encoder.patch_embed.proj.bias\", \"module.sam.image_encoder.blocks.0.norm1.weight\", \"module.sam.image_encoder.blocks.0.norm1.bias\", \"module.sam.image_encoder.blocks.0.attn.rel_pos_h\", \"module.sam.image_encoder.blocks.0.attn.rel_pos_w\", \"module.sam.image_encoder.blocks.0.attn.qkv.qkv.weight\", \"module.sam.image_encoder.blocks.0.attn.qkv.qkv.bias\", \"module.sam.image_encoder.blocks.0.attn.qkv.linear_a_q.weight\", \"module.sam.image_encoder.blocks.0.attn.qkv.linear_b_q.weight\", \"module.sam.image_encoder.blocks.0.attn.qkv.linear_a_v.weight\", \"module.sam.image_encoder.blocks.0.attn.qkv.linear_b_v.weight\", \"module.sam.image_encoder.blocks.0.attn.proj.weight\", \"module.sam.image_encoder.blocks.0.attn.proj.bias\", \"module.sam.image_encoder.blocks.0.norm2.weight\", \"module.sam.image_encoder.blocks.0.norm2.bias\", \"module.sam.image_encoder.blocks.0.mlp.lin1.weight\", \"module.sam.image_encoder.blocks.0.mlp.lin1.bias\", \"module.sam.image_encoder.blocks.0.mlp.lin2.weight\", \"module.sam.image_encoder.blocks.0.mlp.lin2.bias\", \"module.sam.image_encoder.blocks.1.norm1.weight\", \"module.sam.image_encoder.blocks.1.norm1.bias\", \"module.sam.image_encoder.blocks.1.attn.rel_pos_h\", \"module.sam.image_encoder.blocks.1.attn.rel_pos_w\", \"module.sam.image_encoder.blocks.1.attn.qkv.qkv.weight\", \"module.sam.image_encoder.blocks.1.attn.qkv.qkv.bias\", \"module.sam.image_encoder.b..."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}