{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Evaluation_Metrics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO9i6JnSRErR3mqnu5T4v8P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/NLP_Evaluation_Metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using nltk library"
      ],
      "metadata": {
        "id": "OaYJWbrL1P7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install nltk==3.5"
      ],
      "metadata": {
        "id": "VP7fnOQiefDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcO5gxlrdnXR",
        "outputId": "a0f2f3ca-4682-4141-b366-5438c172e252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU_1:0.5134, BLEU_2:0.2567, BLEU_3:0.0000, BLEU_4:0.0000\n",
            "prec:1.0000, rec:0.6000, f1:0.6250, tp:3.0000\n",
            "Meteor:0.5324\n"
          ]
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.chrf_score import chrf_precision_recall_fscore_support\n",
        "from nltk.translate.meteor_score import single_meteor_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "\n",
        "label = 'this is a small test'.split()\n",
        "prediction    = 'this is test'.split()\n",
        "BLEU_1 = sentence_bleu([label], prediction, weights=(1, 0, 0, 0))\n",
        "BLEU_2 = sentence_bleu([label], prediction, weights=(1, 1, 0, 0))\n",
        "BLEU_3 = sentence_bleu([label], prediction, weights=(1, 1, 1, 0))\n",
        "BLEU_4 = sentence_bleu([label], prediction, weights=(1, 1, 1, 1))\n",
        "print('BLEU_1:%.4f, BLEU_2:%.4f, BLEU_3:%.4f, BLEU_4:%.4f'%(BLEU_1, BLEU_2, BLEU_3, BLEU_4))\n",
        "\n",
        "label = 'this is a small test'.split()\n",
        "prediction    = 'this is test'.split()\n",
        "prec, rec, f1, tp = chrf_precision_recall_fscore_support(label, prediction, n=1) # where n = n-gram\n",
        "print('prec:%.4f, rec:%.4f, f1:%.4f, tp:%.4f'%(prec, rec, f1, tp))\n",
        "\n",
        "\n",
        "label = 'this is a small test'\n",
        "prediction    = 'this is test'\n",
        "meteor = single_meteor_score(label, prediction)\n",
        "print('Meteor:%.4f'%meteor)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using python coco captioning library"
      ],
      "metadata": {
        "id": "CDOTnqA61Uqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pycocoevalcap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWzI_sYfgyJP",
        "outputId": "b3cc42e4-0ff1-4178-8314-b8595f353530"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 104.3 MB 75 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pycocoevalcap.bleu.bleu import Bleu\n",
        "from pycocoevalcap.cider.cider import Cider\n",
        "from pycocoevalcap.meteor.meteor import Meteor\n",
        "from pycocoevalcap.rouge.rouge import Rouge\n",
        "from pycocoevalcap.spice.spice import Spice\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "labels = [['this is a small test'],['a large jetliner flying over a traffic filled street']]\n",
        "predictions = [['this is test'],['plane is flying through the sky']]\n",
        "\n",
        "labels = dict(zip(np.arange(len(labels)).astype(np.float), labels))\n",
        "predictions = dict(zip(np.arange(len(predictions)).astype(np.float), predictions))\n",
        "\n",
        "(bleu1_avg, bleu1_per_sentence) = Bleu(n=1).compute_score(labels, predictions) # n = n-gram\n",
        "(bleu4_avg, bleu4_per_sentence) = Bleu(n=4).compute_score(labels, predictions)\n",
        "(cider_avg, cider_per_sentence) = Cider().compute_score(labels, predictions)\n",
        "(meteor_avg, meteor_per_sentence) = Meteor().compute_score(labels, predictions)\n",
        "(rouge_avg, rouge_per_sentence) = Rouge().compute_score(labels, predictions)\n",
        "\n",
        "(spice_avg, cider_per_sentence) = Spice().compute_score(labels, predictions)\n",
        "\n",
        "print('BLEU_1:%.4f, CIDEr:%.4f, METEOR:%.4f, ROUGE:%.4f, SPICE:%.4f'\n",
        "        %(bleu1_avg[0], cider_avg, meteor_avg, rouge_avg, spice_avg))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSGkA-fnhyai",
        "outputId": "fcd5514f-ac93-4908-987d-3ff74f4f5567"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'testlen': 9, 'reflen': 14, 'guess': [9], 'correct': [4]}\n",
            "ratio: 0.6428571428112246\n",
            "{'testlen': 9, 'reflen': 14, 'guess': [9, 7, 5, 3], 'correct': [4, 1, 0, 0]}\n",
            "ratio: 0.6428571428112246\n",
            "BLEU_1:0.2550, CIDEr:1.6123, METEOR:0.1570, ROUGE:0.4232, SPICE:0.3333\n"
          ]
        }
      ]
    }
  ]
}