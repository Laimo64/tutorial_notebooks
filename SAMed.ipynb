{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/SAMed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customized Segment Anything Model for Medical Image Segmentation\n",
        "### [[Paper](https://arxiv.org/pdf/2304.13785.pdf)] [[Github](https://github.com/hitachinsk/SAMed)]\n",
        "---\n",
        "[Kaidong Zhang](https://hitachinsk.github.io/), and [Dong Liu](https://faculty.ustc.edu.cn/dongeliu/), technical report, 2023\n",
        "\n",
        "All rights reserved by the authors of SAMed\n",
        "\n",
        "We provide the entire inference pipeline in this page."
      ],
      "metadata": {
        "id": "1P2M4gZbKZWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup environment"
      ],
      "metadata": {
        "id": "Id3D1PuuLQMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q einops==0.6.1 icecream==2.1.3 MedPy==0.4.0 monai==1.1.0 opencv_python==4.5.4.58 SimpleITK==2.2.1 tensorboardX==2.6 ml-collections==0.1.1 onnx==1.13.1 onnxruntime==1.14.1 tensorboardX torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmmYvx7FLUif",
        "outputId": "245b06a1-33db-40b1-d0dd-99aa5a8bf95f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m727.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for MedPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download codes, pretrained weights and test data"
      ],
      "metadata": {
        "id": "m-tSMFkgPhyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare codes\n",
        "import os\n",
        "CODE_DIR = 'samed_codes'\n",
        "os.makedirs(f'./{CODE_DIR}')\n",
        "!git clone https://github.com/hitachinsk/SAMed.git $CODE_DIR\n",
        "os.chdir(f'./{CODE_DIR}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyB2eYACPtEX",
        "outputId": "2c05847b-ec17-4aa9-9ab6-6b294743d469"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'samed_codes'...\n",
            "remote: Enumerating objects: 225, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 225 (delta 86), reused 72 (delta 72), pack-reused 123\u001b[K\n",
            "Receiving objects: 100% (225/225), 635.01 KiB | 5.16 MiB/s, done.\n",
            "Resolving deltas: 100% (105/105), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "\n",
        "download_with_pydrive = True\n",
        "\n",
        "class Downloader(object):\n",
        "  def __init__(self, use_pydrive):\n",
        "    self.use_pydrive = use_pydrive\n",
        "    current_directory = os.getcwd()\n",
        "    self.save_dir = '.'\n",
        "    if self.use_pydrive:\n",
        "      self.authenticate()\n",
        "\n",
        "  def authenticate(self):\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    self.drive = GoogleDrive(gauth)\n",
        "\n",
        "  def download_file(self, file_id, file_name):\n",
        "    file_dst = f'{self.save_dir}/{file_name}'\n",
        "    if os.path.exists(file_dst):\n",
        "      print(f'{file_name} already exists')\n",
        "      return\n",
        "    downloaded = self.drive.CreateFile({'id': file_id})\n",
        "    downloaded.FetchMetadata(fetch_all=True)\n",
        "    downloaded.GetContentFile(file_dst)\n",
        "\n",
        "downloader = Downloader(download_with_pydrive)\n",
        "samed_model = {'id': '1P0Bm-05l-rfeghbrT1B62v5eN-3A-uOr', 'name': 'epoch_159.pth'}\n",
        "sam_model = {'id': '1_oCdoEEu3mNhRfFxeWyRerOKt8OEUvcg', 'name': 'sam_vit_b_01ec64.pth'}\n",
        "test_data = {'id': '1RczbNSB37OzPseKJZ1tDxa5OO1IIICzK', 'name': 'test_vol_h5.zip'}\n",
        "downloader.download_file(file_id=samed_model['id'], file_name=samed_model['name'])\n",
        "downloader.download_file(file_id=sam_model['id'], file_name=sam_model['name'])\n",
        "downloader.download_file(file_id=test_data['id'], file_name=test_data['name'])"
      ],
      "metadata": {
        "id": "NI9jWQnsPty2",
        "outputId": "784e3fc1-00ba-42ab-a68c-5d6b675f15f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip test_vol_h5.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng42nD8DSCp0",
        "outputId": "d17bf19e-b5c7-4497-973a-46282d81faf2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  test_vol_h5.zip\n",
            "   creating: test_vol_h5/\n",
            "  inflating: test_vol_h5/case0038.npy.h5  \n",
            "  inflating: test_vol_h5/case0036.npy.h5  \n",
            "  inflating: test_vol_h5/case0035.npy.h5  \n",
            "  inflating: test_vol_h5/case0032.npy.h5  \n",
            "  inflating: test_vol_h5/case0029.npy.h5  \n",
            "  inflating: test_vol_h5/case0025.npy.h5  \n",
            "  inflating: test_vol_h5/case0022.npy.h5  \n",
            "  inflating: test_vol_h5/case0008.npy.h5  \n",
            "  inflating: test_vol_h5/case0004.npy.h5  \n",
            "  inflating: test_vol_h5/case0003.npy.h5  \n",
            "  inflating: test_vol_h5/case0001.npy.h5  \n",
            "  inflating: test_vol_h5/case0002.npy.h5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execute SAMed"
      ],
      "metadata": {
        "id": "ModmC4zTSSQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/samed_codes\n",
        "import os\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "# from utils import test_single_volume\n",
        "from importlib import import_module\n",
        "from segment_anything import sam_model_registry\n",
        "from datasets.dataset_synapse import Synapse_dataset\n",
        "from icecream import ic\n",
        "from medpy import metric\n",
        "from scipy.ndimage import zoom\n",
        "import torch.nn as nn\n",
        "import SimpleITK as sitk\n",
        "import torch.nn.functional as F\n",
        "import imageio\n",
        "from einops import repeat\n",
        "\n",
        "\n",
        "\n",
        "class_to_name = {1: 'spleen', 2: 'right kidney', 3: 'left kidney', 4: 'gallbladder', 5: 'liver', 6: 'stomach', 7: 'aorta', 8: 'pancreas'}\n",
        "\n",
        "def calculate_metric_percase(pred, gt):\n",
        "    pred[pred > 0] = 1\n",
        "    gt[gt > 0] = 1\n",
        "    if pred.sum() > 0 and gt.sum() > 0:\n",
        "        dice = metric.binary.dc(pred, gt)\n",
        "        hd95 = metric.binary.hd95(pred, gt)\n",
        "        return dice, hd95\n",
        "    elif pred.sum() > 0 and gt.sum() == 0:\n",
        "        return 1, 0\n",
        "    else:\n",
        "        return 0, 0\n",
        "\n",
        "def test_single_volume(image, label, net, classes, multimask_output, image_size=[512, 512],\n",
        "                       test_save_path=None, case=None):\n",
        "    image, label = image.squeeze(0).cpu().detach().numpy(), label.squeeze(0).cpu().detach().numpy()\n",
        "    print('image, label:', image.shape, label.shape )\n",
        "\n",
        "    prediction = np.zeros_like(label)\n",
        "    for ind in range(image.shape[0]):\n",
        "        slice = image[ind, :, :]\n",
        "        x, y = slice.shape[0], slice.shape[1]\n",
        "        inputs = torch.from_numpy(slice).unsqueeze(0).unsqueeze(0).float().cuda()\n",
        "        inputs = repeat(inputs, 'b c h w -> b (repeat c) h w', repeat=3)\n",
        "        net.eval()\n",
        "        with torch.no_grad():\n",
        "            # print('model input:', inputs.shape)\n",
        "            outputs = net(inputs, multimask_output, image_size[0])\n",
        "            output_masks = outputs['masks']\n",
        "            out = torch.argmax(torch.softmax(output_masks, dim=1), dim=1).squeeze(0)\n",
        "            out = out.cpu().detach().numpy()\n",
        "            out_h, out_w = out.shape\n",
        "            if x != out_h or y != out_w:\n",
        "                pred = zoom(out, (x / out_h, y / out_w), order=0)\n",
        "            else:\n",
        "                pred = out\n",
        "            prediction[ind] = pred\n",
        "\n",
        "    metric_list = []\n",
        "    for i in range(1, classes + 1):\n",
        "        metric_list.append(calculate_metric_percase(prediction == i, label == i))\n",
        "\n",
        "    return metric_list\n",
        "\n",
        "def inference(args, multimask_output, db_config, model, test_save_path=None):\n",
        "    db_test = db_config['Dataset'](base_dir=args.volume_path, list_dir=args.list_dir, split='test_vol')\n",
        "    print('sample size:', len(db_test))\n",
        "    testloader = DataLoader(db_test, batch_size=1, shuffle=False, num_workers=1)\n",
        "    logging.info(f'{len(testloader)} test iterations per epoch')\n",
        "    model.eval()\n",
        "    metric_list = 0.0\n",
        "    for i_batch, sampled_batch in tqdm(enumerate(testloader)):\n",
        "        h, w = sampled_batch['image'].shape[2:]\n",
        "        image, label, case_name = sampled_batch['image'], sampled_batch['label'], sampled_batch['case_name'][0]\n",
        "        print(image.shape, label.shape)\n",
        "        metric_i = test_single_volume(image, label, model, classes=args.num_classes, multimask_output=multimask_output,\n",
        "                                      image_size=[args.img_size, args.img_size],\n",
        "                                      test_save_path=test_save_path, case=case_name)\n",
        "        metric_list += np.array(metric_i)\n",
        "        print('idx %d case %s mean_dice %f mean_hd95 %f' % (\n",
        "            i_batch, case_name, np.mean(metric_i, axis=0)[0], np.mean(metric_i, axis=0)[1]))\n",
        "        logging.info('idx %d case %s mean_dice %f mean_hd95 %f' % (\n",
        "            i_batch, case_name, np.mean(metric_i, axis=0)[0], np.mean(metric_i, axis=0)[1]))\n",
        "        if i_batch == 0:\n",
        "            break\n",
        "    metric_list = metric_list / len(db_test)\n",
        "    for i in range(1, args.num_classes + 1):\n",
        "        try:\n",
        "            logging.info('Mean class %d name %s mean_dice %f mean_hd95 %f' % (i, class_to_name[i], metric_list[i - 1][0], metric_list[i - 1][1]))\n",
        "        except:\n",
        "            logging.info('Mean class %d mean_dice %f mean_hd95 %f' % (i, metric_list[i - 1][0], metric_list[i - 1][1]))\n",
        "    performance = np.mean(metric_list, axis=0)[0]\n",
        "    mean_hd95 = np.mean(metric_list, axis=0)[1]\n",
        "    logging.info('Testing performance in best val model: mean_dice : %f mean_hd95 : %f' % (performance, mean_hd95))\n",
        "    logging.info(\"Testing Finished!\")\n",
        "    return 1\n",
        "\n",
        "\n",
        "def config_to_dict(config):\n",
        "    items_dict = {}\n",
        "    with open(config, 'r') as f:\n",
        "        items = f.readlines()\n",
        "    for i in range(len(items)):\n",
        "        key, value = items[i].strip().split(': ')\n",
        "        items_dict[key] = value\n",
        "    return items_dict\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--config', type=str, default=None, help='The config file provided by the trained model')\n",
        "    parser.add_argument('--volume_path', type=str, default='testset/test_vol_h5/')\n",
        "    parser.add_argument('--dataset', type=str, default='Synapse', help='Experiment name')\n",
        "    parser.add_argument('--num_classes', type=int, default=8)\n",
        "    parser.add_argument('--list_dir', type=str, default='./lists/lists_Synapse/', help='list_dir')\n",
        "    parser.add_argument('--output_dir', type=str, default='/output')\n",
        "    parser.add_argument('--img_size', type=int, default=512, help='Input image size of the network')\n",
        "    parser.add_argument('--input_size', type=int, default=224, help='The input size for training SAM model')\n",
        "    parser.add_argument('--seed', type=int,\n",
        "                        default=1234, help='random seed')\n",
        "    parser.add_argument('--is_savenii', action='store_true', help='Whether to save results during inference')\n",
        "    parser.add_argument('--deterministic', type=int, default=1, help='whether use deterministic training')\n",
        "    parser.add_argument('--ckpt', type=str, default='checkpoints/sam_vit_b_01ec64.pth',\n",
        "                        help='Pretrained checkpoint')\n",
        "    parser.add_argument('--lora_ckpt', type=str, default='checkpoints/epoch_159.pth', help='The checkpoint from LoRA')\n",
        "    parser.add_argument('--vit_name', type=str, default='vit_b', help='Select one vit model')\n",
        "    parser.add_argument('--rank', type=int, default=4, help='Rank for LoRA adaptation')\n",
        "    parser.add_argument('--module', type=str, default='sam_lora_image_encoder')\n",
        "\n",
        "    args = parser.parse_args([])\n",
        "    args.volume_path = 'test_vol_h5'\n",
        "    args.output_dir = 'results'\n",
        "    args.ckpt = 'sam_vit_b_01ec64.pth'\n",
        "    args.lora_ckpt = 'epoch_159.pth'\n",
        "\n",
        "    if args.config is not None:\n",
        "        # overwtite default configurations with config file\\\n",
        "        config_dict = config_to_dict(args.config)\n",
        "        for key in config_dict:\n",
        "            setattr(args, key, config_dict[key])\n",
        "\n",
        "    if not args.deterministic:\n",
        "        cudnn.benchmark = True\n",
        "        cudnn.deterministic = False\n",
        "    else:\n",
        "        cudnn.benchmark = False\n",
        "        cudnn.deterministic = True\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "    dataset_name = args.dataset\n",
        "    dataset_config = {\n",
        "        'Synapse': {\n",
        "            'Dataset': Synapse_dataset,\n",
        "            'volume_path': args.volume_path,\n",
        "            'list_dir': args.list_dir,\n",
        "            'num_classes': args.num_classes,\n",
        "            'z_spacing': 1\n",
        "        }\n",
        "    }\n",
        "    if not os.path.exists(args.output_dir):\n",
        "        os.makedirs(args.output_dir)\n",
        "\n",
        "    # register model\n",
        "    sam, img_embedding_size = sam_model_registry[args.vit_name](image_size=args.img_size,\n",
        "                                                                    num_classes=args.num_classes,\n",
        "                                                                    checkpoint=args.ckpt, pixel_mean=[0, 0, 0],\n",
        "                                                                    pixel_std=[1, 1, 1])\n",
        "\n",
        "    pkg = import_module(args.module)\n",
        "    net = pkg.LoRA_Sam(sam, args.rank).cuda()\n",
        "\n",
        "    assert args.lora_ckpt is not None\n",
        "    net.load_lora_parameters(args.lora_ckpt)\n",
        "\n",
        "    if args.num_classes > 1:\n",
        "        multimask_output = True\n",
        "    else:\n",
        "        multimask_output = False\n",
        "\n",
        "    # initialize log\n",
        "    log_folder = os.path.join(args.output_dir, 'test_log')\n",
        "    os.makedirs(log_folder, exist_ok=True)\n",
        "    logging.basicConfig(filename=log_folder + '/' + 'log.txt', level=logging.INFO,\n",
        "                        format='[%(asctime)s.%(msecs)03d] %(message)s', datefmt='%H:%M:%S')\n",
        "    logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))\n",
        "    logging.info(str(args))\n",
        "\n",
        "    if args.is_savenii:\n",
        "        test_save_path = os.path.join(args.output_dir, 'predictions')\n",
        "        os.makedirs(test_save_path, exist_ok=True)\n",
        "    else:\n",
        "        test_save_path = None\n",
        "    inference(args, multimask_output, dataset_config[dataset_name], net, test_save_path)"
      ],
      "metadata": {
        "id": "-y2mu4ndPfOZ",
        "outputId": "9c241052-d2ff-4169-b8f2-2eb2d82a6587",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/samed_codes\n",
            "sample size: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 148, 512, 512]) torch.Size([1, 148, 512, 512])\n",
            "image, label: (148, 512, 512) (148, 512, 512)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [02:27, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "idx 0 case case0008 mean_dice 0.681535 mean_hd95 16.097952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sK84zHQQtqyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "python test.py --volume_path test_vol_h5 --output_dir results --ckpt sam_vit_b_01ec64.pth --lora_ckpt epoch_159.pth"
      ],
      "metadata": {
        "id": "TsKn0gVsSUYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tEWvz8iy2N-3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}